[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos analíticos",
    "section": "",
    "text": "Temario y referencias\nEste es un curso de estadística bayesiana con énfasis en inferencia causal y flujos de trabajo robustos para análisis de datos. Está basado en el material de McElreath (2020).\nTodas las notas y material del curso estarán en este repositorio.\n\nModelos estadísticos e inferencia causal\nBásicos del flujo de trabajo para inferencia bayesiana\nBásicos de modelación\nModelos gráficos (DAGS) y efectos causales\nExperimentos. Buenos y malos controles\nMCMC, Monte Carlo Hamiltoniano y Stan\nFlujo de trabajo bayesiano avanzado\nModelos jerárquicos\nError de medición y clasificación incorrecta\nDatos faltantes\nOtros métodos de inferencia causal\n\n\nEvaluación\n\nTareas semanales (20%)\nExamen parcial (40% teórico)\nUn examen final (40% práctico)\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\nEste curso sigue aproximadamente la primera referencia (Statistical Rethinking).\n\nStatistical Rethinking\nCausal Inference in Statistics: a primer\nCounterfactuals and Causal Inference: Methods and Principles for Social Research\nBayesian workflow\nTowards a principled Bayesian workflow\n\n\n\nOtras referencias\n\nThe Book of Why\nCausal Inference: The Mixtape\nData Analysis Using Regression and Multilevel/Hierarchical Models\nPattern Recognition and Machine Learning\n\n\n\nSoftware: R y Rstudio\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje de programación que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click. Adicionalmente usaremos Stan:\n\nStan: a state-of-the-art platform for statistical modeling and high-performance statistical computation, que tiene interfaces en R, Python, etc.\n\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "Temario y referencias"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Diagramas causales\nEste es un curso de modelación bayesiana aplicada, que se concentra en plantear y resolver problemas aplicados usando estadística. Para hacer esto necesitamos entender tres componentes:\nEste proceso aplica tanto a estadística bayesiana como frecuentista, aunque en este curso, por su flexibilidad y unidad, consideraremos el enfoque bayesiano. Para la parte 1 y 2, consideraremos modelos gráficos causales, que expresan nuestro conocimiento acerca del problema de interés. Para la parte 3 propondremos un flujo de trabajo bayesiano que nos permita probar y entender el funcionamiento de nuestros modelos. Finalmente, para 2 y 3 propondremos distintas estrategias de modelación, como son modelos jerárquicos, regresión, cómo trabajar con datos faltantes, entre otros.\nEn primer lugar, observamos (McElreath (2020)):\nLas causas de los datos no pueden extrarse de los datos solamente. Muchas veces nos referimos a las causas de los datos como el proceso generador de los datos: esto incluye aspectos del fenómeno que nos interesa (ciencia o proceso de negocios, etc.), así como el proceso de observación (muestras, valores no observados, etc.).\nConsideremos un ejemplo simple para ilustrar este primer principio:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales",
    "href": "01-introduccion.html#diagramas-causales",
    "title": "1  Introducción",
    "section": "",
    "text": "Causas y mecanismos\n\n\n\nLas razones del análisis estadístico (que procedimiento o algoritmo seleccionamos, por ejemplo) en un en un problema dado no está en los datos observados, sino en las causas de los datos.\n\n\n\n\n\nEjemplo (cálculos renales)\nEste es un estudio real acerca de tratamientos para cálculos renales (Julious y Mullee (1994)). Pacientes se asignaron de una forma no controlada a dos tipos de tratamientos para reducir cálculos renales. Para cada paciente, conocemos el tipo de ćalculos que tenía (grandes o chicos) y si el tratamiento tuvo éxito o no.\nLa tabla original tiene 700 renglones (cada renglón es un paciente)\n\ncalculos &lt;- read_csv(\"../datos/kidney_stone_data.csv\")\nnames(calculos) &lt;- c(\"tratamiento\", \"tamaño\", \"éxito\")\ncalculos &lt;- calculos |&gt; \n   mutate(tamaño = ifelse(tamaño == \"large\", \"grandes\", \"chicos\")) |&gt; \n   mutate(resultado = ifelse(éxito == 1, \"mejora\", \"sin_mejora\")) |&gt; \n   select(tratamiento, tamaño, resultado)\nnrow(calculos)\n\n[1] 700\n\n\ny se ve como sigue (muestreamos algunos renglones):\n\ncalculos |&gt; \n   sample_n(10) |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\n\n\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nsin_mejora\n\n\nB\ngrandes\nsin_mejora\n\n\nA\ngrandes\nmejora\n\n\nA\ngrandes\nsin_mejora\n\n\nA\nchicos\nmejora\n\n\nA\ngrandes\nsin_mejora\n\n\nB\nchicos\nsin_mejora\n\n\nB\nchicos\nsin_mejora\n\n\nA\ngrandes\nmejora\n\n\n\n\n\nAunque estos datos contienen información de 700 pacientes, los datos pueden resumirse sin pérdida de información contando como sigue:\n\ncalculos_agregada &lt;- calculos |&gt; \n   group_by(tratamiento, tamaño, resultado) |&gt; \n   count()\ncalculos_agregada |&gt; kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nresultado\nn\n\n\n\n\nA\nchicos\nmejora\n81\n\n\nA\nchicos\nsin_mejora\n6\n\n\nA\ngrandes\nmejora\n192\n\n\nA\ngrandes\nsin_mejora\n71\n\n\nB\nchicos\nmejora\n234\n\n\nB\nchicos\nsin_mejora\n36\n\n\nB\ngrandes\nmejora\n55\n\n\nB\ngrandes\nsin_mejora\n25\n\n\n\n\n\nComo en este caso nos interesa principalmente la tasa de éxito de cada tratamiento, podemos mejorar mostrando como sigue:\n\ncalculos_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, tamaño, total, prop_mejora) |&gt; \n   arrange(tamaño) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\ntotal\nprop_mejora\n\n\n\n\nA\nchicos\n87\n0.93\n\n\nB\nchicos\n270\n0.87\n\n\nA\ngrandes\n263\n0.73\n\n\nB\ngrandes\n80\n0.69\n\n\n\n\n\nEsta tabla descriptiva es una reescritura de los datos, y no hemos resumido nada todavía. Pero es apropiada para empezar a contestar la pregunta (que es científica o causal):\n\n¿Qué indican estos datos acerca de qué tratamiento es mejor? ¿Acerca del tamaño de cálculos grandes o chicos?\n\nPodemos suponer que un analista considera de la tabla de arriba y llega a la siguiente conclusión: el tratamiento A es mejor, porque es mejor en los dos grupos de pacientes (con piedras chicas o grandes).\nAhora supongamos que otro analista decide comparar los pacientes que recibieron cada tratamiento, ignorando la variable de tamaño:\n\ncalculos |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\ny parece ser que el tratamiento \\(B\\) es mejor que el \\(A\\).\nEl contraste entre los resultados de los dos analistas es una paradoja (un ejemplo de la paradoja de Simpson) . Si un médico no sabe que tipo de cálculos tiene el paciente, ¿entonces debería recetar \\(B\\)? ¿Si sabe debería recetar \\(A\\)? Esta discusión parece no tener mucho sentido.\nPodemos investigar por qué está pasando esto considerando la siguiente tabla, que solo examina cómo se asignó el tratamiento dependiendo del tipo de cálculos de cada paciente:\n\ncalculos |&gt; group_by(tratamiento, tamaño) |&gt; count() |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\ntamaño\nn\n\n\n\n\nA\nchicos\n87\n\n\nA\ngrandes\n263\n\n\nB\nchicos\n270\n\n\nB\ngrandes\n80\n\n\n\n\n\nNuestra hipótesis aquí es que la decisión de qué tratamiento usar depende del tamaño de los cálculos. En este caso, hay una decisión pues A es una cirugía y B es un procedimiento menos invasivo, y se prefiere utilizar el tratamiento \\(A\\) para cálculos grandes, y \\(B\\) para cálculos chicos. Esto quiere decir que en la tabla total el tratamiento \\(A\\) está en desventaja porque se usa en casos más difíciles, pero el tratamiento \\(A\\) parece ser en general mejor. La razón es probablemente un proceso de optimización de recursos y riesgo que hacen los doctores.\n\nEn este caso, una mejor respuesta a la pregunta de qué tratamiento es mejor es la que presenta los datos desagregados.\nLa tabla desagregada de asignación del tratamiento nos informa acerca de cómo se está distribuyendo el tratamiento en los pacientes.\n\n\n\n\n\n\n\nNota\n\n\n\nLos resúmenes descriptivos acompañados de hipótesis causales acerca del proceso generador de datos, nos guía hacia descripciones interpretables de los datos.\n\n\nLas explicaciones no son tan simples y, otra vez, interviene el comportamiento de doctores, tratamientos, y distintos tipos de padecimientos.\nPodemos codificar la información causal con un diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    T \n    M \n    C\n  edge [minlen = 3]\n    T -&gt; M\n    C -&gt; T\n    C -&gt; M\n{ rank = same; M; T }\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, el tamaño de los cálculos es una causa común de tratamiento (T) y resultado (M). Veremos más adelante que la decisión de condicionar ( que a veces se menciona como estratificar el análisis) al tipo de cálculos proviene de un análisis relativamente simple de este diagrama causal, independientemente de los métodos que usemos para estimar las proporciones de interés (en este ejemplo, examinar las tablas cruzadas es equivalente a hacer estimaciones de máxima verosimlitud).\n\n\nEjemplo (cálculos renales 2)\nContrastemos el ejemplo anterior usando exactamente la misma tabla de datos, pero con el supuesto de un proceso generador diferente. En este caso, los tratamientos son para mejorar alguna enfermedad del corazón. Sabemos que parte del efecto de este tratamiento ocurre gracias a una baja en presión arterial de los pacientes, así que después de administrar el tratamiento, se toma la presión arterial de los pacientes. Ahora tenemos la tabla agregada y desagregada como sigue:\n\ncorazon &lt;- calculos |&gt; \n  select(tratamiento, presión = tamaño, resultado) |&gt; \n  mutate(presión = ifelse(presión == \"grandes\", \"alta\", \"baja\"))\ncorazon_agregada &lt;- corazon |&gt; \n   group_by(tratamiento, presión, resultado) |&gt; \n   count()\ncorazon_agregada |&gt; pivot_wider(names_from = resultado, values_from = n) |&gt; \n   mutate(total = mejora + sin_mejora) |&gt; \n   mutate(prop_mejora = round(mejora / total, 2)) |&gt; \n   select(tratamiento, presión, total, prop_mejora) |&gt; \n   arrange(presión) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\npresión\ntotal\nprop_mejora\n\n\n\n\nA\nalta\n263\n0.73\n\n\nB\nalta\n80\n0.69\n\n\nA\nbaja\n87\n0.93\n\n\nB\nbaja\n270\n0.87\n\n\n\n\n\n\ncorazon |&gt; group_by(tratamiento) |&gt; \n   summarise(prop_mejora = mean(resultado == \"mejora\") |&gt; round(2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\ntratamiento\nprop_mejora\n\n\n\n\nA\n0.78\n\n\nB\n0.83\n\n\n\n\n\n¿Cuál creemos que es el mejor tratamiento en este caso? ¿Deberíamos usar la tabla agregada o la desagregada por presión?\n\nEn este caso, la tabla agregada es más apropiada (B es mejor tratamiento).\nLa razón es que presión en este caso es una consecuencia de tomar el tratamiento, y como las tablas muestran, B es más exitoso en bajar la presión de los pacientes.\nSi sólo comparamos dentro de los grupos de presión baja o de presión alta, ignoramos lo más importante del tratamiento en la probabilidad de mejorar.\n\nNuestros supuestos causales podemos mostrarlos con el siguiente diagrama:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    P\n    T \n    M \n  edge [minlen = 3]\n    T -&gt; P\n    P -&gt; M\n    T -&gt; M\n{ rank = same; M; T}\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nNótese que el análisis más apropiado no está en los datos: en ambos casos la tabla de datos es exactamente la misma. Los supuestos acerca del proceso que genera los datos sin embargo nos lleva a respuestas opuestas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#diagramas-causales-1",
    "href": "01-introduccion.html#diagramas-causales-1",
    "title": "1  Introducción",
    "section": "Diagramas causales",
    "text": "Diagramas causales\nLos diagramas de arriba se llaman DAGs (Gráficas dirigidas acíclicas), y no son generadas por datos observados, sino que codifican conocimiento acerca del fenómenos y los datos observados. Nos ayudan a (McElreath (2020)):\n\nPensar claramente en términos científicos/de negocio acerca de nuestro problema\nExpresar los supuestos que hacemos que soportan nuestro análisis\nEntender qué podemos entender o explicar, sin hacer supuestos adicionales acerca de las relaciones particulares entre las variables.\nGuiar el análisis para decidir que modelos o procedimientos usar para contestar preguntas de interés.\n\nLos DAGs se construyen con causas, e implican asociaciones observables, pero no se construyen con asociaciones simplemente. El pensamiento causal es útil siempre que queremos responder preguntas acerca de un fenómeno de interés. En particular nos asiste en las siguientes tareas:\n\nAnálisis descriptivo\n\nComo vimos en el ejemplo anterior, incluso el análisis descriptivo (qué tabla usar, qué gráfica usar) de datos requiere de un análisis causal.\nMuchas veces los datos que tenemos, por distintas razones, tienen características que requieren procesarlos (por ejemplo ponderarlos) para que nos den respuestas entendibles.\n\n\n\nInferencia causal\n\nEfectos de intervenciones: En algunos casos, queremos saber consecuencias de una intervención sobre un sistema o proceso dados (por ejemplo, ¿cuántos accidentes graves habría si pusiéramos una multa por no usar cinturón de seguridad?). Esto requiere utilizar pensamiento causal.\nContrafactuales: También es usual necesitar pensar cómo serían las cosas si el pasado se hubiera desarrollado de manera distinta (por ejemplo, ¿cómo serían las ventas si no se hubiera gastado en publicidad?) en publicidad ?).\n\n\n\nDiseño de estudios o experimentos\n\nSi queremos recolectar datos acerca de un fenómeno particular (por ejemplo, ¿cómo debo seleccionar una muestra para medir orientación política de una población?), diseños eficientes requieren tener conocimiento de dominio acerca de las causas de las variables que nos interesa medir. Por ejemplo, si queremos tomar una muestra de casillas para estimar el resultado de una votación, deberíamos considerar variables geográficas como distrito electoral, grado de urbanización, etc.\n\n\n\nPredicción\n\nIncluso en problemas de predicción, modelos útiles resultan de pensar en la estructura causal del problema. Ignorar estos aspectos puede llevar fácilmente a evaluación incorrecta del desempeño, filtración de datos, o modelos que no pueden implementarse en la práctica.\n\n\n\nOtro ejemplo (admisiones de Berkeley)\nUna ejemplo al que regresaremos más adelante es el siguiente: en 1973 se recolectaron datos agregados de solicitantes para estudiar en Berkeley para los 6 departamentos más grandes, clasificados por sexo del solicitante y si fue admitido o no. Los resultados se muestran a continuación:\n\ndata(\"UCBAdmissions\")\nadm_original &lt;- UCBAdmissions |&gt; as_tibble() |&gt; \n   pivot_wider(names_from = Admit, values_from = n) \nadm_original |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nGender\nDept\nAdmitted\nRejected\n\n\n\n\nMale\nA\n512\n313\n\n\nFemale\nA\n89\n19\n\n\nMale\nB\n353\n207\n\n\nFemale\nB\n17\n8\n\n\nMale\nC\n120\n205\n\n\nFemale\nC\n202\n391\n\n\nMale\nD\n138\n279\n\n\nFemale\nD\n131\n244\n\n\nMale\nE\n53\n138\n\n\nFemale\nE\n94\n299\n\n\nMale\nF\n22\n351\n\n\nFemale\nF\n24\n317\n\n\n\n\n\ny las proporciones de admisión por sexo y departamente son las siguientes:\n\nadm_tbl &lt;- adm_original |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected), 2), total = Admitted + Rejected) |&gt; \n   select(Gender, Dept, prop_adm, total) |&gt; \n   pivot_wider(names_from = Gender, values_from = prop_adm:total)\nadm_tbl |&gt; knitr::kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nDept\nprop_adm_Male\nprop_adm_Female\ntotal_Male\ntotal_Female\n\n\n\n\nA\n0.62\n0.82\n825\n108\n\n\nB\n0.63\n0.68\n560\n25\n\n\nC\n0.37\n0.34\n325\n593\n\n\nD\n0.33\n0.35\n417\n375\n\n\nE\n0.28\n0.24\n191\n393\n\n\nF\n0.06\n0.07\n373\n341\n\n\n\n\n\nComplementamos con las tasas de aceptación a total por género, y tasas de aceptación por departamento:\n\nadm_original |&gt; group_by(Gender) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nGender\nAdmitted\nRejected\nprop_adm\n\n\n\n\nFemale\n557\n1278\n0.30\n\n\nMale\n1198\n1493\n0.45\n\n\n\n\n\nLa pregunta que queremos hacer es: ¿existe discriminación por sexo en la selección de candidatos? Examinando las tablas no está clara cuál es la respuesta.\n\nadm_original |&gt; group_by(Dept) |&gt; \n   summarise(Admitted = sum(Admitted), Rejected = sum(Rejected)) |&gt; \n   mutate(prop_adm = round(Admitted / (Admitted + Rejected),2)) |&gt; \n   kable() |&gt; \n   kable_paper(full_width = FALSE)\n\n\n\n\nDept\nAdmitted\nRejected\nprop_adm\n\n\n\n\nA\n601\n332\n0.64\n\n\nB\n370\n215\n0.63\n\n\nC\n322\n596\n0.35\n\n\nD\n269\n523\n0.34\n\n\nE\n147\n437\n0.25\n\n\nF\n46\n668\n0.06\n\n\n\n\n\nDiscutiremos este ejemplo con más detalle más adelante. La interpretación debe ser hecha con cuidado, y debemos establecer claramente los supuestos que fundamentan nuestra decisión de mostrar cada tabla y de qué forma mostrarlas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#modelos-y-algoritmos",
    "href": "01-introduccion.html#modelos-y-algoritmos",
    "title": "1  Introducción",
    "section": "1.2 Modelos y algoritmos",
    "text": "1.2 Modelos y algoritmos\nEn muchos cursos introductorios de estadística se muestran distintos tipos de procedimientos, que aplican según el tipo de datos (por ejemplo, categóricos o numéricos, pareados, no pareados, etc), generalmente con el propósito de evaluar evidencia en contra de una hipótesis nula. Por ejemplo, de McElreath (2020):\n\n\n\nEjemplo de proceso de decisión para procedimientos estadísticos\n\n\nEste enfoque puede ser confuso en un principio (¿cómo se relacionan todos estos procedimientos?), y también restringir nuestra capacidad para analizar datos: ¿qué hacemos cuando no se cumplen los supuestos de un procedimiento? Adicionalmente si no tenemos mucha experiencia, la manera en que fallan estas herramientas puede ser poco intuitiva y difícil de descubrir.\nY aunque son herramientas poderosas, no sustituyen el pensamiento científico o de proceso de negocios. Estas herramientas no generan hallazgos si no están acompañados de pensamiento causal.\nBuscamos entonces:\n\nDar herramientas (bayesianas) para analizar datos que son más flexibles, y se puedan adaptar a distintas situaciones.\nProponer un proceso para analizar datos, que sea más sistemático, robusto, y maneras de checar que el proceso es correcto o hace lo que pensamos que tiene qué hacer.\nLigar 1 y 2 con supuestos causales claros para proponer una interpretación sólida de nuestros resultados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#análisis-como-proceso",
    "href": "01-introduccion.html#análisis-como-proceso",
    "title": "1  Introducción",
    "section": "1.3 Análisis como proceso",
    "text": "1.3 Análisis como proceso\nIremos refinando nuestro poco a poco, conforme veamos distintas herramientas y problemas. El más básico es el siguiente (McElreath (2020)):\n\nDefinir un modelo generativo para la muestra de datos.\nDefinir la cantidad que queremos estimar en relación al fenómeno de interés.\nDefinir un proceso estadístico para hacer una estimación.\nProbar el proceso 3 usando 1 y 2.\n(Usar datos) Analizar los datos, resumir resultados.\nChecar cómputos y desempeño del modelo.\n\nEste proceso no es exclusivo de los modelos bayesianos, pero quizá es más natural, como veremos, cuando adoptamos el punto de vista bayesiano. Su propósito es múltiple: verificar que nuestros modelos están estimando las cantidades que realmente nos interesan, según nuestros supuestos, verificar los programas y cómputos con los que se obtienen resultados, y checar la adecuación del modelo a datos reales, cuestionando supuestos teóricos y supuestos de modelación.\nFinalmente, quisiéramos llegar a un proceso como el que se describe en Towards a Principled Bayesian Workflow, e incorporar el que se detalla en Gelman et al. (2020):\n\n\n\nGelman et al, Bayesian Workflow",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "href": "01-introduccion.html#modelación-y-análisis-ingeniería",
    "title": "1  Introducción",
    "section": "1.4 Modelación y análisis: ingeniería",
    "text": "1.4 Modelación y análisis: ingeniería\nCualquier proceso de análisis de datos se beneficia de muchos aspectos de ingenería de software. Parte de la profesionalización del análisis de datos que observamos en ciencia de datos es utilizar las herramientas reconocidas para resolver problemas de desarrollo y calidad de código, así como su documentación.\n\nAnálisis como software: Una parte de este proceso está relacionado con la reproducibilidad y documentación del trabajo, y su objetivo es evitar errores de programación y de organización (esta parte hablaremos menos: es necesario seguir los estándares de la industria para obtener resultados más confiables).\nOtra parte es el proceso con el cual construimos y contrastamos modelos para contestar preguntas, verificamos los modelos y sus respuestas y checamos resultados de cómputos.\n\n\n\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, y Martin Modrák. 2020. «Bayesian Workflow». https://arxiv.org/abs/2011.01808.\n\n\nJulious, Steven A, y Mark A Mullee. 1994. «Confounding and Simpson’s paradox». BMJ 309 (6967): 1480-81. https://doi.org/10.1136/bmj.309.6967.1480.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html",
    "href": "02-flujo-basico.html",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "",
    "text": "2.1 Paso 1: Modelo generativo\nEn esta sección introductoria, veremos una aplicación básica del flujo de trabajo que seguiremos. El objetivo en este ejemplo es estimar la proporción de personas que es seropositiva de una enfermedad en una población dada, usando una muestra de la población de interés a la que se le aplicó una prueba de seropositivdad.\nRecordamos que el flujo básico es:\nConsideremos primero qué variables de interés tenemos: \\(p\\), la proporción de seropositivos en la población, \\(N\\) que es el número de personas a las que les hicimos la prueba, y \\(N_{+}\\) y \\(N_{-}\\) que cuentan el número de positivos y seronegativos en la muestra. Supondremos que la prueba da resultados exactos. Denotaremos por \\(\\theta\\) a la proporción de seropositivos en la muestra.\nComenzamos construyendo el diagrama que indica cómo influye cada variable en otra (nota: no son asociaciones, sino que indican qué variables “escuchan” a otras para determinar su valor). En este caso, \\(N\\) y \\(\\theta\\) son variable que no depende de ninguna otra, mientras que \\(N_{+}\\) y \\(N_{-}\\) dependen de \\(N\\) y \\(\\theta\\). Como \\(\\theta\\) es una cantidad que no observamos directamente, mostramos su nodo como un círculo.\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    theta -&gt; Nneg\n    N -&gt; Npos\n    N -&gt; Nneg\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos; Nneg}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\nQue también podríamos simplificar (suponiendo la \\(N\\) fija y conocida, pues \\(N_+\\) y \\(N\\) dan \\(N_{-}\\)) como:\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    N -&gt; Npos\n    #esp -&gt; Pos\n    #sens -&gt; Pos\n    #esp -&gt; Neg\n    #sens -&gt; Neg\n{ rank = same; theta; N }\n{ rank = same; Npos}\n#{ rank = max; sens; esp}\n\n  \n}\n\", width = 300, height = 100)\nY ahora construimos el modelo generativo. Supondremos que la muestra de \\(N\\) personas se toma de manera aleatoria de la población (una población grande, así que podemos ignorar el efectos de poblaciones finitas). Supondremos provisionalmente, además, que la prueba es perfecta, es decir, no hay falsos positivos o negativos.\nLa siguiente función simula una muestra de \\(N\\) personas, y regresa el número de Positivos y Negativos en la muestra.\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 1, esp = 1) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra\n  Pos &lt;- Pos_verdadero\n  Neg &lt;- 1 - Pos\n  # Observaciones\n  tibble(Pos = Pos, Neg = Neg)\n}\nPodemos hacer algunas pruebas del modelo generativo en casos extremos:\nset.seed(8212)\nsim_pos_neg(theta = 1.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     1     0\n 2     1     0\n 3     1     0\n 4     1     0\n 5     1     0\n 6     1     0\n 7     1     0\n 8     1     0\n 9     1     0\n10     1     0\n\nsim_pos_neg(theta = 0.0, N = 10)\n\n# A tibble: 10 × 2\n     Pos   Neg\n   &lt;int&gt; &lt;dbl&gt;\n 1     0     1\n 2     0     1\n 3     0     1\n 4     0     1\n 5     0     1\n 6     0     1\n 7     0     1\n 8     0     1\n 9     0     1\n10     0     1\n\nsim_pos_neg(theta = 0.1, N = 1e7) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.1001\nEn la práctica podemos definir pruebas más exhaustivas si es necesario. En este caso, se trata principalmente de pruebas unitarias que se utilizan comunmente en desarrollo de software.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-1-modelo-generativo",
    "href": "02-flujo-basico.html#paso-1-modelo-generativo",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "",
    "text": "Pruebas unitarias\n\n\n\nLa práctica estándar de pruebas unitarias consiste en probar unidades relativamente pequeñas de código (por ejemplo funciones) para verificar que funcionan correctamente.\nEsta estrategia debe utilizarse también, en la medida de los posible, en estadística.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-2-definir-estimando",
    "href": "02-flujo-basico.html#paso-2-definir-estimando",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.2 Paso 2: Definir estimando",
    "text": "2.2 Paso 2: Definir estimando\nAhora podemos definir en términos de nuestro modelo el valor que queremos estimar. En este caso, coincide con un párametro del modelo \\(\\theta\\), pero no necesariamente es así siempre: como veremos más adelante, puede ser una cantidad que se deriva de otras variables y parámetros del modelo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "href": "02-flujo-basico.html#paso-3-definir-un-proceso-estadístico",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.3 Paso 3: definir un proceso estadístico",
    "text": "2.3 Paso 3: definir un proceso estadístico\nDada la información limitada que tenemos acerca de la población, esperamos tener cierta incertidumbre en nuestra estimación del valor de \\(\\theta\\). En estadística bayesiana esta incertidumbre la expresamos mediante una distribución de probabilidades sobre posibles valores del \\(\\theta\\). Si denotamos por \\(D\\) a los datos observados, nuestro objetivo es calcular o aproximar\n\\[p(\\theta|D)\\] que es una distribución sobre los posibles valores de \\(\\theta\\), una vez que tenemos información de la muestra, y que pone más masa de probabilidad sobre las conjeturas de \\(\\theta\\) que son más probables o creíbles. A esta distribución le llamamos la distribución posterior de \\(\\theta\\).\nCon esta posterior podemos hacer afirmaciones probabilísticas de la forma:\n\n¿Cuál es la probabilidad de que \\(\\theta\\) sea menor a 1%, dado los datos que obtuvimos? (Muy pocos seropositivos)\n¿Cuál es la probabildad de que \\(\\theta\\) sea mayor a 80%, dado los datos que obtuvimos? (Población cerca de saturación)\n\nEstas cantidades se calculan, al menos teóricamente, integrando \\(p(\\theta|D)\\) sobre los valores de \\(\\theta\\) que nos interesan, por ejemplo,\n\\[P(\\theta &lt;= 0.01|D) = \\int_0^{0.01} p(\\theta|D) d\\theta\\] Nota: la integral la interpretamos como suma en el caso discreto.\nSupongamos entonces una \\(\\theta\\) dada, y que observamos la muestra \\(1,0,0,1,0\\). La probabilidad de observar esta muestra es (suponiendo observaciones independientes):\n\\[\\theta(1-\\theta)(1-\\theta)\\theta(1-\\theta) = \\theta^2(1-\\theta)^3\\] Para algunos valores de \\(\\theta\\) (posibles conjeturas acerca del valor de \\(\\theta\\)) podemos escribir una tabla como sigue (Nota: discretizamos por el momento a un número finito de valores de \\(\\theta\\) para hacer el argumento más simple):\n\ntheta &lt;- seq(0, 1, length.out = 11)\ntibble(conjetura_theta = theta, verosimiltud = theta^2 * (1 - theta)^3) |&gt; \n  kbl(col.names = c(\"Conjetura θ\", \"p(D|θ)\"), format = \"html\")\n\n\n\n\nConjetura θ\np(D|θ)\n\n\n\n\n0.0\n0.00000\n\n\n0.1\n0.00729\n\n\n0.2\n0.02048\n\n\n0.3\n0.03087\n\n\n0.4\n0.03456\n\n\n0.5\n0.03125\n\n\n0.6\n0.02304\n\n\n0.7\n0.01323\n\n\n0.8\n0.00512\n\n\n0.9\n0.00081\n\n\n1.0\n0.00000\n\n\n\n\n\nEn la tabla vemos que hay algunas conjeturas, o posibles valores de \\(\\theta\\), que tienen probabilidad considerablemente más alta que otra. La notación\n\\[p(D|\\theta)\\] significa: la probabilidad de los datos \\(D\\) dado el valor de \\(\\theta\\). Nótese que esta distribución no es la posterior que describimos arriba, y no es una distribución de probabilidad sobre \\(\\theta\\) (las probabilidades no suman uno). Esta función se llama usualmente verosimilitud de los datos, e incorpora supuestos concretos del proceso generador de los datos.\nUsando reglas de probabilidad (en particular la regla de Bayes), observamos que\n\\[p(\\theta | D) = \\frac{p(D|\\theta)p(\\theta)} { p(D)}.\\] Como \\(p(\\theta|D)\\) debe dar una distribución de probabilidad (suma o integra a 1), entonces \\(p(D)\\) debe ser una constante de normalización para el numerador de la derecha, es decir, basta escribir\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta) \\] Ahora es donde encontramos que tenemos que tener \\(p(\\theta)\\) para poder calcular la cantidad que nos interesa, que es la distribución posterior \\(p(\\theta|D)\\). \\(p(\\theta)\\), la distribución a priori o distribución inicial es simplemente una afirmación de dónde puede estar \\(\\theta\\), antes de observar ningún dato.\nPor el momento, podríamos poner \\(p(\\theta)\\) constante, de manera que es parte de la constante de normalización, y sólo tendríamos que normalizar como sigue:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_post &lt;- tibble(conjetura = theta, probablidad = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prob_posterior = probablidad / sum(probablidad)) \nprob_post |&gt; \n  kable(booktabs = TRUE, col.names = c(\"Conjetura θ\", \"p(D|θ)\",\"p(θ|D)\"), \n        format = \"html\") |&gt;\n  kable_paper()\n\n\n\n\nConjetura θ\np(D|θ)\np(θ|D)\n\n\n\n\n0.0\n0.00000\n0.0000000\n\n\n0.1\n0.00729\n0.0437444\n\n\n0.2\n0.02048\n0.1228923\n\n\n0.3\n0.03087\n0.1852385\n\n\n0.4\n0.03456\n0.2073807\n\n\n0.5\n0.03125\n0.1875188\n\n\n0.6\n0.02304\n0.1382538\n\n\n0.7\n0.01323\n0.0793879\n\n\n0.8\n0.00512\n0.0307231\n\n\n0.9\n0.00081\n0.0048605\n\n\n1.0\n0.00000\n0.0000000\n\n\n\n\n\nCon esto, expresamos nuestro conocimiento acerca de \\(\\theta\\), después de observar los datos, con una distribución posterior de probabilidad sobre las posibles conjecturas. Este es el resultado principal de inferencia bayesiana, y es la base para tomar decisiones relativas a \\(\\theta\\).\n\nUsando información adicional\nSupongamos que tenemos información adicional acerca de \\(\\theta\\), por ejemplo, que en un experimento similar anterior alguien tomó una muestra de dos personas, y encontraron dos negativos. Tenemos entonces como creencias inciales:\n\ntheta &lt;- seq(0, 1, length.out = 11)\nprob_priori &lt;- tibble(conjetura = theta) |&gt; \n  mutate(prob_priori = (1 - theta) * (1 - theta)) |&gt; \n  mutate(prob_priori = prob_priori / sum(prob_priori)) \nprob_priori |&gt;\n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\"), format = \"html\") |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\n\n\n\n\n0.0\n0.2597403\n\n\n0.1\n0.2103896\n\n\n0.2\n0.1662338\n\n\n0.3\n0.1272727\n\n\n0.4\n0.0935065\n\n\n0.5\n0.0649351\n\n\n0.6\n0.0415584\n\n\n0.7\n0.0233766\n\n\n0.8\n0.0103896\n\n\n0.9\n0.0025974\n\n\n1.0\n0.0000000\n\n\n\n\n\nPor ejemplo, al probabilidad inicial de que \\(\\theta\\) sea muy grande es cercana a cero, pues observamos dos negativos y ningún positivo. Ahora regresamos a considerar nuestra fórmula\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta), \\]\nEn este caso, la apriori o inicial tiene un efecto sobre la posterior. Reconsideramos entonces la posterior de nuestra muestra de 5 personas, y calculamos el producto de \\(P(D|\\theta)\\) por \\(p(\\theta)\\):\n\nprob_post &lt;- prob_priori |&gt; \n  mutate(verosimilitud = theta^2 * (1 - theta)^3) |&gt; \n  mutate(prod = verosimilitud * prob_priori)\n\n\nprob_post |&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\", \"p(D|θ)p(θ)\"), \n        format = \"html\") |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n\n\n\n\n\nY finalmente, normalizamos para encontrar la probabilidad posterior:\n\nprob_post &lt;- prob_post |&gt; \n  mutate(prob_posterior = prod / sum(prod))\n\nprob_post|&gt; \n  kable(col.names = c(\"Conjetura θ\", \"p(θ)\", \"p(D|θ)\",\n    \"p(D|θ)p(θ)\", \"p(θ|D)\"), format = \"html\") |&gt; kable_paper()\n\n\n\n\nConjetura θ\np(θ)\np(D|θ)\np(D|θ)p(θ)\np(θ|D)\n\n\n\n\n0.0\n0.2597403\n0.00000\n0.0000000\n0.0000000\n\n\n0.1\n0.2103896\n0.00729\n0.0015337\n0.0992712\n\n\n0.2\n0.1662338\n0.02048\n0.0034045\n0.2203539\n\n\n0.3\n0.1272727\n0.03087\n0.0039289\n0.2542983\n\n\n0.4\n0.0935065\n0.03456\n0.0032316\n0.2091640\n\n\n0.5\n0.0649351\n0.03125\n0.0020292\n0.1313412\n\n\n0.6\n0.0415584\n0.02304\n0.0009575\n0.0619745\n\n\n0.7\n0.0233766\n0.01323\n0.0003093\n0.0200177\n\n\n0.8\n0.0103896\n0.00512\n0.0000532\n0.0034430\n\n\n0.9\n0.0025974\n0.00081\n0.0000021\n0.0001362\n\n\n1.0\n0.0000000\n0.00000\n0.0000000\n0.0000000\n\n\n\n\n\nLa última columna nos da el resultado final de la inferencia bayesiana. Podemos resumir algunas de sus características, por ejemplo:\n\nEs muy poco probable que la seropositividad sea mayor o igual a 0.7\nUn intervalo de 90% de probabilidad para la seropositividad es \\([0.1, 0.5]\\)\n\nLa gráfica de la posterior es:\n\nprob_post |&gt;\n  ggplot(aes(x = conjetura, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\n\n\n\n\nAhora podemos definir, para nuestro ejemplo discretizado, la función que calcula la posterior dados los pasos 1 y 2:\n\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^(N - Npos) * prob_priori) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\n\nmuestra &lt;- c(1,0,0,1,0)\n\n\ncalcular_posterior(muestra, prob_priori) \n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0         0       \n 2   0.1       0.0993  \n 3   0.2       0.220   \n 4   0.3       0.254   \n 5   0.4       0.209   \n 6   0.5       0.131   \n 7   0.6       0.0620  \n 8   0.7       0.0200  \n 9   0.8       0.00344 \n10   0.9       0.000136\n11   1         0       \n\n\nProcedemos ahora a hacer algunas pruebas simples de nuestra función:\n\ncalcular_posterior(rep(0, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0.996\n 2   0.1          0.004\n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\ncalcular_posterior(rep(1, 50)) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0    \n 6   0.5          0    \n 7   0.6          0    \n 8   0.7          0    \n 9   0.8          0.011\n10   0.9          0.989\n11   1            0    \n\ncalcular_posterior(c(rep(0, 100), rep(1, 100))) |&gt; round(3)\n\n# A tibble: 11 × 2\n   theta prob_posterior\n   &lt;dbl&gt;          &lt;dbl&gt;\n 1   0            0    \n 2   0.1          0    \n 3   0.2          0    \n 4   0.3          0    \n 5   0.4          0.023\n 6   0.5          0.966\n 7   0.6          0.01 \n 8   0.7          0    \n 9   0.8          0    \n10   0.9          0    \n11   1            0    \n\n\n\n\nMás verificaciones a priori\nOtra verificación útil que podemos hacer es, una vez que hemos definido nuestro modelo generativo y un modelos estadístico asociado, generar bajo simulación datos que podríamos observar. Esto tiene como fin verificar que nuestro modelo generativo y nuestro modelo estadístico producen datos que están de acuerdo con el conocimiento experto (teoría científica o conocimiento de negocio).\nAsí que simulamos datos del modelo:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos), .groups = \"drop\") |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n\n\n\n\n\n\n\nObservamos que con nuestros supuestos, hay una probabilidad alta de observar 0 positivos (alrededor de 0.30). Esto se debe en parte a la discretización que hicimos, y que nuestra apriori pone peso considerable en prevalencia igual a cero, lo que quizá no es muy realista, y probablemente deberíamos escoger al menos una discretización más fina.\nTambién, si consideramos los supuestos como correctos, esto puede indicar el riesgo de usar una muestra chica para estimar prevalencia si esta es muy baja: es probable que obtengamos 0 observaciones positivas.\n\n\n\n\n\n\nVerificación predictiva a priori\n\n\n\nCon este tipo de verificaciones podemos detectar las consecuencias de nuestros supuestos (incluyendo la elección de distribuciones a priori), así como otras decisiones de modelado (como la discretización).\nConflictos con el conocimiento del área deben ser explorados para entenderlos y si es necesario corregir nuestros supuestos.\n\n\nEste tipo de verificaciones es muy flexible, y debe adaptarse a los aspectos del conocimiento del área que son importantes para los expertos. Podemos usar todos nuestros recursos analíticos (tablas, resúmenes, gráficas) para producir estos chequeos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "href": "02-flujo-basico.html#paso-4-probar-el-proceso-de-estimación",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.4 Paso 4: Probar el proceso de estimación",
    "text": "2.4 Paso 4: Probar el proceso de estimación\nAntes de utilizar datos, verificamos cómo se comporta nuestro proceso de estimación de acuerdo a los supuestos de nuestro modelo generativo.\n\n\n\n\n\n\nVerificación a priori\n\n\n\nLo mínimo que esperamos de nuestro método es que, bajo nuestros propios supuestos acerca del proceso generador de datos y nuestro procedimiento de estimación definido, nuestra función de estimación no tenga problemas numéricos o de programación, y que las estimaciones que arroja son apropiadas para la cantidad que nos interesa estimar. El procedimiento a grandes rasgos es:\n\nEstablecer valores de los parámetros a estimar\nSimular datos observados (con una \\(N\\) apropiada, dependiendo del tamaño de muestra que esperamos, aunque se puede explorar hacer más grande o más chico este valor).\nCalcular posterior de las cantidades de interés\nCompara los valores de 1) con la posterior de 3)\n\n\n\nDefinir que las posteriores son apropiadas para la cantidad que nos interesa estimar es delicado, y más adelante veremos algunos criterios para evaluar este aspecto. Por lo pronto, haremos algunas pruebas simples que pueden diagnosticar errores graves:\n\ntheta &lt;- 0.2\nN &lt;- 30\n# simular\nset.seed(9914)\ndatos_sim &lt;- sim_pos_neg(theta = theta, N = N)\nposterior &lt;- calcular_posterior(datos_sim$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(xintercept = theta, color = \"red\", linetype = \"dashed\")\n\n\n\n\n\n\n\n\nEn este caso, la estimación parece correcta. Podemo repetir el proceso con distintos valores de \\(\\theta\\):\n\nset.seed(21)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\n\nY vemos que en general nuestro método parece funcionar correctamente.\n\n\n\n\n\n\nObservaciones\n\n\n\n\nMás adelante veremos cómo comparar valores a estimar con la posterior a través de varias simulaciones de manera más rigurosa. Por el momento, recuerda que incluso pruebas simples o limitadas son mejores que ninguna prueba.\nTípicamente los valores iniciales se toman de la distribución a priori, como hicimos arriba. Esta prueba es en general más apropiada, pues no nos interesan configuración de parámetros con probabilidad inicial extremadamente baja (imposibles según nuestros supuestos), pero también es posible tomar algunos valores fijos de interés.\nVeremos más de chequeos o pruebas predictivas a priori, que en general también sirven para entender la adecuación del modelo y supuestos en términos de como coinciden o no datos generados con la teoría.\n\n\n\nEste paso también es importante para entender si, bajo nuestros propios supuestos, es factible obtener información útil bajo el diseño que propongamos. Por ejemplo, alguien podría proponer un diseño de muestra que sólo tome 5 personas. Podemos probar cómo se comportan nuestras estimaciones:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 3)\n      posterior &lt;- calcular_posterior(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\n\nNuestra respuesta en este caso es que quizá con 3 personas la información obtenida no será suficiente para tomar decisiones útiles: nótese que la posterior está muy poco concentrada alrededor del verdadero valor de \\(\\theta\\).\n\n2.4.1 Introduciendo un bug\nSupongamos que tenemos un error en el cálculo de la posterior:\n\ncalcular_posterior_bug &lt;- function(muestra, prob_priori){\n  # distribución inicial o a prior\n  theta &lt;- seq(0, 1, length.out = 11)\n  priori &lt;- tibble(theta = theta, prob_priori = (1 - theta) * (1 - theta)) |&gt; \n    mutate(prob_priori = prob_priori / sum(prob_priori))\n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post &lt;- tibble(theta = theta) |&gt; \n      left_join(priori, by = \"theta\") |&gt; \n    # la siguiente línea tiene un error!\n      mutate(prob_posterior = theta ^ Npos * (1 - theta)^((N - Npos * prob_priori))) |&gt; \n    mutate(prob_posterior = prob_posterior / sum(prob_posterior)) \n  prob_post |&gt; select(theta, prob_posterior)\n}\n\nNuestro chequeo apriori se ve entonces:\n\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular valor inicial\n      theta_sim &lt;- sample(seq(0, 1, length.out = 11), \n        prob = prob_priori$prob_priori, size = 1)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      posterior &lt;- calcular_posterior_bug(datos_sim$Pos)\n      posterior |&gt; mutate(theta = theta) |&gt; \n        mutate(rep = rep) |&gt; \n        mutate(theta_sim = theta_sim)\n    })\nggplot(simulacion_rep, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\n\nDonde vemos en varios casos que la “posterior” está lejos de ser consistente con los valores simulados de prueba para \\(\\theta\\).\n\n\n\n\n\n\nAspectos numéricos\n\n\n\nEs importante notar que los cálculos que hicimos arriba ingoran un principio importante al hacer cálculos de productos de probabilidades: generalmente es mejor utilizar la escala logarítmica para hacer los cálculos, y sólo al final convertir a probabilidades. Esto es porque es fácil tener subflujos numéricos al multiplicar muchas probabilidades pequeñas.\n\n\nAunque en este caso no es crítico, la siguiente función sigue esta práctica que en general es necesario seguir:\n\n# Evitar desbordes al sumar exponenciales\nlog_sum_exp &lt;- function(x){\n  max_x &lt;- max(x)\n  max_x + log(sum(exp(x - max_x)))\n}\ncalcular_posterior &lt;- function(muestra, prob_priori){\n  # evitar 0 o 1 exactos\n  theta &lt;- seq(1e-12, 1 - 1e-12, length.out = 11)\n  # no es necesario normalizar esta distribución apriori\n  log_priori &lt;- tibble(theta = theta, log_prob_priori = 2 * log(1 - theta)) \n  # calcular la probabilidad posterior\n  N &lt;- length(muestra)\n  Npos &lt;- sum(muestra)\n  prob_post_tbl &lt;- tibble(theta = theta) |&gt; \n    left_join(log_priori, by = \"theta\") |&gt; \n    # log verosimilitud\n    mutate(log_prob_posterior = \n        Npos * log(theta) + log(1 - theta) * (N - Npos)) |&gt; \n    # sumar log apriori\n    mutate(log_prob_posterior = log_prob_posterior + log_prob_priori) |&gt; \n    mutate(log_prob_posterior_norm = \n      log_prob_posterior - log_sum_exp(log_prob_posterior)) |&gt; \n    mutate(prob_posterior = exp(log_prob_posterior_norm))\n  prob_post_tbl |&gt; select(theta, prob_posterior)\n}\n\nEjercicio: corre las pruebas para esta versión de la función como hicimos arriba. Este es un cambio correcto, y desde el punto de vista de desarrollo, si nuestra batería de pruebas es apropiado podemos hacerlo con más confianza.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "href": "02-flujo-basico.html#paso-5-analizar-los-datos-y-resumir-resultados.",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.5 Paso 5: Analizar los datos y resumir resultados.",
    "text": "2.5 Paso 5: Analizar los datos y resumir resultados.\nCon este trabajo hecho (ojo: para modelos grandes es un trabajo considerable, pero importante), podemos proceder a analizar los datos.\nSupongamos que se tomó una muestra de \\(N=20\\) personas, con 17 negativos y 3 positivos. Calculamos la posterior:\n\n# en nuestro modelo *no* importa el orden, verifica:\ndatos_tbl &lt;- tibble(Pos = c(rep(1, 3), rep(0, 17)))\nposterior &lt;- calcular_posterior(muestra = datos_tbl$Pos)\nggplot(posterior, aes(x = theta, y = prob_posterior)) +\n  geom_col() +\n  labs(x = \"theta\", y = \"Prob posterior\") \n\n\n\n\n\n\n\n\nY hay varias maneras de resumir esta posterior. Por ejemplo, podemos calcular (ojo: veremos más detalles de esto más adelante):\n\n# Media\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  summarise(media = sum(theta * prob_posterior))\n\n# A tibble: 1 × 1\n  media\n  &lt;dbl&gt;\n1 0.166\n\n# Intervalo de alta probabilidad 90%\nposterior |&gt; \n  mutate(theta = theta) |&gt; \n  arrange(desc(prob_posterior)) |&gt; \n  mutate(cumsum = cumsum(prob_posterior)) |&gt; \n  filter(cumsum &lt;= 0.9) |&gt; \n  pull(theta) |&gt; \n  range()\n\n[1] 0.1 0.2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "href": "02-flujo-basico.html#paso-6-evaluar-el-modelo-y-cómputos",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.6 Paso 6: Evaluar el modelo y cómputos",
    "text": "2.6 Paso 6: Evaluar el modelo y cómputos\nEn este ejemplo, el modelo es muy simple, y los cómputos son sencillos. Para modelos más complejos es necesario checar que los cómputos sean correctos, y que el modelo ajusta razonablemente bien a los datos en los aspectos que nos interesan, de modo que dejaremos esta discusión cuando veamos el flujo bayesiano más avanzado.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#versión-continua",
    "href": "02-flujo-basico.html#versión-continua",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.7 Versión continua",
    "text": "2.7 Versión continua\nEn el ejemplo anterior utilizamos una variable aleatoria discreta para modelar la seroprevalencia, pero esto generalmente no es conveniente. Ahora repetimos el ejercicio considerando más naturalmente que \\(\\theta\\) puede tomar cualquier valor en \\([0,1]\\).\nPara el paso 1 y 2 (definir modelo generativo y cantidad a estimar), utilizamos el mismo diagrama de arriba y la misma función que simula datos. Igual que antes, para cualquier muestra \\(D\\) compuesta de 0 y 1’s (negativos y positivos), la probabilidad de observar la muestra \\(D\\) dada una conjetura \\(\\theta\\) es:\n\\[ p(D|\\theta) = \\theta^{N_+}(1-\\theta)^{N_-}\\] Y recordamos que desde el punto de vista bayesiano, queremos resumir nuestra información obtenida con la distribución posterior \\(p(\\theta|D)\\), e igual que antes tenemos que:\n\\[p(\\theta | D) \\propto p(D|\\theta)p(\\theta).\\] Por el momento pondremos la densidad continua uniforme \\(p(\\theta) = 1\\) para \\(\\theta\\in [0,1]\\) (densidad uniforme), entonces\n\\[p(\\theta|D) \\propto \\theta^{N_+}(1-\\theta)^{N_-}\\]\nEn este caso, para normalizar tenemos que hacer la integral de la expresión de la derecha, y dividir por el resultado. En general, escribiremos\n\\[B(a,b) = \\int_{0}^1 \\theta^{a-1}(1-\\theta)^{b-1} d\\theta\\] así que en nuestro caso, la posterior es:\n\\[p(\\theta|D) = \\frac{1}{B(N_{+} + 1,N_{-}+1)} \\theta^{N_+}(1-\\theta)^{N_-}\\] Es posible demostrar con cálculo que \\(B(a,b) = \\frac{(a-1)!(b-1)!}{(a+b-1)!}\\), pero eso no es importante ahora. Este tipo de densidades pertenecen a la familia beta con parámetros \\((a,b)\\), donde \\(a&gt;0, b&gt;0\\).\nPor ejemplo, si observamos 2 positivos y tres negativos, nuestra posterior es una beta con parámetros \\((3,4)\\), y se ve así:\n\nlibrary(tidyverse)\ntheta &lt;- seq(0,1, 0.01)\ntibble(theta = theta, densidad = dbeta(theta, 3, 4)) |&gt; \n  ggplot(aes(x = theta, y = densidad)) +\n  geom_line() +\n  labs(x = \"theta\", y = \"Densidad posterior\") \n\n\n\n\n\n\n\n\nNotamos adicionalmente que es posible seleccionar otra distribución inicial que no sea la uniforme. En este caso particular es conveniente (aunque no siempre tiene sentido) usar una distribución beta, de manera que es fácil ver que si ponemos por ejemplo\n\\[p(\\theta) \\propto \\theta^{a-1}(1-\\theta)^{b-1}\\]\nentonces la posterior, por la fórmula de Bayes, es:\n\\[p(\\theta|D) \\propto \\theta^{N_+ +a -1 }(1-\\theta)^{N_{-}+b-1}\\] que también es de la familia beta, pero con parámetros \\((N_{+} +a, N_{-} +b)\\).\n\n2.7.1 Ejercicio: actualizaciones de posterior\nPodemos examinar la posterior para dados distintos datos. Supondremos que la distribución a priori es uniforme.\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n      densidad = dbeta(theta_seq, n_pos + 1, n_neg + 1)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = 0, intercept = 1, color = \"gray\") \n\n\n\n\n\n\n\n\nAhora repetimos con una inicial beta \\((0,2)\\) (que equivale a observar dos negativos y ningún positivo en una muestra de 3 personas), de modo que \\(p(\\theta) = 2(1-\\theta)\\):\n\nset.seed(92192)\ntheta_seq &lt;- seq(0,1, 0.001)\ndatos_sim &lt;- sim_pos_neg(theta = 0.25, N = 12) |&gt; \n  mutate(obs = ifelse(Pos==1, \"P\", \"N\")) |&gt; \n  mutate(n = 1:12)\n# graficar posteriores para cada n\ndatos_graf &lt;- datos_sim |&gt; \n  mutate(n_pos = cumsum(Pos), n_neg = cumsum(Neg)) |&gt; \n  mutate(muestra = accumulate(obs, ~ paste0(.x, .y))) |&gt; \n  group_by(n) |&gt;\n  mutate(dens_graf = \n    list(tibble(theta = theta_seq, \n                densidad = dbeta(theta_seq, n_pos + 1, n_neg + 3)))) |&gt; \n  unnest(dens_graf)\nggplot(datos_graf, aes(x=theta, y = densidad, group = n)) +\n  geom_line() + \n  facet_wrap(~ muestra) +\n  geom_abline(slope = -2, intercept = 2, color = \"gray\") \n\n\n\n\n\n\n\n\n\nEn este punto, podríamos ir al siguiente paso, que es escribir una función para calcular la posterior. En realidad ya sabemos su función de densidad, pero cualquier resumen que hagamos de esta distribución requerirá de integrales (¿por qué? piensa en cómo calcular la probabilidad de ser menor que un valor, o cómo se calcula la media).\nAunque en este ejemplo simple la posterior tiene una forma conocida y hay manera de calcular (analíticamente o con rutinas numéricas ya implementadas) esos resúmenes de interés (media, cuantiles, etc.), en general calcular directamente integrales no es una estrategia que podamos llevar muy lejos.\n\n\nMás de verificaciones apriori\nAntes de continuar, sin embargo, veremos cómo se veo el chequeo predictivo a priori que consideramos en la sección de arriba.\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 1, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\n\nPodemos ver por ejemplo dónde esperamos ver el número de positivos a lo largo de distintas muestras, cuando \\(N=30\\):\n\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\nEste resultado es consecuencia de nuestros supuestos, antes de ver los datos, y resume que esperamos con mayor probabilidad un número bajo de positivos (en una muestra de N=30), y que es muy poco probable que observemos prevalencias muy altas. Dependiendo de la situación, este puede ser un resultado aceptable.\nUn resultado no aceptable para una enfermedad que sabemos que es relativamente rara (aunque tenemos incertidumbre), por ejemplo, podría ser el siguiente:\n\nset.seed(231)\nsimulacion_datos_tbl &lt;- map_df(1:500, \n    function(rep){\n      # apriori seleccionada\n      theta_sim &lt;- rbeta(1, 30, 3)\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 30)\n      tibble(rep = rep, theta_sim = theta_sim, datos_sim)\n    })\nsimulacion_datos_tbl |&gt; \n  group_by(rep, theta_sim) |&gt; \n  summarise(Npos = sum(Pos)) |&gt; \n  ggplot(aes(x = Npos)) +\n  geom_bar() +\n  labs(x = \"Número de positivos\", y = \"Frecuencia (muestras)\") \n\n`summarise()` has grouped output by 'rep'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\nEste resultado no es aceptable cuando sabemos que es prácticamente imposible que la mayoría de la población está infectada. Debemos entonces regresar y ajustar nuestros supuestos: el problema en este caso es la elección de la distribución a priori para \\(\\theta\\).\nObservación: la crítica es sobre el conjunto completo de supuestos iniciales que hacemos acerca del problema. Cuando los diagnósticos no son aceptables desde el punto de vista teórico es necesario investigar dónde está el problema. Las distribuciones apriori que usamos, igual que cualquier supuesto, están sujetas a esta crítica. Nótese que esta crítica la estamos haciendo sin ver los datos que esperamos observar: es una crítica de supuestos.\n\n\n2.7.2 Métodos Monte Carlo\nUna vez que tenemos la densidad posterior podemos mostrarla o resumirla de varias maneras. Si tenemos una expresión analítica, esos resúmen típicamente consisten de integrales, por ejemplo:\n\nLa media o mediana posterior\nDeciles o u otro tipo de percentiles de la posterior\nIntervalos de probabilidad posterior\n\nEste proceso puede ser no trivial incluso para densidades posteriores conocidas. La alternativa a integrar es simular de la posterior y calcular las cantidades de interés a partir de las simulaciones. En general, esto es más fácil que integrar. En nuestro ejemplo, en lugar de usar una función de calcular_posterior, construimos una que es simular_posterior.\nEsta función será simple porque simular de una beta es un problema estándar, y existen muchas implementaciones. Podríamos escribir, por ejemplo:\n\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, length(muestra) - sum(muestra) + 1))\n}\n\n\nmuestra\n\n[1] 1 0 0 1 0\n\nsims_post &lt;- simular_posterior(muestra, 10000)\n\n\nsims_post |&gt; \n  ggplot(aes(x = theta)) +\n  geom_histogram(bins = 50)\n\n\n\n\n\n\n\n\nSi queremos calcular la media, por ejemplo, hacemos\n\n sims_post |&gt; pull(theta) |&gt;  mean()\n\n[1] 0.4280916\n\n\nSi queremos la probabilidad de que la prevalencia esté por debajo de 20% hacemos:\n\nsims_post |&gt; \n  summarise(prob = mean(theta &lt; 0.2))\n\n# A tibble: 1 × 1\n    prob\n   &lt;dbl&gt;\n1 0.0961\n\n\nMuchas veces se presentan intervalos de probabilidad posterior, por ejemplo, podríamos reportar que con 90% de probabilidad la prevalencia está en el siguiente intervalo:\n\nsims_post |&gt; \n  summarise(inf = quantile(theta, 0.05),\n            sup = quantile(theta, 0.95)) |&gt; \n  mutate(inf = round(inf, 2),\n         sup = round(sup, 2))\n\n# A tibble: 1 × 2\n    inf   sup\n  &lt;dbl&gt; &lt;dbl&gt;\n1  0.16  0.73\n\n\nObservación: No hay un intervalo mágico que debe reportarse (por ejemplo 95% de probabilidad es una costumbre o superstición). Hay varias maneras de construir intervalos de probabilidad. Dejaremos esta discusión para más adelante.\n\n\n\n\n\n\nMétodos Monte Carlo\n\n\n\nLos métodos Monte Carlo están basados en simulación de variables aleatorias. Las cantidades que nos interesan son integrales bajo una densidad de probabilidad. Si queremos calcular en general \\[I = \\int f(x)p(x)dx,\\] simulamos una gran cantidad de observaciones \\(x_1,\\ldots, x_M\\) bajo \\(p(x)\\), y entonces (Ley de los grandes números):\n\\[\\frac{1}{M} \\sum_{i=1}^{M} f(x_i) \\to I\\] cuando \\(M\\to \\infty\\). De este modo, podemos aproximar con la precisión que requiramos la integral \\(I\\).\n\n\nNota 1: Sin más información del proceso de simulación, no es posible demostrar que una aproximación es “suficientemente” buena, no importa que tan grande sea \\(M\\). Más adelante veremos una batería de diagnósticos para al menos excluir los casos comunes en los que la aproximación es mala.\nNota 2: En nuestro caso, las integrales de interés usualmente son de la forma \\[I = \\int f(\\theta)p(\\theta|D) d\\theta,\\] donde \\(D\\) es la información de la muestra, \\(\\theta\\) en general es un vector de parámetros del modelo, y \\(f(\\theta)\\) es una función de \\(\\theta\\) que nos interesa. Por ejemplo, para la media posterior de \\(\\theta\\), usaríamos \\(f(\\theta) = \\theta\\). Podemos aproximar cualquier integral si tenemos simulaciones de la posterior:\n\\[\\theta_i \\sim p(\\theta|D) \\implies \\frac{1}{M} \\sum_{i=1}^{M} f(\\theta_i) \\to I.\\]\n\nFinalmente, checamos todo nuestra construcción de estimación como hicimos arriba, la diferencia es que ahora usamos simulaciones para entender el comportamiento de la posterior. En este caso, el proceso es como sigue:\n\nGeneramos un valor de la apriori \\(\\theta_{sim} \\sim \\text{Beta}(1,3)\\)\nSimulamos datos de la muestra (\\(N=25\\)) con el valor simulado de \\(\\theta\\)\nSimulamos un número grande \\(M\\) de valores de la posterior (aquí usaremos \\(M=10000\\))\nRepetimos 1-3\n\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 25)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior(datos_sim$Pos, 10000)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\nsimular_posterior &lt;- function(muestra, n){\n  tibble(theta = \n    rbeta(n, sum(muestra) + 1, \n             length(muestra) - sum(muestra) + 3))\n}\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico.html#observaciones-1",
    "href": "02-flujo-basico.html#observaciones-1",
    "title": "2  Flujo de trabajo básico: motivación",
    "section": "2.8 Observaciones",
    "text": "2.8 Observaciones\nEl proceso de arriba lo refinaremos considerablemente en el resto del curso.\n\nEn primer lugar, los modelos generativos serán más complicados, y estarán basados en teoría más compleja (que expresamos con diagramas causales)\nUsaremos más herramientas y componentes para construir modelos estadísticos apropiados, ya sea que construyamos un modelo completo para todo el proceso de generación de datos, o que usemos modelos estándar como regresión para aproximar respuestas, cuando es apropiado\nRefinaremos el proceso de checar que el cómputo (checar Monte Carlo) y la inferencia (verificación apriori) es correcta bajo nuestros supuestos.\nFinalmente, veremos qué hacer después de hacer la estimación y que los puntos de arriba están resueltos, para tener confianza en nuestras conclusiones.\n\n\n2.8.1 Resumen\nAquí juntamos algunas observaciones que se derivan de lo que hemos visto (flujo de trabajo y estimación bayesiana):\n\nTodo nuestro trabajo está fundamentado en entender qué es lo que queremos estimar dentro de un modelo generativo. Los diagramas causales nos ayudan a conectar el problema de interés con nuestros modelos, a construir modelos generativos y hacer explícitos nuestros supuestos.\nEl proceso de estimación siempre es el mismo: nuestro estimador es la distribución posterior, que se construye a partir de la verosimilitud y la apriori (modelo generativo). Nuestro estimador es la posterior de las cantidades de interés, que pueden resumirse de distintas maneras. Cualquier cálculo derivado de otras cantidades de interés debe considerar toda la posterior (no solo la media o la moda, etc. posterior).\nNuestro proceso incluye los chequeos predictivos a priori (basados en simulación de datos). Esto son cruciales para detectar problemas en nuestros supuestos (vs teoría) y que nuestro proceso sea internamente consistente. Esto también es una verificación de la información a priori.\nGeneralmente es más conveniente y práctico hacer simulaciones que calcular analíticamente la posterior o sus integrales.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Flujo de trabajo básico: motivación</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico-2.html",
    "href": "02-flujo-basico-2.html",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "",
    "text": "3.1 Prevalencia con error conocido\nEn esta parte veremos cómo continuaríamos refinando el modelo tomando en cuenta otros aspectos importantes del problema de estimar la seropositividad de una población.\nEl primer aspecto importante es persistir el seguir el flujo de trabajo. En segundo lugar, este ejemplo ilustra que la construcción de modelos preferiblemente se hace de manera iterativa: una vez que probamos nuestro código, entendemos cómo funciona nuesto modelo, podemos continuar agregando componentes para hacerlo más útil.\nNuestro ejemplo de la sección anterior es poco realista pues usualmente las pruebas que son utilizadas para medir la prevalencia no son perfectas. Bajo condiciones muy controladas, el perfil de desempeño de las pruebas se mide, obteniendo resultados son del siguiente tipo:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Flujo de trabajo básico: refinando el modelo</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "href": "02-flujo-basico-2.html#prevalencia-con-error-conocido",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "",
    "text": "En pruebas de gold standard, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas.\nSin considerar la incertidumbre, esto implica que la prueba tiene una sensibilidad de 84% y una especificidad de 99.5%.\n\n\n3.1.1 Paso 1: modelo generativo\nPrimero supondremos que estos porcentajes de error son fijos. Nuestro modelo que incluye el error de medición se como sigue:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n    Npos\n  node [shape=plaintext]\n    N\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n    #Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n    #sens\n    #esp\n  edge [minlen = 3]\n    theta -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n{ rank = same; theta; N }\n{ rank = same; Npos}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nDonde vemos ahora que el estado real de cada persona de la prueba es desconocido, aunque el resultado de la prueba depende de ese estado, y la cantidad de positivos que observamos es ahora \\(N_{obs}\\), que depende también de la sensibilidad y especificidad de la prueba.\nY para constuir el modelo generativo notamos que la probabilidad de que un individuo infectado salga positivo es \\(\\text{sens}\\), y la probabilidad de que un individuo no infectado salga positivo es \\((1-\\text{esp})\\). De este modo, el modelo generativo es:\n\nsim_pos_neg &lt;- function(theta = 0.01, N = 20, sens = 0.84, esp = 0.995) {\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, theta)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nHacemos unas pruebas:\n\nset.seed(8212)\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 0.7, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.2099\n\nsim_pos_neg(theta = 0.3, N = 1e7, sens = 1, esp = 1) |&gt; pull(Pos) |&gt; mean() |&gt; \n  round(4)\n\n[1] 0.3001\n\n\n\n\n3.1.2 Paso 2: cantidad a estimar\nEn este punto hay que tener cuidado, porque no queremos estimar la proporción de positivos potenciales en la población (pues la prueba es imperfecta), sino la proporción de verdaderos positivos en la población. Esta cantidad sigue siendo representada por \\(\\theta\\) en nuestro modelo generativo.\n\n\n3.1.3 Paso 3: modelo estadístico\nEl modelo estadístico es ahora diferente. Vamos a plantear primero \\(p(D|\\theta, sens, esp)\\), que es la probabilidad de observar los datos \\(D\\) dado que \\(\\theta\\) es el parámetro de interés, y \\(sens\\) y \\(esp\\) (que en este caso suponemos conocidos). Es fácil ver que la probabilidad de obtener un positivo ahora es:\n\\(\\theta_{obs} = P(Positivo | \\theta, sens, esp) = \\theta \\cdot sens + (1-\\theta) \\cdot (1-esp)\\)\nSi llamamos a esta cantidad \\(\\theta_{obs}\\), de forma que dada una muestra de 0’s y 1’s, tenemos que la verosimilitud de la muestra dada cada conjetura \\(\\theta\\), y con \\(sens\\) y \\(esp\\) fijas, es:\n\\[p(D|\\theta, sens, esp) = \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] Suponiendo que la distribución apriori de \\(\\theta\\) es uniforme, tenemos entonces que la distribución posterior cumple:\n\\[p(\\theta|D, sens, esp) \\propto \\theta_{obs}^{N_{+}}(1-\\theta_{obs})^{N_{-}}\\] donde \\(\\theta_{obs}\\) está dada por la fórmula de arriba. Sustituyendo:\n\\[p(\\theta|D, sens, esp) \\propto (\\theta \\cdot sens + (1-\\theta) \\cdot (1-esp))^{N_{+}}(\\theta(1-sens) + (1-\\theta)esp)^{N_{-}}\\]\nEsta posterior tiene la estructura de una distribución beta, pero es un poco más complicada. En este punto, utilizaremos una técnica que funciona para problemas chicos (de unos cuantos parámetros), y que consiste en hacer una aproximación discreta de la distribución posterior:\n\n\n\n\n\n\nMétodo de aproximación de rejilla\n\n\n\n\nDividimos el intervalo \\([0,1]\\) en \\(m\\) partes iguales, y calculamos el valor de la expresión proporcional a la posterior en cada uno de estos intervalos (por ejemplo en los puntos medios).\nNormalizamos estos valores para que sumen 1, y obtenemos una distribución discreta que aproxima la posterior.\nMuestreamos de esta distribución discreta para obtener una muestra de la posterior.\n\nEste método sólo es factible en modelos simples cuando hay solamente unos cuantos parámetros por estimar, pues su complejidad crece exponencialmente con el número de parámetros. Rara vez se usa en la práctica por esta razón.\n\n\nAquí implementamos esta técnica de aproximación por rejilla. Incluimos también una Beta(1,3) como a priori:\n\nsimular_posterior_error &lt;- function(muestra, n, sens = 1, esp = 1){\n    theta &lt;- seq(1e-12, 1-1e-12, by = 0.0001)\n    p_obs &lt;- theta * sens + (1 - theta) * (1 - esp)\n    # verosimilitud (en logaritmo)\n    log_dens_sin_norm &lt;- log(p_obs) * sum(muestra) +  \n      log(1-p_obs) * (length(muestra) - sum(muestra))\n    # a priori\n    log_dens_sin_norm &lt;- log_dens_sin_norm + dbeta(theta, 1, 3, log = TRUE)\n    # normalizar\n    log_dens_norm &lt;- log_dens_sin_norm - log_sum_exp(log_dens_sin_norm)\n    densidad_post &lt;- exp(log_dens_norm)\n    tibble(theta = sample(theta, size = n, replace = TRUE, prob = densidad_post))\n}\n\nY ahora podemos ver cómo se ve la posterior:\n\nset.seed(328)\nuna_muestra &lt;- sim_pos_neg(theta = 0.2, N = 600, sens = 0.6, esp = 0.999)\nmean(una_muestra$Pos)\n\n[1] 0.1233333\n\nsims_post_error &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, sens = 0.6, esp = 0.999) \nsims_post_error |&gt;\n  ggplot(aes(x = theta)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAhora seguimos el flujo. Agregaremos la verificación a priori para entender si nuestro modelo recupera los parámetros.\n\nset.seed(8112)\nsimulacion_rep_error &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, sens = 0.6, esp = 0.999)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\nAhora usamos histogramas por ejemplo para mostrar cómo luce la posterior, y comparamos con los valores de la simulación:\n\nggplot(simulacion_rep_error, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\nFigura 3.1: Verificación a priori\n\n\n\n\n\nContrasta con lo que pasaría si usaramos el modelo sin considerar fuentes de error:\n\nset.seed(812)\nsimulacion_rep &lt;- map_df(1:20, \n    function(rep){\n      # simular de la apriori\n      theta_sim &lt;- rbeta(1, 1, 3)\n      # simular datos según modelo\n      datos_sim &lt;- sim_pos_neg(theta = theta_sim, N = 150, sens = 0.6, esp = 0.999)\n      # simulaciones montecarlo para la posterior\n      posterior &lt;- simular_posterior_error(datos_sim$Pos, 10000, 1, 1)\n      # junta todo\n      posterior |&gt; mutate(n_sim = n()) |&gt;\n        mutate(rep = rep) |&gt;\n        mutate(theta_sim = theta_sim)\n    })\n\n\nggplot(simulacion_rep, aes(x = theta)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"theta\", y = \"Prob posterior\") +\n  geom_vline(aes(xintercept = theta_sim), color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~rep)\n\n\n\n\n\n\n\nFigura 3.2: Verificación a priori fallida (modelo incorrecto)\n\n\n\n\n\nEste resultado está lejos de ser aceptable.\nComparamos esta densidad con lo que obtendríamos sin considerar el error de medición, con los mismos datos:\n\nset.seed(8)\nsims_post &lt;- \n  simular_posterior_error(una_muestra$Pos, 5000, 1, 1)\nambas_sims_tbl &lt;- \n  sims_post_error |&gt;\n  mutate(tipo = \"Con error de medición\") |&gt;\n  bind_rows(sims_post |&gt;\n              mutate(tipo = \"Sin error de medición\"))\nambas_sims_tbl |&gt; ggplot(aes(x = theta, fill = tipo)) +\n  geom_histogram(position = \"identity\", alpha = 0.5, bins = 50) +\n  scale_fill_manual(values = c(\"red\", \"blue\")) +\n  geom_vline(xintercept = 0.2, linetype = \"dashed\", color = \"black\")\n\n\n\n\n\n\n\n\nY vemos que la diferencia entre las distribuciones es considerable. En primer lugar, la distribución con error de medición es más ancha (hay más incertidumbre). En segundo lugar, como estimador de el parámetro de interés, nuestro modelo que no considera el error parece dar estimaciones sesgadas hacia abajo. Esto es porque la prevalencia no es tan baja, y la sensibilidad de la prueba no es muy buena, de manera que con el modelo con error inferimos correctamente que hay más prevalencia que lo que indicaría la proporción de positivos en las pruebas.\nAunque este ejemplo es claro, prevalencia, sensibilidad y especificidad interactúan de maneras a veces poco intuitivas.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Flujo de trabajo básico: refinando el modelo</span>"
    ]
  },
  {
    "objectID": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "href": "02-flujo-basico-2.html#prevalencia-con-datos-de-referencia",
    "title": "3  Flujo de trabajo básico: refinando el modelo",
    "section": "3.2 Prevalencia con datos de referencia",
    "text": "3.2 Prevalencia con datos de referencia\nAhora haremos un paso adicional: los valores de sensibilidad y especificidad generalmente no son conocidos con certeza, sino que son estimados a partir de una muestra de “estándar de oro”. En esta prueba particular, el kit identificó correctamente como positivos a 103 de 122 personas infectadas, e identificó correctamente como negativos a 399 de 401 personas no infectadas. Consideraremos 122 y 401 como tamaños de muestra fijos y conocidos (las personas fueron extraídas de otra población).\nDenotamos como \\(Ref\\) a los datos de referencia de “estándar de oro”.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    theta [label = &lt;&theta;&gt;]\n    esp\n    sens\n    Npos [label = &lt;N&lt;SUB&gt;+&lt;/SUB&gt;&gt;]\n  node [shape=plaintext]\n    Nobs [label = &lt;N&lt;SUB&gt;obs&lt;/SUB&gt;&gt;]\n   # Nneg [label = &lt;N&lt;SUB&gt;-&lt;/SUB&gt;&gt;]\n  edge [minlen = 3]\n    theta -&gt; Npos\n    #p -&gt; Nneg\n    N -&gt; Npos\n    Npos -&gt; Nobs\n    #N -&gt; Nneg\n    esp -&gt; Nobs\n    sens -&gt; Nobs\n    #esp -&gt; Nneg\n    #sens -&gt; Nneg\n    esp -&gt; Ref\n    sens -&gt; Ref\n{ rank = same; theta; N }\n#{ rank = same; Npos; Nneg}\n{ rank = max; sens; esp}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nUsando argumentos como los del modelo original, las distribuciones de esp y sens son beta y podemos incorporarlas en la simulación de la posterior. Nuestra nueva función para simular el proceso generativo es:\n\nsim_pos_neg &lt;- function(p = 0.01, N = 20, pos_gold = c(103,122), neg_gold = c(399,401)) {\n  # Simular especificidad y sensibilidad\n  sens &lt;- rbeta(1, pos_gold[1] + 1, pos_gold[2] - pos_gold[1] + 1)\n  esp &lt;- rbeta(1, neg_gold[1] + 1, neg_gold[2] - neg_gold[1] + 1)\n  # verdaderos positivos que capturamos en la muestra\n  Pos_verdadero &lt;- rbinom(N, 1, p)\n  Neg_verdadero &lt;- 1 - Pos_verdadero\n  # positivos observados en la muestra: si es positivo, calculamos\n  # la probabilidad de que realmente sea positivo\n  sim_tbl &lt;- tibble(Pos_verdadero, Neg_verdadero) |&gt; \n    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |&gt; \n    mutate(Neg = 1 - Pos)\n  # Observaciones\n  sim_tbl |&gt; select(Pos, Neg)\n}\n\nConsiderando que tenemos tres parámetros, en este punto decidimos no hacer la aproximación de rejilla. Es posible hacer otro tipo de aproximaciones (por ejemplo cuadráticas), pero en lugar de esto veremos cómo lo haríamos con Stan. Más adelante discutiremos los algoritmos que Stan utiliza para simular de la posterior de modelos muy generales. Por el momento, notamos que está basado en un algoritmo de simulación MCMC (Markov Chain Montecarlo), que es el estándar para modelos que no son muy simples. Este ejemplo es para ilustrar cómo resolveríamos el problema más general, no es necesario que en este punto entiendas cómo funciona o los detalles de la implementación.\n\nlibrary(cmdstanr)\nmod_sc &lt;- cmdstan_model(\"./src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n;\n  int&lt;lower=0&gt; kit_pos;\n  int&lt;lower=0&gt; n_kit_pos;\n  int&lt;lower=0&gt; kit_neg;\n  int&lt;lower=0&gt; n_kit_neg;\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; //seroprevalencia\n  real&lt;lower=0, upper=1&gt; sens; //sensibilidad\n  real&lt;lower=0, upper=1&gt; esp; //especificidad\n}\n\ntransformed parameters {\n  real&lt;lower=0, upper=1&gt; prob_pos;\n\n  prob_pos = theta * sens + (1 - theta) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  theta ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\n\nn &lt;- 50\nN &lt;- 3300\ndatos_lista &lt;- list(N = 3300, n = 50,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean      q5    q95\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 theta    0.0104 0.00224 0.0180\n\n\nY podemos graficar la posterior de la seroprevalencia:\n\nggplot(sims, aes(x = theta)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY vemos que los datos son consistentes con el dato reportado por los autores (alrededor de 1.2%), pero que no podemos excluir valores de prevalencia muy bajos (por abajo de 0.3% por ejemplo). Por otro lado, también son consistentes valores muy altos de seroprevalencia, de manera que este estudio resultó ser poco informativo de la IFR del COVID.\nPodemos hacer diagnósticos adicionales acerca de la razón de esta variabilidad alta, si graficamos la relación entre especificidad de la prueba y estimación de prevalencia:\n\nggplot(sims, aes(x = esp, y = theta)) + geom_point() +\n  xlab(\"Especificidad del kit\") + ylab(\"Prevalencia\") + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nLa asociación entre estas dos cantidades es interesante porque conceptualmente (y desde punto de vista del modelo), no hay relación entre estas dos variables: su asociación aparece porque son causas que compiten para explicar una observación.\nNótese que dada la prevalencia baja, la especificidad del kit es un factor importante para explicar la prevalencia observada, pero si no pensamos con cuidado podríamos concluir que los falsos positivos no deberían ser problema por que la especificidad para ser muy buena.\nY notamos que aún con una muestra relativamente grande, el rango de \\(\\theta\\) es considerable: va desde valores cercanos a 0 hasta valores alrededor de 0.025-0.03.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Flujo de trabajo básico: refinando el modelo</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html",
    "href": "03-modelos-genericos.html",
    "title": "4  Componentes de modelación 1",
    "section": "",
    "text": "4.1 Predicciones sin explicación\nEn esta sección veremos las primeras componentes que podemos utilizar para hacer modelación, en particular regresión lineal y logística. Lo haremos en el contexto de nuestro flujo de trabajo que incluye establecer claramente un modelo causal.\nEs posible obtener buenas predicciones con modelos estadísticos genéricos sin tener una explicación de cómo funciona el fenómeno que estamos modelando. Estos modelos, aunque pueden resultar en predicciones muy buenas y ser útiles, pueden ser riesgosos si se interpretan fuera de un contexto teórico con supuestos claros.\nEl primer ejemplo es de nuestra referencia de McElreath (2020): los epicilos planetarios del modelo geocéntrico para explicar el movimiento retrógrado de planetas en el cielo. Este modelo fue exitoso y muy preciso para calcular las posiciones futuras de los planetas en el cielo, pero sus fundamentos eran incorrectos: no es posible interpretar este modelo por sí solo para entender cómo funciona el sistema solar.\nModelos genéricos como regresión lineal o logística, métodos basados en árboles, redes neuronales típicamente caen en esta categoría de modelos de tipo “geocéntrico”: aunque pueden ser efectivos para predecir, debemos ser cuidadosos en su interpretación en términos de causas, efectos, y mecanismos del fenómeno que nos interesa.\nPodemos aplicar con éxito estas componentes de modelación si entendemos su papel: estos modelos genéricos no contienen o nos dan causas o mecanismos por sí solos, pero pueden ayudarnos extraer información causal bajo los supuestos apropiados.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#ejemplo-regresión-lineal",
    "href": "03-modelos-genericos.html#ejemplo-regresión-lineal",
    "title": "4  Componentes de modelación 1",
    "section": "4.2 Ejemplo: regresión lineal",
    "text": "4.2 Ejemplo: regresión lineal\nEn este ejemplo, introducimos notación para representar modelos, usaremos posteriores con varios parámetros, y veremos cómo construir y aplicar modelos lineales, todo desde el punto de vista de nuestro flujo de trabajo.\nEn este ejemplo de McElreath (2020) queremos describir la relación entre peso y estatura de adultos de una población relativamente homogénea. Nuestro modelo causal es como sigue:\n\nEn primer lugar, la estatura (\\(H\\)) de las personas adultas influye en su peso (\\(W\\)). El peso, está influenciado también por otras variables no observadas:\n\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    U\n  node [shape=plaintext]\n    H\n    W\n  edge [minlen = 3]\n    H -&gt; W\n    U -&gt; W\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nNótese que no consideramos \\(W\\to H\\), porque podemos pensar en varias intervenciones que podrían cambiar el peso por no cambian la estatura. Por otro lado, es difícil pensar en alguna intervención que cambie la estatura pero no cambie el peso de una persona. Adicionalmente, hay otros factores desconocidos no observados \\(U\\) que afectan el peso de cada persona adicionalmente a su estatura.\nAhora pasamos la modelo generativo. Supondremos que el peso de una persona adulta depende de su estatura de manera lineal, de forma que podemos escribir:\n\\[W = \\alpha + \\beta H + U\\] Como \\(U\\) no es observada, tenemos que definir cómo generar esta variable. Una distribución natural para esta variable es una distribución normal con media 0 y desviación estándar \\(\\sigma\\) no conocida, que escribimos como \\(U\\sim N(0,\\sigma)\\). Tenemos entonces que dados los valores \\(\\alpha\\) y \\(\\beta\\),\n\\[E[W|H] = \\alpha + \\beta H,\\] así que el valor esperado del peso de una persona, dada su estatura, es una función lineal de la estatura. La variable \\(U\\) representa la variabilidad en peso alrededor de este valor esperado. Usamos la distribución normal considerando que es una agregación de varias perturbaciones pequeñas, no relacionadas con estatura, que afectan el peso de una persona (aunque este supuesto también tiene que validarse).\nAdicionalmente, tenemos que hacer supuestos acerca del proceso generador para la estatura \\(H\\). Por el momento, y para ejemplificar, supondremos que la estatura es una variable normal con media en 160 cm y desviación estándar de 10cm.\nEmpezamos a escribir nuestro modelo generativo:\n\nsim_peso &lt;- function(n= 10, alpha, beta, sigma){\n  # simular estatura\n  H &lt;- rnorm(n, 160, 10)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- alpha + beta * H + U\n  tibble(H, W)\n}\n\nPodemos checar nuestro modelo generativo con simulaciones predictivas a priori: generamos una muestra y checamos con el conocimiento del área:\n\nset.seed(9)\nsim_peso(100, alpha = 0, beta = 0.5, sigma = 5) |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\")\n\n\n\n\n\n\n\n\nPodemos escribir este generativo siguiendo el código de la función de arriba. Si cada persona la denotamos por un índice \\(i\\) entonces:\n\\[\n\\begin{align}\nW_i &= \\alpha + \\beta H_i + U_i \\\\\nU_i &\\sim N(0,\\sigma) \\\\\nH_i &\\sim N(160, 10)\n\\end{align}\n\\] De lado izquierdo están las variables, del lado derecho las definiciones, igualdad significa una relación determinística y \\(\\sim\\) significa “se distribuye como”.\nAhora podemos plantear nuestra pregunta inicial en términos de este modelo: nos interesa describir cómo cambia el peso esperado de una persona dependiendo de su estatura, es decir, describir la recta\n\\[ \\alpha + \\beta H\\] Con esto hemos terminado los primeros paso de nuestro flujo (modelo causal, modelo generativo, cantidad a estimar).\nNuestro método de estimación es bayesiano, así que podemos ser más específicos y decir que nos interesa la distribución posterior de \\(\\alpha,\\beta\\) dado datos observados. Otra manera de decir esto es que nos interesa describir la posterior de la recta \\(\\alpha + \\beta H\\).\nNótese en particular que en este ejemplo no nos interesa el proceso generador de \\(H\\), y dado nuestro diagrama causa, podemos considerar el análisis condicional a los valores que observamos de estatura.\nAhora podemos plantear nuestra estrategia de modelación estadística. Tenemos tres parámetros desconocidos \\(\\alpha,\\beta,\\sigma\\), y tenemos por la regla de bayes la posterior está dada por:\n\\[p(\\alpha,\\beta,\\sigma|W_i,H_i)\\propto p(W_i|H_i, \\alpha,\\beta,\\sigma)p(\\alpha,\\beta,\\sigma)\\] De modo que sólo nos interesa entender como es el peso condicional a la estatura, y por eso nuestra verosimilitud sólo considera \\(W_i\\) condicional a \\(H_i\\) (desde el punto de vista del diagrama, nos interesa modelar el nodo \\(W\\). En otros casos, quizá buscaríamos modelar la distribución conjunta de \\(W_i,H_i\\).\nAhora tenemos que poner distribuciones a priori \\(p(\\alpha, \\beta,\\sigma)\\) para los parámetros desconocidos, y continuar con nuestro flujo de modelación haciendo verificaciones a priori.\n\n\n\n\n\n\nDistribuciones a priori\n\n\n\nLa propuesta de distribuciones a priori depende de manera cercana de nuestras verificaciones, como veremos más adelante. En general no existen distribuciones a priori “correctas”, sino justificables desde el punto de vista del conocimiento del área.\nLos chequeos a priori nos permite entender las consecuencias de nuestras decisiones acerca de las iniciales. Nótese que todo este trabajo se hace antes de ver los datos, lo que implica que no estamos buscando “sacar el resultado que queremos” de los datos.\n\n\n\n4.2.1 Distribuciones a priori\nEn primer lugar, haremos este trabajo más fácil si parametrizamos la recta de regresión de la siguiente manera, donde restamos a la estatura un valor típico de la distribución de estaturas (también puede usarse la media los datos, más comunmente, pero en este ejemplo tomamos un valor fijo para simplificar la explicación):\n\\[E[W|H] =  \\alpha + \\beta (H - 160)\\]\nLas apriori o iniciales expresan conocimiento del área (incluyendo las unidades que se están utilizando), y actúan como restricciones suaves. Supondremos que peso está en kilogramos y estatura en centímetros.\n\nCuando \\(H=160\\) esperamos que \\(W\\) esté alrededor de 50-70 kg, así que podemos centrar \\(\\alpha\\) en 60. Las unidades de \\(\\alpha\\) son kg. Una inicial (verificaremos dentro de un momento esa decisión) puede ser \\(\\alpha\\sim N(60, 10)\\). Recordemos que esto implica que \\(\\alpha\\) están dentre 60 - 2(10) = 40 y 60 + 10(2) = 80 con probabilidad 0.95, lo cual es considerable pero no excesivamente amplio para una persona de estatura 160cm.\nSi \\(\\alpha\\) es está alrededor de 60, la constante de proporcionalidad \\(\\beta\\) debe ser positiva, y no muy lejana de un valor entre 0 y 2. La razón es que no tiene sentido esperar que un aumento de 10 cm tenga un aumento esperado de peso de 30 kilos, por ejemplo. Podríamos poner una inicial como \\(\\beta\\sim N^+(0, 1)\\) (normal truncada en 0) por ejemplo. Esta distribución tiene los siguientes percentiles:\n\n\nquantile(rnorm(10000, 0, 1) |&gt; abs(), probs = seq(0, 1, 0.1)) |&gt; \n  round(3)\n\n   0%   10%   20%   30%   40%   50%   60%   70%   80%   90%  100% \n0.000 0.124 0.251 0.383 0.518 0.673 0.839 1.032 1.269 1.618 3.818 \n\n\nFinalmente, tenemos que poner una inicial para \\(\\sigma\\). Debe ser positiva, y representa la variabilidad que hay en el peso que no se debe a la estatura. Una inicial razonable es \\(\\sigma\\sim N^+(0, 20)\\), por ejemplo.\nQuedamos entonces con:\n\\[\n\\begin{align}\nW_i &= \\alpha + \\beta (H_i - 160) + U_i \\\\\nU_i &\\sim N(0,\\sigma) \\\\\n\\alpha &\\sim N(60, 10) \\\\\n\\beta &\\sim N^+(0, 1) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\]\n\n\nChequeo predictivo a priori\nAhora podemos simular de la a priori cuáles son las posibilidades que estamos considerando. Utilizaremos valores razonables simulados de \\(H\\) para hacer el análisis.\n\nsim_peso_mod &lt;- function(n= 10){\n  alpha &lt;- rnorm(1, 60, 10)\n  beta &lt;- rnorm(1, 0, 1) |&gt; abs()\n  sigma &lt;- rnorm(1, 0, 20) |&gt; abs()\n  \n  # simular estaturas y pesos\n  H &lt;- rnorm(n, 160, 10)\n  mu_W = alpha + beta * (H - 160)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- mu_W + U\n  tibble(alpha, beta, sigma, H, W)\n}\n\nY hacemos varias replicaciones:\n\nsims_tbl &lt;- map_df(1:20, function(rep) {\n  sim_peso_mod(100) |&gt; mutate(rep = rep)\n})\n\nNuestros supuestos actuales se ven como sigue:\n\nsims_tbl |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  geom_abline(aes(intercept = alpha - 160 * beta, slope = beta), data = sims_tbl, color = \"red\") +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\") +\n  facet_wrap(~rep)\n\n\n\n\nSimulaciones predictivas a priori\n\n\n\n\nObservación: Esto parece ser razonable, aunque algunas replicaciones son algo extremas (muy poca variabilidad de peso, una relación muy débil o muy fuerte entre estatura y peso). Comenzaremos con este modelo y seguiremos explorando sus consecuencias.\nNótese que en esta situación, un punto de vista que aparentemente es “conservador” en efecto pone peso en resultados que son infactibles del todo. Por ejemplo, si pusiéramos \\(\\beta\\sim N^+(0,100)\\) y \\(\\sigma\\sim N^+(0, 1000)\\), bajo el argumento de que no tenemos información acerca de \\(\\beta\\) o \\(\\sigma\\), obtendríamos:\n\n\nCódigo\nsim_peso_mod_mal &lt;- function(n= 10){\n  alpha &lt;- rnorm(1, 60, 10)\n  beta &lt;- rnorm(1, 0, 100) |&gt; abs()\n  sigma &lt;- rnorm(1, 0, 1000) |&gt; abs()\n  \n  # simular estaturas y pesos\n  H &lt;- rnorm(n, 160, 10)\n  mu_W = alpha + beta * (H - 160)\n  # simular perturbación de peso\n  U &lt;- rnorm(n, 0, sigma)\n  # regresión lineal de peso dado estatura\n  W &lt;- mu_W + U\n  tibble(alpha, beta, sigma, H, W)\n}\nsims_mal_tbl &lt;- map_df(1:20, function(rep) {\n  sim_peso_mod_mal(100) |&gt; mutate(rep = rep)\n})\nsims_mal_tbl |&gt; \n  ggplot(aes(x = H, y = W)) +\n  geom_point() +\n  geom_abline(aes(intercept = alpha - 160 * beta, slope = beta), data = sims_mal_tbl, color = \"red\") +\n  labs(x = \"Estatura (cm)\", y = \"Peso (kg)\") +\n  facet_wrap(~rep)\n\n\n\n\n\nModelo no realista\n\n\n\n\nEsta es una prueba inicial fallida. Regresaremos a este ejemplo más adelante. En este ejemplo particular que es muy simple y como veremos no es grave permitir algunos resultados algo extremos.\n\n\n\n\n\n\nTip\n\n\n\nEs riesgoso permitir valores de las apriori que no son consistentes con el conocimiento del área. Cuando tenemos muchos datos y relativamente pocos parámetros no es muy importante, pero conforme vayamos avanzando veremos que utilizar supuestos no realistas (como distribuiciones no informativas para los parámetros) tiene consecuencias considerables.\n\n\n\n\nModelo en Stan\nAunque en este punto es posible todavía hacer una aproximación por rejilla (sólo tenemos tres parámetros), escribiremos el modelo en Stan y simularemos de la posterior con MCMC (recuerda que más tarde explicaremos este proceso).\n\nNuestro objetivo ahora es calcular la posterior bajo los supuestos de arriba para datos generados de nuestro modelo, y ver si los cálculos funcionan apropiadamente.\n\nEl modelo en Stan se puede escribir como sigue:\n\nlibrary(cmdstanr)\nmod_peso &lt;- cmdstan_model(\"./src/peso-estatura-1.stan\")\nprint(mod_peso)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  h;\n  vector[N]  w;\n}\n\nparameters {\n  real alpha;\n  real &lt;lower=0&gt; beta;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] w_media;\n  // determinístico dado parámetros\n  w_media = alpha + beta * (h - 160);\n}\n\nmodel {\n  // partes no determinísticas\n  w ~ normal(w_media, sigma);\n  alpha ~ normal(60, 10);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 20);\n}\n\n\nUna vez que escribimos nuestro modelo, hacemos nuestra siguiente verificación a priori: dados los supuestos del modelo generativo, ¿nuestro estimador funciona apropiadamente para responder la pregunta de interés?\nUtilizaremos una muestra de 350 personas simulada de nuestro proceso generador de datos. En cada caso, buscamos correr nuestro modelo y checar que nuestra estimación de la recta de regresión es consistente con los valores que utilizamos para generar los datos.\n\nset.seed(881)\nsims_inicial_check_tbl &lt;- map_df(1:10, function(rep) {\n  sim_peso_mod(352) |&gt; mutate(rep = rep)\n}) |&gt; nest(datos_sim = c(H, W))\nsims_tbl\n\n# A tibble: 2,000 × 6\n   alpha  beta sigma     H     W   rep\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n 1  61.0 0.203  22.9  165.  37.1     1\n 2  61.0 0.203  22.9  176.  52.4     1\n 3  61.0 0.203  22.9  154.  37.2     1\n 4  61.0 0.203  22.9  162.  70.2     1\n 5  61.0 0.203  22.9  156.  22.5     1\n 6  61.0 0.203  22.9  158.  54.8     1\n 7  61.0 0.203  22.9  173.  77.1     1\n 8  61.0 0.203  22.9  174.  56.9     1\n 9  61.0 0.203  22.9  150.  41.4     1\n10  61.0 0.203  22.9  150.  41.6     1\n# ℹ 1,990 more rows\n\n\nEn la siguiente gráfica vemos un comportamiento razonable de nuestro proceso de estimación. Recuerda que cada punto negro representa una simulación de la posterior, y el punto rojo es el valor que usamos para hacer la simulación de cada recuadro:\nOjo: los ejes de los recuadros varían con la simulación\n\n# fig-cap: Posterior para datos simulados\ndatos_check_tbl &lt;- sims_inicial_check_tbl |&gt; \n  select(rep, post_tbl) |&gt; \n  unnest(post_tbl)\nggplot(datos_check_tbl, aes(x = alpha, y = beta)) +\n  geom_point(alpha = 0.2) +\n  labs(x = \"alpha\", y = \"beta\") +\n  geom_point(data = sims_inicial_check_tbl, color = \"red\", size = 3) +\n  facet_wrap(~ rep, scales = \"free\") \n\n\n\n\n\n\n\n\nEsta gráfica también podemos hacerla como sigue, usando rectas:\n\n# nota: el intercept en geom_abline es la ordenada al origen\n# mientras que la alpha es valor de la recta para h = 160\ndatos_check_tbl |&gt; \n  ggplot() +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              alpha = 0.5, colour = \"gray\") +\n  facet_wrap(~ rep, scales = \"free\") +\n  scale_x_continuous(limits = c(130, 200)) + \n  scale_y_continuous(limits = c(0, 200)) +\n  geom_abline(data = sims_inicial_check_tbl, \n    aes(intercept = alpha - beta * 160, \n      slope = beta), color = \"red\", linewidth = 1.05)\n\n\n\n\n\n\n\n\nEsta prueba computacional tiene buenos resultados: en general, la posterior se concentra alrededor del valor verdadero de cada simulación. Ahora podemos proceder a cargar los datos reales y hacer una simulación de la posterior.\n\n\n4.2.2 Ajustando el modelo a los datos reales\nCargamos los datos y producimos simulaciones de la posterior.\n\nset.seed(81)\ndatos_tbl &lt;- read_delim(\"../datos/Howell1.csv\", delim = \";\") |&gt; \n  filter(age &gt;= 18)\n\nRows: 544 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): height, weight, age, male\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndata_list &lt;- list(\n  N = nrow(datos_tbl),\n  h = datos_tbl$height,\n  w = datos_tbl$weight\n)\n# correr modelo en Stan\nmod_peso_ajuste &lt;- mod_peso$sample(\n  data = data_list,\n  iter_sampling = 2000,\n  refresh = 0)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.3 seconds.\nChain 2 finished in 0.3 seconds.\nChain 3 finished in 0.3 seconds.\nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.7 seconds.\n\n\nLa posterior de los parámetros de la recta se ve como siguen:\n\nsims_peso_post_tbl &lt;- mod_peso_ajuste |&gt; \n  as_draws_df() |&gt; \n  select(.draw, alpha, beta, sigma) \n\n\nggplot(sims_peso_post_tbl)+\n  geom_point(aes(x = alpha, y = beta)) \n\n\n\n\n\n\n\n\nY un resumen simple está dado por:\n\nmod_peso_ajuste$summary(c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  mutate(across(where(is.numeric),  ~ round(.x, 2)))\n\n# A tibble: 3 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 alpha    48.4   48.4   0.28  0.28 47.9  48.9      1    5122.    5333.\n2 beta      0.63   0.63  0.03  0.03  0.58  0.68     1    4983.    4992.\n3 sigma     4.26   4.25  0.17  0.16  3.99  4.55     1    5383.    4946.\n\n\n\n\n\n\n\n\nSimulaciones conjuntas\n\n\n\nObserva que los resúmenes marginales (variable por variable) no cuentan la historia completa de la posterior. En nuestro ejemplo, \\(\\alpha\\) y \\(\\beta\\) están correlacionadas en la posterior como muestra la gráfica anterior. Por eso cuando queremos calcular resúmenes de cantidades en las que influyen varios parámetros, es importante trabajar con las simulaciones conjuntas de los parámetros.\n\n\nPuedes ver que en realidad no es posible calcular la distribución de cantidades como \\(\\alpha + 10\\beta\\), por ejemplo, a partir de la información de la tabla de arriba: por ejemplo, la varianza de esta suma no es simplemente la suma de las varianzas",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#distribución-predictiva-posterior",
    "href": "03-modelos-genericos.html#distribución-predictiva-posterior",
    "title": "4  Componentes de modelación 1",
    "section": "4.3 Distribución predictiva posterior",
    "text": "4.3 Distribución predictiva posterior\nDado nuestro modelo, ahora podemos generar cómo se verían observaciones nuevas: en este caso, si tuviéramos una estatura, ¿cómo sería el peso de esa persona? Para esto tenemos que tener en cuenta tanto la posterior de los parámetros como el modelo de los datos.\nEn primer lugar, la posterior de la relación lineal es (cada línea de esta gráfica es una simulación de la posterior):\n\nggplot(sims_peso_post_tbl) +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              colour = \"gray\", alpha = 0.1) +\n  scale_x_continuous(limits = c(130, 180)) +\n  scale_y_continuous(limits = c(20, 70)) \n\n\n\n\n\n\n\n\nEsto nos indican los valores esperados para estatura. Para la predictiva posterior, también tenemos que considerar dónde pueden aparecer individuos. Para simular a una estatura fija, por ejemplo, hacemos lo sugiente:\n\nsim_pred_post &lt;- function(n, sims_peso_post_tbl, h) {\n  # extraer parámetros de la posterior\n  pars &lt;- slice_sample(sims_peso_post_tbl, n = n, replace = TRUE) \n  # simular pesos\n  sims_tbl &lt;- map_df(h, function(h){\n    w_media &lt;- pars$alpha + pars$beta * (h - 160)\n    w &lt;- rnorm(n, w_media, pars$sigma)\n    tibble(rep = 1:n, h = h, w_media = w_media, w = w)\n  })\n  sims_tbl\n}\n\nLas predictivas posteriores para las estaturas \\(h = 160\\) y \\(h=150\\) son:\n\ncomp_ppost_tbl &lt;- sim_pred_post(5000, sims_peso_post_tbl, c(150, 160))\nggplot(comp_ppost_tbl, aes(x =  w, fill = factor(h))) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") \n\n\n\n\n\n\n\n\nque como vemos presentan variabilidad considerable más allá de la diferencia de valores esperados. Podemos calcular por ejemplo cuál es la probabilidad de que una persona de 150 cm sea más alta que una de 170 cm:\n\ncomp_ppost_tbl |&gt; \n  select(-w_media) |&gt; \n  pivot_wider(names_from = h, values_from = w) |&gt; \n  summarise(prop = mean(`150` &gt; `160`))\n\n# A tibble: 1 × 1\n   prop\n  &lt;dbl&gt;\n1 0.141\n\n\nY también es más útil calcular la distribución de la diferencia de pesos entre personas de 150 y 160 cm:\n\ncomp_ppost_tbl |&gt; \n  select(-w_media) |&gt; \n  pivot_wider(names_from = h, values_from = w) |&gt; \n  mutate(diferencia = `160` - `150`) |&gt; \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") +\n  labs(x = \"Diferencia de pesos 160 - 150cm\")\n\n\n\n\n\n\n\n\nEn contraste, si comparamos las estaturas medias de cada grupo, que no incluyen variabilidad individual más allá de la producida por la estatura:\n\nggplot(comp_ppost_tbl, aes(x =  w_media, fill = factor(h))) +\n  geom_histogram(bins = 100, alpha = 0.5, position = \"identity\") +\n  labs(x = \"Media de pesos\")\n\n\n\n\n\n\n\n\nPrácticamente tenemos seguridad que la media de pesos de los individuos de 150 cm es menor que la de los de 160 cm.\n\n\n\n\n\n\nTip\n\n\n\nEs importante no confundir el contraste a nivel individuo que hicimos arriba, y el que hicimos a nivel de medias de grupos. Los grupos tienen claramente medias diferentes, pero las distribuciones de individuos tienen traslape considerable.\n\n\nPodemos también resumir la distribución predictiva para distintas estaturas:\n\nresumen_ppost_tbl &lt;- sim_pred_post(20000, sims_peso_post_tbl, \n                                   h = seq(130, 180, 2.5)) |&gt; \n  group_by(h) |&gt; \n  summarise(q5 = quantile(w, 0.05), \n            q95 = quantile(w, 0.95),\n            q_media_5 = quantile(w_media, 0.05),\n            q_media_95 = quantile(w_media, 0.95)) \n\nEn nuestra gráfica anterior tendríamos entonces nuestra recta junto con rangos de 90% para la estatura de los individuos:\n\nggplot(sims_peso_post_tbl) +\n  geom_abline(aes(intercept = alpha - beta * 160, slope = beta),\n              colour = \"gray\", alpha = 0.01) +\n  scale_x_continuous(limits = c(130, 180)) +\n  scale_y_continuous(limits = c(10, 80)) + \n  geom_ribbon(data = resumen_ppost_tbl,\n    aes(x = h, ymin = q_media_5, ymax = q_media_95),\n      fill = NA, colour = \"gray\") + \n  geom_ribbon(data = resumen_ppost_tbl,\n    aes(x = h, ymin = q5, ymax = q95), fill = NA, colour = \"red\")\n\n\n\n\n\n\n\n\n\n4.3.1 Verificaciones de predictiva posterior\nAdemás de ser útil para calcular cantidades de interés de manera natural, la predictiva posterior también está sujeta a crítica y validación. Veremos más de este punto, pero la idea básica es la siguiente:\n\n\n\n\n\n\nVerificaciones de predictiva posterior\n\n\n\nUna vez que tenemos la posterior dados los datos:\n\nTomamos una simulación de todos los parámetros del modelo.\nSimulamos nuevas observaciones (una muestra del mismo tamaño) a partir de los parámetros simulados.\nComparamos los datos simulados con los datos observados (gráficas u otros resúmenes apropiados).\nRepetimos para varias simulaciones.\n\nDiferencias sistemáticas entre datos observados y datos simulados de la predictiva posterior indican fallas del modelo o áreas donde puede mejorar.\n\n\nHay muchas variaciones de este tipo de verificaciones. En nuestro caso podemos hacer manualmente este proceso una vez que tenemos simulaciones de la posterior, tomando las mismas estaturas de los datos y simulando datos del modelo para el peso.\n\nsims_check_post &lt;- sim_pred_post(10, sims_peso_post_tbl, \n                                 h = datos_tbl$height) |&gt; \n  select(-w_media)\nsims_check_post &lt;- bind_rows(sims_check_post, \n   datos_tbl |&gt; mutate(rep = 11) |&gt; select(rep, h = height, w = weight)) |&gt; \n  mutate(rep = digest::digest2int(as.character(rep), seed = 992)) \nggplot(sims_check_post) +\n  geom_point(aes(x = h, y = w), alpha = 0.2) + facet_wrap(~ rep)\n\n\n\n\n\n\n\n\n¿Puedes reconocer dónde están los datos? Si hay desajustes graves y sistemáticas, deberías poder detectarlos en una gráfica de este tipo. Veremos más de este tipo de verificaciones en el curso.\n\n# Respuesta\ndigest::digest2int(\"11\", seed = 992)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#ampliando-el-modelo",
    "href": "03-modelos-genericos.html#ampliando-el-modelo",
    "title": "4  Componentes de modelación 1",
    "section": "4.4 Ampliando el modelo",
    "text": "4.4 Ampliando el modelo\nEntre los adultos humanos, hombres y mujeres tienen distintas distribuciones de peso y estatura. La variable \\(S\\) (sexo) influye tanto en estatura como en peso. La relación la consideramos causalmente partiendo en \\(S\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    U\n    V\n    Z\n  node [shape=plaintext]\n    H\n    W\n    S\n  edge [minlen = 3]\n    H -&gt; W\n    U -&gt; W\n    S -&gt; H\n    S -&gt; W\n    V -&gt; H\n    Z -&gt; S\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nOmitiendo del diagrama las variables no observadas que también son causas únicamente de \\(S\\) y \\(W, H\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n  \n  node [shape=plaintext]\n    H\n    W\n    S\n  edge [minlen = 3]\n    H -&gt; W\n    S -&gt; H\n    S -&gt; W\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nSi queremos saber cómo influye el sexo en el peso, este diagrama indica que hay dos tipos de preguntas que podemos hacer:\n\n¿Cuál es el efecto causal de \\(S\\) sobre \\(W\\) (efecto total) ?\n¿Cuál es el efecto causal directo de \\(S\\) sobre \\(W\\)? Es decir, que no actúa a través de \\(H\\).\n\nAunque tenemos un solo modelo causal, pueden construirse distintos modelos estadísticos para contestar cada pregunta, y cada pregunta exigirá que se cumplan ciertas condicines en nuestro modelo gráfico. El modelo causal nos dice que si no tenemos causas comunes de \\(S\\) y \\(H\\) y \\(W\\), entonces podemos estimar el efecto total de \\(S\\) sobre \\(W\\) (esto lo formalizaremos más adelante).\nEmpezamos con el efecto total. Para esto, podemos usar el modelo lineal e ignorar la estatura, donde \\(S_i=2\\) si el individuo \\(i\\) es hombre y \\(S_i=1\\) si el individuo \\(i\\) es mujer.\n\\[\n\\begin{align}\nW_i &\\sim N(\\alpha_{S_i}, \\sigma)\\\\\n\\alpha_1,\\alpha_2 &\\sim N(60, 10) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\] Nótese que tenemos dos posibles medias para el peso, una para hombres y otra para mujeres. La estatura no nos importa porque la pregunta es acerca del efecto total de sexo sobre estatura. Para las iniciales podemos seguir un argumento similar al de arriba.\nNota: esta parametrización es más conveniente que utilizar un indicador (o dummy) de sexo en términos de interpetación y en términos de poner iniciales acordes con el conocimiento del área, aunque estadísticamente son equivalentes.\nEl modelo generador simplificado para este caso puede ser:\n\nsim_peso_mod_s &lt;- function(S, alpha, sigma){\n  n &lt;- length(S)\n  W &lt;- rnorm(n, alpha[S], sigma)\n  tibble(alpha_1 = alpha[1], alpha_2 = alpha[2], \n         sigma, S = S, W = W)\n}\n\nDado este modelo generador, ¿cuál es el efecto causal de sexo? Tenemos que definir esta cantidad en términos del modelo. En nuestro caso, definiremos el efecto causal promedio sobre la población, que definimos como la diferencia promedio de estaturas de dos poblaciones: una compuesta enteramente por hombres y otra por mujeres.\n\nset.seed(2021)\n# Fjamos mismos valores de los parámetros para simular dos\n# poblaciones\nsim_hombres &lt;-  sim_peso_mod_s(rep(2, 1000), c(55, 70), 10)\nsim_mujeres &lt;-  sim_peso_mod_s(rep(1, 1000), c(55, 70), 10)\nmean(sim_hombres$W - sim_mujeres$W)\n\n[1] 14.75203\n\n\n\nVerificación a priori\nAhora generamos una población con estos parámetros y vemos si podemos recuperar el efecto causal promedio sobre la población. Nuestro modelo es como definimos arriba:\n\nlibrary(cmdstanr)\nmod_peso &lt;- cmdstan_model(\"./src/peso-estatura-2.stan\")\nprint(mod_peso)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  w;\n  array[N] int s;\n}\n\nparameters {\n  array[2] real alpha;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n\n}\n\nmodel {\n  // modelo para peso\n  w ~ normal(alpha[s], sigma);\n  // también se puede escribir como\n  // for (i in 1:N) {\n  //   w[i] ~ normal(alpha[s[i]], sigma);\n  // }\n  // iniciales\n  alpha ~ normal(60, 10);\n  sigma ~ normal(0, 20);\n}\n\n\nSimulamos datos y ajustamos el modelo, usando los mismos parámetros fijos:\n\nS_sim &lt;- sample(c(1,2), 1000, replace = TRUE)\ndatos_sim_tbl &lt;- sim_peso_mod_s(S_sim, c(55, 70), 10)\n\n\nmod_2_fit &lt;- mod_peso$sample(\n  data = list(N = nrow(datos_sim_tbl), \n              s = datos_sim_tbl$S, \n              w = datos_sim_tbl$W),\n  refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nmod_2_fit$summary(c(\"alpha\", \"sigma\"))\n\n# A tibble: 3 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 alpha[1] 55.0   54.9  0.439 0.440 54.2   55.7  1.00    4382.    2860.\n2 alpha[2] 70.9   70.9  0.442 0.434 70.2   71.6  1.00    4265.    3176.\n3 sigma     9.76   9.75 0.225 0.227  9.40  10.1  1.00    3850.    2282.\n\n\nNótese que la diferencia de medias poblacionales es de alrededor de 15 kg, que es lo que esperábamos según el cálculo de arriba. Podemos replicar el cálculo que hicimos arriba directamente usando simulación:\n\nPara cada simulación de la posterior calculamos una población hipotética de hombres y otras de mujeres (mismos parámetros)\nCalculamos la diferencia de medias poblacionales\nResumimos con la posterior.\n\nEsto es fácil hacerlo directamente en Stan, pero en este ejemplo lo calcularemos manualmente:\n\nsims_post_tbl &lt;- mod_2_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\nsimular_diferencia_post &lt;- function(sims_post_tbl){\n  # Simulamos parámetros de la posterior\n  pars &lt;- sample_n(sims_post_tbl, 1) |&gt; \n    select(starts_with(\"alpha\"), sigma)\n  # Simulamos datos\n  sims_hombres &lt;- sim_peso_mod_s(rep(2, 1000), \n      alpha = c(pars$`alpha[1]`, pars$`alpha[2]`), pars$sigma)\n  sims_mujeres &lt;- sim_peso_mod_s(rep(1, 1000), \n      c(pars$`alpha[1]`, pars$`alpha[2]`), pars$sigma)\n  diferencia &lt;- mean(sims_hombres$W - sims_mujeres$W)\n  # Calculamos la diferencia de medias\n  tibble(diferencia = diferencia) |&gt; bind_cols(pars)\n}\n\n\nsimular_diferencia_post(sims_post_tbl)\n\n# A tibble: 1 × 4\n  diferencia `alpha[1]` `alpha[2]` sigma\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1       16.8       55.1       71.5  9.76\n\n\nY ahora calculamos el resumen de interés, que es la posterior del contraste o diferencia entre las dos poblaciones simuladas. Comparamos con la línea en rojo que es la cantidad que establecimos a estimar:\n\nmap_df(1:4000, ~ simular_diferencia_post(sims_post_tbl) |&gt; \n         mutate(rep = .x)) |&gt;  \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"Efecto de sexo en estatura hombres vs mujeres (kg)\") +\n  geom_vline(xintercept = mean(sim_hombres$W - sim_mujeres$W), \n             color = \"red\", linewidth = 1.5)\n\n\n\n\n\n\n\n\nPuedes repetir este ejercicio para distintos valores de los parámetros, como hicimos en los ejemplos de arriba.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#ajustar-a-los-datos-observados-y-resumir",
    "href": "03-modelos-genericos.html#ajustar-a-los-datos-observados-y-resumir",
    "title": "4  Componentes de modelación 1",
    "section": "4.5 Ajustar a los datos observados y resumir",
    "text": "4.5 Ajustar a los datos observados y resumir\nAhora usamos los datos reales y calculamos el estimador que probamos arriba.\n\nmod_2_fit &lt;- mod_peso$sample(\n  data = list(N = nrow(datos_tbl), \n              s = datos_tbl$male + 1, \n              w = datos_tbl$weight),\n  refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.0 seconds.\n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/Rtmpqu4tS8/model-20a7240ffbe1.stan', line 18, column 2 to column 30)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/Rtmpqu4tS8/model-20a7240ffbe1.stan', line 18, column 2 to column 30)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/Rtmpqu4tS8/model-20a7240ffbe1.stan', line 18, column 2 to column 30)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\nY repetimos exactamente el proceso que probamos arriba:\n\nsims_post_tbl &lt;- mod_2_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\ndif_tbl &lt;- map_df(1:4000, ~ simular_diferencia_post(sims_post_tbl) |&gt; \n         mutate(rep = .x)) \ndif_tbl |&gt; \nggplot(aes(x = diferencia)) +\n  geom_histogram(bins = 50) +\n  labs(x = \"Efecto de sexo en peso hombres vs mujeres (kg)\") \n\n\n\n\n\n\n\n\nConcluimos que el efecto total de sexo sobre peso está entre unos 5.5 y 8 kg de diferencia de hombres vs mujeres.\nEjercicio: explica porqué mostrar por separado las distribuciones de poblaciones de hombres vs la de poblaciones de mujeres no da la respuesta que buscamos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#efecto-directo-de-sexo",
    "href": "03-modelos-genericos.html#efecto-directo-de-sexo",
    "title": "4  Componentes de modelación 1",
    "section": "4.6 Efecto directo de sexo",
    "text": "4.6 Efecto directo de sexo\nAhora pensemos cómo podemos calcular el efecto directo de sexo sobre peso, sin tomar en cuente su influencia en la estatura. En nuestro diagrama, nos interesa sólo considerar la influencia que va directamente de sexo a peso, y no la que pasa por el camino que va a través de la estatura. Este tipo de análisis se llama a veces análisis de mediación.\nLa idea es bloquear el camino que va de sexo a estatura, y esto podemos hacer condicionando o estratificando por los valores de \\(H\\) (bajo los supuestos de nuestro diagrama). Es decir, para cada valor de \\(H\\), queremos calcular cuál es la diferencia entre una población de hombres y de mujeres (con la misma estatura \\(H\\)). Las diferencias que encontremos no puede deberse a estatura, pues esta valor es fijo. Al estratificar por \\(H\\), decimos que el camino \\(S\\to H\\to W\\) está bloqueado, y refinaremos esta idea más adelante.\nNota: si consideráramos que hay una causa común para estatura y peso, veremos y explicaremos con detalle más adelante por qué esta estrategia de condicionar bajo \\(H\\) no funciona para calcular el efecto directo de sexo sobre peso.\nBajos los supuestos de nuestro modelo original, en términos de cantidad a estimar quisiéramos, para cada estatura \\(H\\), calcular la diferencia de una población de hombres vs una de mujeres. La diferencia es el efecto directo a la estatura \\(H\\).\nEl modelo estadístico que proponemos para estimar el efecto directo es entonces:\n\\[\n\\begin{align}\nW_i &\\sim N(\\mu_i, \\sigma)\\\\\n\\mu_i &= \\alpha_{S_i} + \\beta_{S_i} (H_i - \\bar{H})\\\\\n\\alpha_1,\\alpha_2 &\\sim N(60, 10) \\\\\n\\beta_1,\\beta_2 &\\sim N^+(0, 1) \\\\\n\\sigma &\\sim N^+(0, 20) \\\\\n\\end{align}\n\\]\nEl contraste que queremos calcular lo podemos identificar con parámetros en el modelo. Por ejemplo, si \\(\\beta_1 = \\beta_2\\), el efecto directo, para cualquier estatura, debería ser \\(\\alpha_2 - \\alpha_1\\). Sin embargo, seguimos con nuestro camino de hacer simulación para mantener más flexibilidad y simplicidad.\nEjercicio: Haz verificaciones a priori: genera datos sintéticos, examínalos, y verifica que el modelo es capaz de recuperar el contraste de interés.\n\n4.6.1 Ajuste a datos reales y resumen\n\nmod_peso_2 &lt;- cmdstan_model(\"./src/peso-estatura-3.stan\")\nprint(mod_peso_2)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  w;\n  vector[N]  h;\n  array[N] int s;\n}\n\ntransformed data {\n  real h_media;\n  h_media = mean(h);\n}\n\nparameters {\n  array[2] real alpha;\n  array[2] real&lt;lower=0&gt; beta;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  array[N] real mu;\n  for (i in 1:N) {\n    mu[i] = alpha[s[i]] + beta[s[i]] * (h[i] - h_media);\n  }\n}\n\nmodel {\n  // modelo para peso\n  w ~ normal(mu, sigma);\n  // también se puede escribir:\n  //for (i in 1:N) {\n  //  w[i] ~ normal(mu[i], sigma);\n  //}\n  alpha ~ normal(60, 10);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 20);\n}\n\ngenerated quantities {\n\n}\n\n\n\nmod_3_fit &lt;- mod_peso_2$sample(\n  data = list(N = nrow(datos_tbl), \n              s = datos_tbl$male + 1, \n              h = datos_tbl$height,\n              w = datos_tbl$weight),\n  init = 0.01, step_size = 0.01, refresh = 0, seed = 221\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.3 seconds.\nChain 2 finished in 0.3 seconds.\nChain 3 finished in 0.3 seconds.\nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.3 seconds.\n\n\n\nmod_3_fit$summary(c(\"alpha\", \"beta\", \"sigma\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nalpha[1]\n45.16\n45.15\n0.44\n0.43\n44.44\n45.86\n1\n2608.65\n2588.93\n\n\nalpha[2]\n45.09\n45.10\n0.45\n0.46\n44.33\n45.82\n1\n2588.37\n2723.75\n\n\nbeta[1]\n0.66\n0.66\n0.06\n0.06\n0.55\n0.76\n1\n2789.48\n2741.81\n\n\nbeta[2]\n0.61\n0.61\n0.05\n0.05\n0.52\n0.70\n1\n2929.67\n2678.50\n\n\nsigma\n4.27\n4.27\n0.16\n0.16\n4.01\n4.53\n1\n3874.01\n2739.60\n\n\n\n\n\nLa diferencia entre las dos rectas parece ser chica. Eso implicaría que el efecto directo de sexo en peso es débil. Sin embargo, es mejor calcular y resumir el contraste como hemos hecho en otros ejemplos.\nRepetimos exactamente el proceso que probamos arriba. Haremos los cálculos manualmente otra vez (aunque conviene más hacerlos dentro de stan):\n\nsims_post_tbl &lt;- mod_3_fit$draws() |&gt; as_draws_df() |&gt; \n  as_tibble()\nh_media &lt;- mean(datos_tbl$height)\n# función para simular pesos\nsim_peso_mod_sh &lt;- function(S, H, alpha, beta, sigma, h_media){\n  n &lt;- length(S)\n  W &lt;- rnorm(n, alpha[S] + beta[S] * (H - h_media), sigma)\n  tibble(W = W)\n}\nsimular_diferencia_post_2 &lt;- function(sims_post_tbl, h){\n  pars &lt;- sample_n(sims_post_tbl, 1) |&gt; \n    select(starts_with(c(\"alpha\", \"beta\")), sigma)\n  alpha &lt;- c(pars$`alpha[1]`, pars$`alpha[2]`)\n  beta &lt;- c(pars$`beta[1]`, pars$`beta[2]`)\n  diferencia &lt;- numeric(length(h))\n  # para cada nivel de estatura especificado\n  for(i in seq_along(h)){\n    # Simulamos poblaciones\n    sims_hombres &lt;- sim_peso_mod_sh(rep(2, 1000), h[i],\n      alpha = alpha, beta = beta, pars$sigma, h_media = h_media)\n    sims_mujeres &lt;- sim_peso_mod_sh(rep(1, 1000), h[i],\n      alpha = alpha, beta = beta, pars$sigma, h_media = h_media)\n    diferencia[i] &lt;- mean(sims_hombres$W - sims_mujeres$W)\n  }\n  tibble(diferencia = diferencia, h = h) |&gt; bind_cols(pars)\n}\n\nPor ejemplo:\n\nsimular_diferencia_post_2(sims_post_tbl, h = c(150, 170))\n\n# A tibble: 2 × 7\n  diferencia     h `alpha[1]` `alpha[2]` `beta[1]` `beta[2]` sigma\n       &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     0.0515   150       44.8       44.7     0.707     0.694  4.29\n2    -0.268    170       44.8       44.7     0.707     0.694  4.29\n\n\n\nh &lt;- seq(130, 190, by = 5)\ndif_tbl &lt;- map_df(1:1000, \n    ~ simular_diferencia_post_2(sims_post_tbl, h) |&gt; \n         mutate(rep = .x))\n\n\ndif_tbl |&gt; \nggplot(aes(x = h, y = diferencia, group = rep)) +\n  geom_line(alpha = 0.1) +\n  labs(y = \"Contraste de peso hombres vs mujeres (kg)\") +\n  labs(x = \"Estatura\") +\n  geom_hline(yintercept = 0, colour = \"red\") \n\n\n\n\n\n\n\n\nEsto muestra que el efecto directo de sexo en peso es relativamente chico: la mayor parte del efecto es a través de la estatura. Existe una ligera tendencia a que los hombre de menos estatura sean más pesados, y las mujeres de más estatura sean relativamente menos pesadas, pero realmente no podemos afirmar con confianza ningún efecto claro.\n\n\n\n\n\n\nTip\n\n\n\nCuando agregamos una variable como estatura en el modelo de regresión, decimos que estamos estratificando por estatura. En este caso, bloqueamos el efecto causal que tiene sexo en peso a través de la estatura. El efecto causal entre los la variable sexo, que se hace dentro de cada estrato, y se expresa en los coeficientes de sexo, tiene una interpretación totalmente diferente en comparación al modelo que no incluye estatura.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#regresión-logística-tiros-de-golf",
    "href": "03-modelos-genericos.html#regresión-logística-tiros-de-golf",
    "title": "4  Componentes de modelación 1",
    "section": "4.7 Regresión logística: tiros de golf",
    "text": "4.7 Regresión logística: tiros de golf\nEste caso está basado en el paper Gelman y Nolan (2002) y el caso de estudio de Gelman.\nQueremos entender la probabilidad de éxito de putts de Golf (putts: tiros relativamente cerca del hoyo que buscan que la pelota ruede al hoyo o muy cerca de él), y cómo depende el éxito de la distancia del tiro. ¿Qué tan precisos son los profesionales a diferentes distancias? Los datos que tenemos son varios putts de Golf de profesionales a varias distancias, y para cada distancia el porcentaje de éxitos de esos putts.\nComenzaremos con el siguiente diagrama causal:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    V\n    Ang [label = &lt;&theta;&gt;]\n    U\n  node [shape=plaintext]\n    D\n    Y\n  edge [minlen = 3]\n    D -&gt; V\n    D -&gt; Y\n    V -&gt; Y\n    Ang -&gt; Y\n    U -&gt; Y\n{rank = same; D; V}\n{rank = same; Ang; Y}\n{rank = max; U}\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEn este caso, el modelo causal es como sigue: conocemos la distancia \\(D\\) al hoyo en cada tiro. El éxito (\\(Y=1\\)) o fracaso (\\(Y=0\\)) depende de la distancia, junto con la velocidad a la que sale la pelota (muy alto o muy bajo puede dar un tiro fallido), y el ángulo \\(\\theta\\) de salida. Adicionalmente, hay otros factores \\(U\\) que pueden afectar la probabilidad de éxito. Nótese que no escribiríamos, por ejemplo \\(Y \\leftarrow D\\), porque la distancia no cambia causalmente con el resultado del tiro, aunque es cierto que si intervenimos en la distancia, esperaríamos obtener tasas de éxito diferentes. Igualmente, podemos poner una flecha de \\(V\\) a \\(D\\) y \\(V\\) a \\(Y\\): son factores no medidos que afectan la probabilidad de éxito, y que pueden variar por la distancia.\nTodas estas variables antecedentes de \\(Y\\) interactúan para determinar el éxito de un tiro.\nCantidad a estimar: queremos conocer el efecto total de \\(D\\) sobre \\(Y\\). Esto es, queremos conocer la curva \\(p(Y=1|D=d)\\), que es una función de \\(d\\), y también hacer contrastes del tipo \\(p(Y=1|D=d + 10) - p(Y = 1|D=d),\\) por ejemplo.\nModelo estadístico: Nuestro diagrama causal justifica que no es necesario considerar \\(V\\) o \\(\\theta\\) en el modelo, pues nos interesa el efecto total de la distancia sobre \\(Y\\). Esto justifica el uso de un modelo genérico usamos \\(Y\\) como respuesta y \\(D\\) como variable independiente. Intentaremos con un modelo genérico como regresión logística.\nPlanteamos entonces un modelo logístico:\n\\(p(Y = 1| D = d) = \\frac{1}{1 + \\exp(-\\alpha - \\beta d)} = h(\\alpha +\\beta d)\\)\nY nuestro modelo es:\n\\[\n\\begin{align}\nY_i &\\sim Bern(p_i(D_i)) \\\\\np_i &= \\frac{1}{1+\\exp(-\\alpha - \\beta D_i)} \\\\\n\\end{align}\n\\]\nEn términos de este modelo, queremos estimar la curva \\(h(\\alpha +\\beta d)\\), o los parámetros \\(\\alpha\\) y \\(\\beta\\).\nAhora construimos un modelo generativo, donde \\(D\\) está dada en centímetros:\n\nsimular_putts &lt;- function(distancias, alpha, beta) {\n  p &lt;- 1 / (1 + exp(-alpha - beta * distancias))\n  tibble(y = rbinom(length(distancias), 1, p), d = distancias) |&gt; \n    select(d, y)\n}\n\nFijamos parámetros y simulamos datos:\n\nset.seed(22)\ndistancias &lt;- seq(0, 1000, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, 3, -0.005) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 0.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nNótese que para este ejemplo utilizamos valores de \\(\\alpha\\) y \\(\\beta\\) fijos. Valores imposibles para golfistas profesionales, por ejemplo, podrían ser los siguientes:\n\nset.seed(22)\ndistancias &lt;- seq(0, 1000, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, 10, -1) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 0.5)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nEsta configuración de parámetros no es razonable, pues implicaría que sólo pueden completar los tiros a unos cuantos centímetros del hoyo. Sabemos que esto no es cierto.\nPara completar nuestro modelo generativo, es necesario especificar los valores que pueden tomar estas variables. Pondremos distribuciones iniciales o a priori apropiadas para los parámetros. En este punto no hemos visto ningún dato, así que podemos experimentar para hacer una selección apropiada desde el punto de vista del conocimiento del área que tenemos actualmente.\nPodemos poner por ejemplo \\[\\alpha \\sim \\text{Normal}(6, 2),\\] pues sabemos a que distancias de casi cero, es muy seguro lograr el tiro (no lejos de 100% de éxito). Para la \\(\\beta\\), consideramos que a unos 100 cm es muy probable hacer el tiro, pero a 1000 cm (10 m) la probabilidad baja considerablemente. Experimentaremos poniendo (debe ser negativa)\n\\[\\beta \\sim \\text{Normal}^-(0, 0.025).\\]\ny ahora reescribimos nuestra función de simulación:\n\nsimular_putts &lt;- function(distancias) {\n  alpha &lt;- rnorm(1, 6, 2)\n  beta &lt;-  - abs(rnorm(1, 0, 0.025))\n  p &lt;- 1 / (1 + exp(-alpha - beta * distancias))\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(alpha = alpha, beta = beta)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 1000, 1) \nmap_df(1:100,  \\(x) simular_putts(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nLos casos extremos son poco creíbles (0 probabilidad a 2 metros o 100% de probabilidad a 6 metros), pero tenemos un rango razonable para las curvas. Podemos ver la curva promedio:\n\nreps_sim &lt;- map_df(1:1000,  \\(x) simular_putts(distancias) |&gt; mutate(id = x)) \nresumen &lt;- reps_sim |&gt; group_by(d) |&gt; summarise(p_5 = quantile(p, 0.10),\n                                                p95 = quantile(p, 0.90),\n                                                p = mean(p))\nreps_sim |&gt; \n  ggplot(aes(x = d, y = p)) +\n  #geom_line(aes(group = id), alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_ribbon(data = resumen, aes(ymin = p_5, ymax = p95), alpha = 0.2) +\n  geom_line(data = resumen, color = \"red\", linewidth = 2) \n\n\n\n\n\n\n\n\nUna vez que estamos satisfechos con nuestro modelo (nótese que hay lugar para varias críticas), podemos proceder a calcular la distribución posterior, primero con datos simulados.\nLa posterior en este caso es más complicada y no tenemos una manera simple de simularla. Explicaremos más adelante cómo hacer esto (usando MCMC). Por ahora, escribiremos un programa de Stan que nos da simulaciones de la posterior. Tomaremos por el momento Stan como una caja negra, y después justificaremos este procedimiento.\n\n#! message: false\nlibrary(cmdstanr)\nmod_logistica &lt;- cmdstan_model(\"./src/golf-logistico.stan\")\nprint(mod_logistica)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int n;\n  vector[N] d;\n  array[N] int y;\n}\nparameters {\n  real alpha;\n  real&lt;upper = 0&gt; beta;\n}\nmodel {\n  y ~ binomial_logit(n, alpha + beta * d);\n  alpha ~ normal(6, 2);\n  beta ~ normal(0, 0.025);\n}\n\n\n\nset.seed(425)\ndistancias &lt;- rnorm(100, 0, 2000) |&gt; abs() \ndatos &lt;- simular_putts(distancias)\ndatos_mod &lt;- datos |&gt; group_by(d) |&gt; \n  summarise(n = n(), y = sum(y)) |&gt; \n  ungroup()\najuste &lt;- mod_logistica$sample(\n  data = list(N = nrow(datos_mod), \n              d = datos_mod$d, y = datos_mod$y, n = datos_mod$n), \n                        refresh = 1000, init = 10, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 3 × 10\n  variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -11.3    -11.0    0.983  0.732  -13.3    -10.3     1.00    1399.\n2 alpha      3.79     3.73   1.25   1.22     1.82     5.96    1.01    1256.\n3 beta      -0.0362  -0.0354 0.0111 0.0113  -0.0552  -0.0189  1.00    1274.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\n\ndatos$alpha[1]\n\n[1] 2.691742\n\ndatos$beta[1]\n\n[1] -0.02548956\n\n\n\nggplot(sims, aes(alpha, beta)) + geom_point() +\n  geom_point(data = datos |&gt; first(), aes(alpha, beta), color = \"red\", size = 3)\n\n\n\n\n\n\n\n\nY podemos graficar la posterior de interés, que se construye con todas las curvas simuladas:\n\ngrafs_tbl &lt;- sims |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = seq(0, 600, 10)) |&gt; \n           mutate(p = 1 / (1 + exp(-alpha - beta * d)))\n  )) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 1000) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\nY graficamos:\n\ngrafs_tbl |&gt; \n  ggplot(aes(x = d, y = p, group = .draw)) +\n  geom_line(alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nPor el momento, podríamos hacer unas cuantas simulaciones distintas, y ver que las curvas obtenidas son las que esperaríamos (más tarde formalizaremos este proceso). También podríamos hacer simulaciones con distintos tamaños de muestra, y entender cuánta incertidumbre en la estimación de las curvas podríamos tener.\nAhora llegamos al siguiente paso, que tomar los datos y estimar nuestra curva de desempeño según la distancia. Será necesario convertir de pies a centímetros en la variable de distancia:\n\n# nota: x está en pies (ft)\ndatos_golf &lt;- read_delim(\"../datos/golf.csv\", delim = \" \")\n\nRows: 19 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): x, n, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(datos_golf)\n\n# A tibble: 6 × 3\n      x     n     y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2  1443  1346\n2     3   694   577\n3     4   455   337\n4     5   353   208\n5     6   272   149\n6     7   256   136\n\n\n\nset.seed(1225)\najuste &lt;- mod_logistica$sample(\n  data = list(N = nrow(datos_golf), \n              d = 30.48 * datos_golf$x, y = datos_golf$y, n = datos_golf$n), \n                        refresh = 1000, init = 10, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 3 × 10\n  variable        mean   median      sd     mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -3028.      -3.03e+3 1.03e+0 7.12e-1 -3.03e+3 -3.03e+3  1.00    1244.\n2 alpha        2.24     2.24e+0 5.84e-2 5.67e-2  2.14e+0  2.33e+0  1.00    1015.\n3 beta        -0.00840 -8.40e-3 2.16e-4 2.07e-4 -8.76e-3 -8.04e-3  1.00    1041.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\ngrafs_tbl &lt;- sims |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = 30.48 * seq(0, 20, 0.5)) |&gt; \n           mutate(p = 1 / (1 + exp(-alpha - beta * d)))\n  )) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\n\nresumen_golf &lt;- datos_golf |&gt;\n  mutate(d = 30.48 * x, p = y / n)\n\n\ngrafs_tbl |&gt; \n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf, \n    aes(ymin = p - 2 * sqrt(p * (1 - p) / n),  \n        ymax = p + 2 * sqrt(p * (1 - p) / n)),\n    color = \"red\")\n\n\n\n\nChequeo predictivo posterior (deficiente)\n\n\n\n\nVemos que la curva estimada desajusta. Este tipo de análisis se llama chequeo a posteriori, y mas frecuentemente se hace un chequeo predictivo posterior, que veremos más adelante. Por el momento, nos quedamos con la conclusión de que el modelo no es apropiado para estos datos: no hemos capturado apropiadamente la relación que hay entre éxito y distancia.\nEn este punto veremos dos caminos:\n\nEl primero es continuar con modelos genéricos que no toman en cuenta mecanismos específicos de los datos. Por ejemplo, podríamos poner más terminos derivados de la distancia (polinomios o splines).\nEl segundo camino, es utilizar más información acerca del fenómeno de interés. Sabemos como funciona básicamente el golf, y también sabemos geometría y física que determina el proceso generador de datos. Podemos utilizar esta información para construir un modelo más apropiado.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#usando-teoría-para-construir-modelos",
    "href": "03-modelos-genericos.html#usando-teoría-para-construir-modelos",
    "title": "4  Componentes de modelación 1",
    "section": "4.8 Usando teoría para construir modelos",
    "text": "4.8 Usando teoría para construir modelos\nEn la gráfica causal que vimos arriba, hay mucha información adicional que no hemos utilizado acerca de la naturaleza de la dependencia de las variables involucradas. En esta parte, en lugar de usar un modelo genérico, utilizaremos geometría y algo de física para construir un modelo más apropiado.\nEl problema es considerablemente complicado conceptualmente (Holmes (1991), Penner (2002)) si consideramos todas las fuentes de variación: ángulo de tiro, potencia de tiro, declive en greens y así sucesivamente.\nSeguiremos haciendo la simplificación de superficie plana, pero consideramos dos parámetros para el tiro con distintas condiciones de éxito:\n\nEl ángulo del tiro\nLa velocidad con la que la pelota llega (o no llega) al hoyo\n\nEl diámetro de una pelota de golf y el hoyo (en centrímetros) es de\n\ndiam_pelota &lt;- (1.68 * 2.54) |&gt;  round(1)\ndiam_hoyo &lt;- (4.25 * 2.54) |&gt;  round(1)\nc(diam_pelota, diam_hoyo)\n\n[1]  4.3 10.8\n\n\nSupondremos por el momento que los greens de golf (áreas cerca del hoyo) son perfectamente planos, de modo que el éxito depende de\n\nTirar la pelota con un ángulo suficientemente cercano a cero con respecto a la línea que va del centro de la pelota al centro del hoyo.\nTirar la pelota con una velocidad suficiente para llegue al hoyo pero no tan alta que vuele por encima del hoyo.\n\nMejores datos de los tipos de fallo sería útil, pero por el momento no consideramos que estén disponibles.\nEmpezamos construyendo nuestro modelo considerando sólamente el ángulo de tiro.\n\n4.8.0.1 Ángulo de tiro\nSupongamos que la distancia del centro de la pelota al centro del hoyo es \\(d\\), y que \\(\\theta\\) es el ángulo del tiro con respecto a la recta que va del centro de la pelota al centro del hoyo. El tiro es exitoso cuando (si \\(\\theta\\) está en radianes):\n\\[\\tan(\\theta) &lt; \\frac{R - r}{2d}\\]\n Tenemos que\n\n(diam_hoyo - diam_pelota)/2\n\n[1] 3.25\n\n\nAsí que para nuestro problema simplificado, la condición de éxito es (d está dado en centímetros y \\(\\theta\\) en radianes):\n\\[\\tan(\\theta) &lt; \\frac{3.25}{d}\\]\nMejores golfistas tendrán mejor control sobre \\(\\theta\\), y conforme \\(d\\) es más grande, la probabilidad de tener éxito baja:\n\ntibble(d = seq(10, 600, 1)) |&gt;  \n  mutate(theta_grados = (180 / pi) * atan(3.25 / d)) |&gt;  \nggplot(aes(d, theta_grados)) + geom_point() +\n  xlab(\"Distancia (cm)\") +\n  ylab(expression(paste(\"Desviación máxima en grados\"))) +\n  labs(subtitle = \"Desviación máxima permitida para tener éxito a distintas distancias\") +\n  scale_y_log10()\n\n\n\n\n\n\n\n\nPor el momento, sólo consideraremos el ángulo y la distancia. Supongamos que un tirador profesional tira con un ángulo \\(\\theta\\) que se distribuye como\n\\[\\theta\\sim N(0,\\sigma),\\] donde \\(\\theta=0\\) indica que el tiro es directo al hoyo. La probabilidad de tener éxito es entonces\n\\[P(Y=1|\\theta) = P(|\\theta| &lt; \\arctan(3.25/d)) = 2\\Phi \\left (\\frac{\\arctan(3.25/d)}{\\sigma}  \\right )-1\\] Así que nuestro modelo completo es\n\\[\n\\begin{align}\nY_i &\\sim Bern(p_i(D_i)) \\\\\np_i &= 2\\Phi(\\arctan(3.25/D_i)/\\sigma)-1 \\\\\n\\end{align}\n\\] Nótese que sólo tenemos un parámetro \\(\\sigma\\) en este modelo en lugar de dos como en la regresión logística. La diferencia grande también es la forma funcional de la probabilidad de éxito.\nAntes de escribir nuestra función, necesitamos poner una inicial sobre \\(\\sigma\\). Probaremos considerando que un jugador profesional puede tener una desviación de 0 a 10 grados, por ejemplo. Convirtiendo a radianes podríamos poner:\n\\[\n\\begin{align}\nY_i &\\sim Bern(p_i(D_i)) \\\\\np_i &= 2\\Phi(\\arctan(3.25/D_i)/\\sigma)-1 \\\\\n\\sigma &\\sim N^+(0, 5\\pi/180))\n\\end{align}\n\\]\n\nsimular_putts_angulo &lt;- function(distancias) {\n  sigma &lt;- rnorm(1, 0, 5 * pi / 180) |&gt; abs()\n  p &lt;- 2 * pnorm(atan(3.25 / distancias)/sigma) - 1\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(sigma = sigma)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 600, 1) \nmap_df(1:100,  \\(x) simular_putts_angulo(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nEsta inicial espera que en general los tiros a menos de menos de 50cm se consigan con mucha frecuencia o casi seguro, 2 metros se consigan con cierta frecuencia, y 6 metros se consigan con relativamente menos frecuencia. Tiene el defecto de que pone mucho peso en desviaciones muy chicas, lo cual es poco creíble (las rectas que se pegan mucho probabilidad uno para todas las distancias).\nUn cambio razonable que podemos hacer, por ejemplo, es poner:\n\\[\\theta_{grados} \\sim Gamma(a, b)\\]\nCuya media queremos poner por ejemplo en 2 grados \\(a/b = 2\\), y suponemos una desviación estándar de unos \\(a/b^2 = 0.5\\) grados. En este caso,\n\nmu &lt;- 2\nbeta  &lt;- 2\nqplot(rgamma(1e5, mu * beta, beta))\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nsimular_putts_angulo &lt;- function(distancias) {\n  sigma &lt;- (pi/180) * rgamma(1, mu * beta, beta) \n  p &lt;- 2 * pnorm(atan(3.25 / distancias)/sigma) - 1\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(sigma = sigma)\n}\n\nY podemos ver cómo se ven diversas curvas que incluye nuestro modelo:\n\ndistancias &lt;- seq(0, 600, 1) \nmap_df(1:200,  \\(x) simular_putts_angulo(distancias) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  ylim(c(0,1))\n\n\n\n\n\n\n\n\nNota: Checando con esta gráfica podemos modificar los parámetros de la Gamma para poner una inicial apropiada.\nDejaremos como ejercicio hacer las pruebas predictivas a priori, y continuaremos con el ajuste a los datos para checar el ajuste de este modelo:\n\n#! message: false\nlibrary(cmdstanr)\nmod_golf &lt;- cmdstan_model(\"./src/golf-principios-1.stan\")\nprint(mod_golf)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int n;\n  vector[N] d;\n  array[N] int y;\n}\ntransformed data {\n  vector[N] angulo_maximo = atan(3.25 ./ d);\n}\nparameters {\n  real&lt;lower=0&gt; sigma_ang;\n  }\ntransformed parameters {\n  real sigma = sigma_ang * pi() / 180;\n  vector[N] p = 2 * Phi(angulo_maximo / sigma) - 1;\n}\nmodel {\n  y ~ binomial_logit(n, p);\n  sigma_ang ~ gamma(4, 2);\n}\n\n\n\nset.seed(225)\najuste_2 &lt;- mod_golf$sample(\n  data = list(N = nrow(datos_golf),\n              d =  30.48 * datos_golf$x, y = datos_golf$y, n = datos_golf$n),\n  refresh = 1000, init = 0.01, step_size = 0.01)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims_2 &lt;- ajuste_2$draws(c(\"sigma\", \"sigma_ang\"), format = \"df\")\nresumen_2 &lt;- ajuste_2$summary(c(\"sigma\", \"sigma_ang\"))\n\n\nresumen_2\n\n# A tibble: 2 × 10\n  variable    mean median      sd     mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 sigma     0.0308 0.0308 0.00138 0.00137 0.0287 0.0331  1.00    1536.    1836.\n2 sigma_ang 1.77   1.76   0.0789  0.0784  1.64   1.90    1.00    1536.    1836.\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\ngrafs_2_tbl &lt;- sims_2 |&gt;\n  rowwise() |&gt;\n  mutate(graf = list(tibble(d = 30.48 * seq(0, 20, 0.5)) |&gt;\n                       mutate(p = 2 * pnorm(atan(3.25 / d)/sigma) - 1))) |&gt;\n  ungroup() |&gt;\n  slice_sample(n = 100) |&gt;\n  select(.draw, graf) |&gt;\n  unnest(graf)\n\nEl resultado es considerablemente mejor que el de la regresión logística, aunque tiene algunos fallos en rangos medios:\n\ngrafs_2_tbl |&gt;\n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf,\n                 aes(ymin = p - 2 * sqrt(p * (1 - p) / n),\n                     ymax = p + 2 * sqrt(p * (1 - p) / n)),\n                 color = \"red\") +\n  ylim(c(0,1))\n\n\n\n\nChequeo predictivo posterior\n\n\n\n\nEste es un modelo relativamente simple que sólo toma en cuenta ángulos y distancia. Para más refinaciones que toman en cuenta la velocidad, puedes revisar también este análisis de M. Broadie, en donde se extiende este modelo bajo principios geométricos y físicos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "03-modelos-genericos.html#modelos-genéricos-para-ajustar-curvas",
    "href": "03-modelos-genericos.html#modelos-genéricos-para-ajustar-curvas",
    "title": "4  Componentes de modelación 1",
    "section": "4.9 Modelos genéricos para ajustar curvas",
    "text": "4.9 Modelos genéricos para ajustar curvas\nOtra posibilidad es utilizar un modelo más flexible creando variables derivadas de la distancia. En este caso, quizá podemos ajustar una curva que sea aceptable desde el punto de vista predictivo, pero no podremos aprender mucho acerca de cómo funciona la probabilidad de éxitos de los tiros de putts\n\n\n\n\n\n\nSplines y ajuste de curvas\n\n\n\nLos splines nos dan una manera estándar de ajustar curvas más flexibles, de tipo polinomial por tramos. Usualmente son numéricamente más conveniente que polinomios.\n\n\nAunque hay muchos tipos de splines (los más comunes son B-splines), para este problema consideraremos una base de splines cuadráticos que resultan en curvas monótonas (I-splines). Puedes ver más detalles de splines en McElreath (2020)\nEn este caso, haremos expansión de entradas de las siguiente manera. Supongamos que tenemos la variable de distancia \\(d\\) que va de 0 a 750 cm, por ejemplo. Construimos entradas derivadas de la siguiente manera:\n\nlibrary(splines2)\nnudos &lt;- c(25, 50, 100, 200, 400)\ndistancias &lt;- seq(0, 750, 1)\nsplines_tbl &lt;- iSpline(distancias, knots = nudos, \n  Boundary.knots = c(0, 750), degree = 2, intercept = FALSE) |&gt; \n  as_tibble() |&gt; \n  mutate(d = distancias) |&gt; \n  pivot_longer(-d, names_to = \"spline\", values_to = \"valor\")\nggplot(splines_tbl) +\n  geom_line(aes(x = d, y = valor, color = spline)) +\n  geom_vline(xintercept = nudos, color = \"red\", linetype = 2) \n\n\n\n\n\n\n\n\nEsta gráfica muestra cómo para cada distancia \\(x\\) generamos valores \\(x_1,\\ldots, x_p\\) que son variables derivadas de \\(x\\). Podemos entonces obtener más flexibilidad hacer regresión en estas nuevas \\(p\\) variables en lugar de usar solamente \\(x\\). Por la elección de la base, obsérvese que siempre que \\(\\beta_1, \\ldots, \\beta_p\\) sean no negativos, entonces la función \\[\\alpha + \\beta_1 x_1 + \\cdots + \\beta_p x_p\\] será monótona no decreciente, que es lo que necesitamos para este problema.\nNuestra función generadora para este modelo puede ser:\n\nsimular_putts &lt;- function(distancias, nudos) {\n  # Simular intercepto\n  alpha &lt;- rnorm(1, 4, 2)\n  # Simular coeficientes de splines\n  beta &lt;-  - abs(rnorm(7, 0, 1.5))\n  # Calcular splines para distancias dadas\n  mat_splines &lt;- splines2::iSpline(distancias, \n    Boundary.knots = c(0, 750), knots = nudos, degree = 2, intercept = FALSE) \n  # Calcular probabilidad de éxito con regresión logística\n  p &lt;- 1 / (1 + exp(- alpha - mat_splines %*% beta))\n  tibble(y = rbinom(length(distancias), 1, p), p = p, d = distancias) |&gt; \n    select(d, p, y) |&gt; \n    mutate(alpha = alpha, beta = list(beta))\n}\n\n\nset.seed(8123)\ndistancias &lt;- seq(1, 600, 5) |&gt; rep(each = 5)\nsimular_putts(distancias, nudos) |&gt; \n  ggplot(aes(x = d, y = y)) +\n  geom_jitter(height = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Éxito\") +\n  geom_smooth(span = 1, se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nY podemos hacer simulaciones a priori para entender nuestros supuestos:\n\nmap_df(1:100,  \\(x) simular_putts(distancias, nudos) |&gt; mutate(id = x)) |&gt; \n  ggplot(aes(x = d, y = p, group = id)) +\n  geom_line(alpha = 0.2) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\")\n\n\n\n\n\n\n\n\nAhora construimos nuestro nuevo modelo en Stan, donde \\(x\\) será la matriz de splines (entradas derivadas como se explicó arriba):\n\n#! message: false\nlibrary(cmdstanr)\nmod_logistica_splines &lt;- cmdstan_model(\"./src/golf-logistico-splines.stan\")\nprint(mod_logistica_splines)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; p;\n  array[N] int n;\n  vector[N] d;\n  matrix[N, p] x;\n  array[N] int y;\n}\nparameters {\n  real alpha;\n  array[p] real&lt;upper=0&gt; beta;\n}\nmodel {\n  for(i in 1:N){\n    y[i] ~ binomial_logit(n[i], alpha + dot_product(x[i,], to_vector(beta)));\n  }\n  alpha ~ normal(4, 2);\n  beta ~ normal(0, 1.5);\n}\n\n\n\nset.seed(1225)\nmat_splines &lt;- splines2::iSpline(30.48 * datos_golf$x, \n      Boundary.knots = c(0, 750), knots = nudos, degree = 2, intercept = FALSE) \najuste &lt;- mod_logistica_splines$sample(\n  data = list(N = nrow(datos_golf), p = ncol(mat_splines),\n              d = 30.48 * datos_golf$x, \n              x = mat_splines,\n              y = datos_golf$y, n = datos_golf$n), \n  refresh = 1000, init = 0.1, \n  step_size = 0.1, adapt_delta = 0.99)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 3.8 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 3.6 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 3.9 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 4.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 4.0 seconds.\nTotal execution time: 16.3 seconds.\n\n\nWarning: 457 of 4000 (11.0%) transitions hit the maximum treedepth limit of 10.\nSee https://mc-stan.org/misc/warnings for details.\n\nsims &lt;- ajuste$draws(c(\"alpha\", \"beta\"), format = \"df\")\n\nresumen &lt;- ajuste$summary()\n\n\nresumen\n\n# A tibble: 9 × 10\n  variable      mean    median    sd   mad       q5        q95  rhat ess_bulk\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 lp__     -2912.    -2911.    2.20  2.15  -2916.   -2909.      1.00    1219.\n2 alpha        4.88      4.81  0.926 0.956     3.51     6.53    1.00    1659.\n3 beta[1]     -0.962    -0.816 0.737 0.751    -2.35    -0.0677  1.00    1659.\n4 beta[2]     -1.27     -1.19  0.787 0.847    -2.70    -0.153   1.00    1643.\n5 beta[3]     -1.90     -1.92  0.273 0.274    -2.33    -1.45    1.00    1429.\n6 beta[4]     -1.04     -1.04  0.237 0.236    -1.45    -0.662   1.00    1230.\n7 beta[5]     -1.21     -1.23  0.286 0.282    -1.63    -0.694   1.00    1239.\n8 beta[6]     -0.421    -0.359 0.312 0.322    -1.01    -0.0327  1.00    1373.\n9 beta[7]     -0.642    -0.521 0.522 0.480    -1.70    -0.0468  1.00    1535.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nAhora simulamos la posterior y la contrastamos con los datos:\n\nd &lt;- 30.48 * seq(0, 20, 0.5)\nmat_splines_pred &lt;- splines2::iSpline(30.48 * seq(0, 20, 0.5), \n       Boundary.knots = c(0, 750), knots = nudos, degree = 2,\n                                 intercept = FALSE) \nsims_2 &lt;- sims  |&gt; group_by(.draw, .chain, .iteration) |&gt; nest() \ngrafs &lt;- purrr::map(sims_2$data, function(pars){\n  pars &lt;- as.numeric(pars)\n  alpha &lt;- pars[1]\n  beta &lt;- pars[2:8]\n  p &lt;- 1/(1 + exp(- alpha - mat_splines_pred %*% beta))\n  tibble(p = as.numeric(p), d = d)\n})\nsims_graf_tbl &lt;- sims_2 |&gt; add_column(graf = grafs) |&gt; select(-data) |&gt; \n  ungroup() |&gt; \n  slice_sample(n = 100) |&gt; \n  select(.draw, graf) |&gt; \n  unnest(graf) \n\n\nsims_graf_tbl |&gt; \n  ggplot(aes(x = d, y = p)) +\n  geom_line(aes(group = .draw), alpha = 0.1) +\n  labs(x = \"Distancia (cm)\", y = \"Probabilidad de Éxito\") +\n  geom_point(data = resumen_golf, color = \"red\") +\n  geom_linerange(data = resumen_golf, \n    aes(ymin = p - 2 * sqrt(p * (1 - p) / n),  \n        ymax = p + 2 * sqrt(p * (1 - p) / n)),\n    color = \"red\")\n\n\n\n\n\n\n\n\nEste modelo ajusta mejor, y puede ser usado para hacer comparaciones de probabilidad de éxito a diferentes distancias. Su defecto es que no es interpetable como nuestro modelo anterior (aprendemos poco sobre cómo funcionan los putts), y es considerablemente más difícil de ajustar.\nPuedes ver más de splines en McElreath (2020), y en Hastie, Tibshirani, y Friedman (2017). Puedes revisar también este caso de Stan que explica cómo utilizar splines de forma más general en Stan.\n\n\n\n\nGelman, Andrew, y Deborah Nolan. 2002. «A Probability Model for Golf Putting». Teaching Statistics 24 (septiembre): 93-95. https://doi.org/10.1111/1467-9639.00097.\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. http://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nHolmes, Brian W. 1991. «Putting: How a golf ball and hole interact». American Journal of Physics 59 (2): 129-36. https://doi.org/10.1119/1.16592.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.\n\n\nPenner, Albert. 2002. «The physics of putting». Canadian Journal of Physics 80 (febrero): 83-96. https://doi.org/10.1139/p01-137.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Componentes de modelación 1</span>"
    ]
  },
  {
    "objectID": "05-dags.html",
    "href": "05-dags.html",
    "title": "5  Modelos gráficos y causalidad",
    "section": "",
    "text": "5.1 Modelos gráficos\nEn esta sección formalizaremos el concepto de modelos gráficos, en particular gráficas dirigidas acícilcas (DAGs), y veremos cómo sirven para representar supuestos causales acerca de los procesos que nos interesa modelar para contestar preguntas, o dicho de otra manera, cómo expresamos más formalmente supuestos acerca de la historia de los datos que nos interesa examinar.\nEn primer lugar, podemos pensar cómo se asignan los valores de las variables en nuestro proceso generador de datos. Pensamos entonces de qué depende directamente cada variable para determinar su valor, de manera que cada nodo \\(X\\) de la variable se puede escribir por ejemplo como \\(Y = f(X, W)\\) y \\(Z = g(X)\\). Esto es desde el punto de vista téorico y de conocimiento de área que tenemos (además de supuestos que provienen del diseño del estudio, si los datos son generados bajo un diseño elegido por nosotros), y representan supuestos causales. En este ejemplo particular, tenemos un modelo gráfico asociado, que escribimos como:\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n    W\n  edge [minlen = 3]\n   X -&gt; Y\n   Z -&gt; X\n   W -&gt; Y\n}\n\", width = 150, height = 40)\nNótese que no describimos exactamente cómo son las funciones que relacionan las variables, sino más bien qué variables son causas directas de qué otras. Por ejemplo, aunque en nuestro ejemplo de arriba \\(Y\\) puede estar correlacionado con \\(Z\\), no hay una causa directa a \\(Y\\), porque cambios en \\(Z\\) afectan a \\(X\\), y es el cambio en \\(X\\) que es causa directa de \\(Y\\).\nAntes de seguir, recordamos que en cualquier proceso de modelación simpre comenzamos con modelos y supuestos relativamente simples, y poco a poco, conforme los vamos entendiendo, vamos agregando más complejidad y características importantes. No es buena idea, al comenzar este proceso, tratar de poner todas las variables que nos podemos imaginar, con todas las relaciones que podemos imaginar para poder estimar todas las cantidades que nos podemos imagniar. Nuestro objetivo es acabar capturando comportamientos escenciales del sistema, para hacer estimaciones específicas que sean de utilidad. Por definición, ningún modelo conceptual o de cualquier tipo captura completamente un fenómeno real.\nNota: hay varias maneras de construir modelos causales además de DAGs. Una de ellas es sistemas de ecuaciones diferenciales (en el tiempo), que a veces son necesarias para modelos de biología, clima o epidemiología por ejemplo. También pueden utilizarse modelos de agentes (modelamos partes más pequeñas o simples del sistemas y sus interacciones). Quizá los DAGs son los modelos con más populares y tienen amplia aplicabilidad.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#modelos-gráficos",
    "href": "05-dags.html#modelos-gráficos",
    "title": "5  Modelos gráficos y causalidad",
    "section": "",
    "text": "Modelos gráficos Y DAGs\n\n\n\nEn un modelo gráfico, dibujamos una arista de un nodo \\(X\\) a un nodo \\(Y\\) si el valor de la variable \\(Y\\) depende directamente del valor de la variable \\(X\\), es decir si \\(X\\) es una causa directa de \\(Y\\). En estos modelos no especificamos la fórmula o naturaleza de cada relación directa, sino simplemente que ésta existe.\nTrabajamos principalmente con modelos causales que pueden representarse como DAGs (gráficas dirigidas acícilcas), donde no existen ciclos de causas entre las variables.\nExisten dos tipos de nodos en estas gráficas: variables exógenas que no dependen de otros nodos para tomar su valor, y variables endógenas que son descendientes de al menos otro nodo. Cuando conocemos las variables exógenas, en teoría podemos simular todo el sistema si especificamos el modelo de cada nodo endógeno.\n\n\n\n\n5.1.1 Ejemplo simple\nPara entender los conceptos empezamos con una historia de datos sencilla. En un juego de azar, supongamos que escogemos al azar un número \\(X\\) entre 0 y 1, y luego tiramos dos veces cinco volados con probabilidad de sol \\(X\\). Medimos el número de soles en cada prueba como \\(S_1\\) y \\(S_2\\). Finalmente, la ganancia \\(G\\) obtenida es la suma de \\(S_1+S_2\\) si el día es lluvioso o solamente \\(S_1\\) si el día es soleado.\nNótese que tanto como \\(S_1\\) y \\(S_2\\) dependen de su valor de \\(X\\), además de que dependen de otras variables \\(U_1\\) y \\(U_2\\), muy complicadas, que determinan cómo caen los volados. \\(G\\) depende de su valor de \\(S_1\\) y \\(S_2\\), además de depender de una variable \\(D\\) que describe si el día actual es lluvioso o soleado. El diagrama causal resultante es el que sigue, donde consideramos que observaremos \\(U1\\), \\(U2\\) y \\(U3\\).\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=circle]\n    U1\n    U2\n    U3\n    U4\n  node [shape=plaintext]\n    S1\n    S2\n    X\n  edge [minlen = 3]\n   X -&gt; S1\n   X -&gt; S2\n   U1 -&gt; S1\n   U2 -&gt; S2\n   S1 -&gt; G\n   S2 -&gt; G\n   D -&gt; G\n   U3 -&gt; D\n   U4 -&gt; X\n{\n  rank = same; S1; S2;U1;U2\n}\n\n}\n\")\n\n\n\n\n\n\nEn este ejemplos no podemos saber \\(U1\\) y \\(U2\\), y no nos interesa modelar la física de monedas, manera de lanzarlas, etc. En este ejemplo también no consideraremos qué hace que un día sea soleado o lluvioso (no nos interesa modelar el clima). En este momento, en teoría tenemos ecuaciones determinísticas para todas las variables, y si conocemos todas las variables exógenas \\(U1,U2,U3,U4\\) podríamos determinar exactamente lo que va a suceder con la ganancia, por ejemplo, o cualquier otra variable del sistema.\nSin embargo, muchas veces excluímos variables exógenas que sólo afectan a una variable endógena (o por otros argumentos no son relevantes para el problema de estimación que queremos atacar), y consideramos que las relaciones de dependiencia de la gráfica son probabilísticas:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=circle]\n   \n  node [shape=plaintext]\n    S1\n    S2\n    X\n  edge [minlen = 3]\n   X -&gt; S1\n   X -&gt; S2\n   S1 -&gt; G\n   S2 -&gt; G\n   D -&gt; G\n{\n  rank = same; S1; S2\n}\n\n}\n\")\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nUsualmente, consideramos que las flechas en un DAG indican que un cambio en el nodo padre causa un cambio en la distribución de probabilidades de los hijos (no necesariamente lo determina).\nUsamos estas distribuciones para abstraer otros efectos exógenos que determinan los hijos cuyo mecanismo no nos interesa modelar causalmente.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#modelos-gráficos-y-regla-del-producto",
    "href": "05-dags.html#modelos-gráficos-y-regla-del-producto",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.2 Modelos gráficos y regla del producto",
    "text": "5.2 Modelos gráficos y regla del producto\nLos modelos gráficos también nos muestran cómo hacer factorizaciones útiles de los datos.\nSi tenemos cualquier conjunto de variables aleatorias \\(X_1,\\ldots,X_p\\), la distibución conjunta de estas variables \\(p(x_1,x_2,\\ldots, x_p)\\) nos sirve para calcular cualquier cantidad de interés que involucra estas variables.\nRecordamos ahora la regla del producto: para cualquier conjunto de variables aleatorias \\(X_1,\\ldots,X_p\\), la conjunta se puede factorizar siempre como:\n\\[p(x_1,x_2,\\ldots, x_p) = p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\\ldots p(x_p|x_1,x_2,\\ldots,x_{p-1})\\] Hay muchas manera de escribir esta factorización, dependiendo de cómo ordenamos las variables. El modelo gráfico nos da un ordenamiento natural (primero van padres y luego hijos) de las variables que nos permite aplicar la regla del producto, según la dirección de las flechas del diagrama:\n\nEjemplo\nEn el ejemplo de arriba, un ordenamiento es \\(X,D,S1,S2,G\\). Entonces, podemos escribir la regla del producto:\n\\[p(x,s_1,s_2,d,g) = p(x)p(d|x)p(s_1|x,d)p(s_2|x,d,s_1)p(g|x,d,s1,s2)\\] Que podemos simplificar porque por ejemplo, \\(p(s_2|x, d,s_1) = p(s_2|x)\\), ya que \\(s_1\\) no influye directamente en \\(s_2\\). Por la misma lógica, \\(p(d|x) = p(d)\\) y \\(p(g|x,s_1,s_2,d) = p(g|s_1,s_2,d)\\), etc. Entonces:\n\\[p(x,s_1,s_2,d,g) = p(x)p(d)p(s_1|x)p(s_2|x)p(g|s_1,s_2,d)\\] Al incluir sólo las causas directas obtenemos una manera más parsimoniosa de modelar las relaciones entre estas variables, lo cual nos servirá más tarde cuando apliquemos modelos estadísticos para aprender de estas relaciones. Bajo nuestros supuestos no es necesario modelar toda la cadena de dependencias, pues algunas flechas no están presentes.\nEn nuestro caso, suponemos de acuerdo con lo que sabemos:\n\n\\(p(x)\\) es uniforme en \\([0,1]\\),\nSupondremos por ejemplo que \\(p(d=lluvioso) =0.3\\) (tomando un día del año al azar),\n\\(S_1|X\\) y \\(S_2|X\\) son binomiales con 5 pruebas y probabilidad \\(X\\), y\n\\(G|S_1,S_2,D\\) es determinística: \\(G\\) toma el valor \\(S_1+ S_2\\) si \\(D\\) es lluvioso, y \\(S_1\\) en otro caso. Con esto, tenemos un modelo conjunto completo del sistema de interés.\n\n\n\nEjemplo\nPara entender mejor la parsimonia que podemos alcanzar usando supuestos causales, considera la cadena \\(X\\to Y\\to Z\\to W\\to A\\). Imagina que cada una de estas variables puede tomar 2 valores. La conjunta de cinco variables binarias \\((X,Y,Z,W,A)\\), en general, requiere de \\(2^5-1=31\\) parámetros. Sin embargo, si se satisface \\(X\\to Y\\to Z\\to W\\to A\\) sólo requirimos 1 parámetro para \\(p(x)\\), 2 para \\(p(y|x)\\), 2 para \\(p(z|y)\\), etc. En total, sólo necesitamos 9 parámetros.\n\n\n\n\n\n\nRegla del producto para DAGs\n\n\n\nSupongamos que tenemos un DAG con variables \\(X_i\\). Si denotamos por \\(pa_i\\) a los padres de \\(X_i\\), entonces siempre podemos factorizar la conjunta como\n\\[p(x_1,\\ldots, x_p) = \\prod_{i=1}^p p(x_i|pa_i)\\] Las posibles conjuntas que satisfacen esta ecuación decimos que son consistentes con el DAG.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#regla-del-producto-y-simulación",
    "href": "05-dags.html#regla-del-producto-y-simulación",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.3 Regla del producto y simulación",
    "text": "5.3 Regla del producto y simulación\nEl orden del modelo gráfico también nos indica cómo simular las variables de la gráfica. Como cada modelo gráfico nos da una factorización de la conjunta, podemos utlizar esta para simular datos una vez que conocemos o estimamos las relaciones de dependencia directa. Empezamos con las variables exógenas (que no tienen padres) y vamos simulando hacia adelante.\n\nEjemplo\nEn nuestro ejemplo simulamos primero \\(X\\) y \\(D\\). A partir de \\(X\\) podemos simular \\(X_1\\) y \\(S_2\\), y a partir de \\(D\\), junto con \\(S_1\\) y \\(S_2\\), podemos simular \\(G\\). En nuestro ejemplo tendríamos\n\nsimular_juego &lt;- function(N){\n  x &lt;- runif(N)\n  d &lt;- sample(c(\"lluvioso\",\"soleado\"), N, replace = TRUE, prob = c(0.3,0.7))\n  s1 &lt;- rbinom(N, 5, x)\n  s2 &lt;- rbinom(N, 5, x)\n  g &lt;- ifelse(d==\"lluvioso\", s1+s2, s1)\n  tibble(x, d, s1, s2, g)\n}\nsimular_juego(5)\n\n# A tibble: 5 × 5\n       x d          s1    s2     g\n   &lt;dbl&gt; &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 0.432  soleado     1     3     1\n2 0.0598 soleado     0     0     0\n3 0.392  soleado     1     2     1\n4 0.112  soleado     1     0     1\n5 0.118  soleado     1     1     1",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#estructuras-básicas-de-dags",
    "href": "05-dags.html#estructuras-básicas-de-dags",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.4 Estructuras básicas de DAGs",
    "text": "5.4 Estructuras básicas de DAGs\nVeremos que para razonar acerca de las asociaciones e independencias (condicionales o no) que pueden aparecer o no en una conjunta, podemos examinar la gráfica que la represente, o dicho de otra manera, entender bajo qué condiciones puede propagarse información de un nodo a otro.\nRecuerda qué es la independencia condicional. Decimos por ejemplo que \\(X\\) y \\(Y\\) son condicionalmente independientes dada \\(Z\\) cuando se cumplen las siguientes ecuaciones equivalentes:\n\n\\(p(x|y,z) = p(x |z)\\)\n\\(p(y|x,z) = p(y|z)\\)\n\\(p(x,y|z) = p(x|z)p(y|z)\\)\n\nEs decir, en estos casos si conocemos \\(Y\\), por ejemplo, información acerca de \\(Z\\) no cambia la condicional \\(p(y|x,z)=p(y|z)\\). También vemos que la conjunta de \\(X\\) y \\(Y\\) condicionada a \\(Z\\) se factoriza como el producto de las condicionales de \\(X\\) y \\(Y\\) dada \\(Z\\).\nEste es un concepto fundamental en estadística, y también en inferencia causal. Como vimos arriba, nos permite construir modelos para sistemas considerablemente grandes, pues muchas veces las relaciones causales directas importantes son ralas (es decir, no todo está conectado con todo).\n\n\n\n\n\n\nIndependencia condicional\n\n\n\nLas independencias condicionales que forzosamente se cumplen para cualquier relación funcional entre variables del sistema (o dicho de otra manera, cualquier conjunta consistente con el DAG), pueden leerse directamente de la estructura del modelo gráfico (DAG) correspondiente (ver definición de \\(d\\)-separación más adelante).\n\nEsto nos permite hacer razonamiento lógico de qué puede estar asociado o no según nuestros supuestos causales.\nNota: Pueden existir otras independencias condicionales adicionales para algunas conjuntas que no necesariamente están representadas en el DAG, dependiendo de la forma particular de las asociaciones en la conjunta.\n\n\n\nPara entender modelos gráficos en general, y qué independencias condicionales implican o no, basta endender cuatro estructuras básicas que pueden aparecer. ßConsideremos tres variables \\(X\\), \\(Y\\) y \\(Z\\). Las cuatro estructuras que tenemos que entender en primer lugar pueden verse también como métodos de razonamiento lógico derivados de las leyes de probabilidad:\n\nCausa común o bifurcaciones \\(X\\leftarrow Z \\rightarrow Y\\).\nCadenas o mediación \\(X\\rightarrow Z \\rightarrow Y\\).\nColisionadores \\(X\\rightarrow Z \\leftarrow Y\\).\nDescendientes, como en \\(X\\rightarrow Z \\rightarrow Y, Z\\to A\\).\n\nTodas estas estructuras pueden ser fuente de confusión, en el sentido de que producen patrones de correlación que pueden ser malinterpretados causalmente si no utilizamos supuestos causales.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#bifurcaciones-o-causa-común",
    "href": "05-dags.html#bifurcaciones-o-causa-común",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.5 Bifurcaciones o causa común",
    "text": "5.5 Bifurcaciones o causa común\nEn el siguiente ejemplo, llamamos a \\(Z\\) una causa que es común a \\(X\\) y \\(Y\\).\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   Z -&gt; X\n   Z -&gt; Y\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) tienen asociación\nSi condicionamos (o estratificamos) con \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nEste tipo de estructura también se llama bifurcación, o decimos más tradicionalmente que \\(Z\\) es un confusor en esta gráfica. Variación en \\(Z\\) produce variación conjunta de \\(X\\) y \\(Y\\).\nPor ejemplo, podríamos encontrar que el uso de aspirina \\(X\\) está asociado a una mortalidad más alta \\(Y\\). Una causa común es enfermedad grave que produce dolor (\\(Z\\)). Sin embargo, si condicionamos a personas sanas, veríamos que no hay relación entre uso de aspirina y mortalidad, igualmente veríamos que entre las personas enfermas el uso de aspirina no les ayuda a vivir más tiempo.\nEn este caso, tenemos:\n\\[p(x, y, z) =  p(z)p(x|z)p(y|z)\\] Y como el lado izquierdo es igual (en general) a \\(p(x,y|z)p(z)\\), obtenemos la independiencia condicional de \\(X\\) y \\(Y\\) dado \\(Z\\).\n\nEjemplo (simulación)\n\nrbern &lt;- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_confusor &lt;- function(n = 10){\n  z &lt;- rbern(n, p = 0.5) |&gt; as.numeric()\n  x &lt;- rbern(n, p = z * 0.3 + (1 - z) * 0.8)\n  y &lt;- rbinom(n, 4, z * 0.9 + (1 - z) * 0.3)\n  tibble(x, z, y)\n}\nsims_confusor &lt;- simular_confusor(50000)\n\n\\(X\\) y \\(Y\\) están asociadas\n\nsims_confusor |&gt; select(x, y) |&gt; \n  count(x, y) |&gt; \n  group_by(x) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\n\n\n\n\nLo cual lo vemos también si calculamos la correlación:\n\ncor(sims_confusor |&gt; select(x,y)) |&gt; round(3)\n\n       x      y\nx  1.000 -0.419\ny -0.419  1.000\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1, vemos que \\(X\\) y \\(Y\\) son independientes, o dicho de otra manera, la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\):\n\nsims_confusor |&gt; \n  count(x, y, z) |&gt; \n  group_by(x, z) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, z, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\n\n\n\n\nUna consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_confusor |&gt; filter(z == 1) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.009\ny 0.009 1.000\n\ncor(sims_confusor |&gt; filter(z == 0) |&gt; select(x,y)) |&gt; round(3)\n\n       x      y\nx  1.000 -0.003\ny -0.003  1.000\n\n\nUn ejemplo con variables continuas podría ser como sigue:\n\nsimular_bifurcacion &lt;- function(n = 10){\n  z &lt;- rbern(n, p = 0.5)\n  x &lt;- rnorm(n, 100 + 20 * z, 15)\n  y &lt;- rnorm(n, 100 + 30 * z, 20)\n  tibble(x, z, y)\n}\nsims_bifurcacion &lt;- simular_bifurcacion(5000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 1, se = FALSE)\n\n\n\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_bifurcacion, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point(alpha = 0.2) +\n  geom_smooth(span = 2)\n\n\n\n\n\n\n\n\n\n\nEjemplo: matrimonio y divorcio\nEn este ejemplo de McElreath (2020), se muestra que regiones de Estados Unidos con tasas más altas de matrimonio también tienen tasas más altas de divorcio.\n\ndata(WaffleDivorce)\nWaffleDivorce |&gt; \n  ggplot(aes(x = Marriage, y = Divorce)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAunque esta es una correlación clara, lo que nos interesa en este caso el efecto causal \\(M\\to D\\). Es importante notar que hay considerable variabilidad de la edad promedio al casarse a lo largo de los estados, como vemos en la siguiente gráfica de cuantiles normales:\n\nWaffleDivorce |&gt; \n  ggplot(aes(sample = MedianAgeMarriage)) +\n  geom_qq() +\n  geom_qq_line() + ylab(\"Edad promedio al casarse\") + xlab(\"z\")\n\n\n\n\n\n\n\n\nPara el modelo causal, tenemos que considerar las siguientes afirmaciones que no son muy difíciles de justificar:\n\nLa edad promedio al casarse de cada estado es un factor que influye en la tasa de divorcio (menor edad a casarse implica mayores tasas de divorcio, pues las parejas tienen más tiempo para divorciarse. Piensa en otras posibles razones).\nAdicionalmente, si la gente tiende a casarse más joven, en cualquier momento hay más gente con probabilidad de casarse, por lo que esperaríamos que la edad al casarse también influye en la tasa de matrimonio.\n\nEsto implica que tenemos que considerar una causa común de la edad al casarse en nuestro diagrama causal:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    M\n    D\n    Edad\n  edge [minlen = 3]\n   Edad -&gt; M\n   Edad -&gt; D\n   M -&gt; D\n{rank=same; M; D;}\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nPor la discusión de arriba, es claro que es necesario considerar la edad al casarse si queremos estimar el efecto de tasa de matrimonio en la tasa de divorcio. Es posible que la correlación entre estas dos tasas puede ser explicada solamente por la edad al casarse, y que en realidad al flecha \\(M\\to D\\) sea muy débil o inexistente.\nYa que tenemos este modelo causal básico, tendríamos que proponer un proceso generador, proponer un modelo estadístico, y probar nuestra estimación. Este paso nos lo saltaremos (ver sección anterior), aunque sigue siendo necesario.\nPor el momento recordemos que si condicionamos (se dice también estratificar) por edad al casarse, y no vemos relación condicional entre las dos tasas, la relación que vimos en los datos es factible que haya aparecido por la causa común que induce correlación. Una manera en que estratificamos o condicionamos a una variable continua en un modelo lineal, como sigue:\n\\[D_i\\sim N(\\mu_i, \\sigma)\\] donde \\[\\mu_i = \\alpha + \\beta_M M_i + \\beta_E Edad_i\\] ¿De qué manera estamos estratificando por edad en este ejemplo? Obsérvese que para cada Edad que fijemos, la relación entre \\(M\\) y \\(D\\) es:\n\\[\\mu_i = (\\alpha + \\beta_E Edad) + \\beta_M M_i  \\] Cada valor de \\(E\\) produce una relación diferente entre \\(M\\) y \\(D\\) (en este caso particular, una recta diferente con distinta altura).\nAhora tenemos que poner iniciales para terminar nuestro modelo estadístico. En este punto poner iniciales informadas para estos coeficientes puede ser complicado (depende de cuánta demografía sabemos). Podemos usar un enfoque más simple, considerando las variables estandarizadas. De esta forma podemos poner iniciales más estándar. Utilizaremos\n\nescalar &lt;- function(x){\n  (x - mean(x))/sd(x)\n}\nWaffleDivorce &lt;- WaffleDivorce |&gt; \n  mutate(Marriage_est = escalar(Marriage), \n         Divorce_est = escalar(Divorce), \n         MedianAgeMarriage_est = escalar(MedianAgeMarriage))\ndatos_lista &lt;- list(\n  N = nrow(WaffleDivorce),\n  d_est = WaffleDivorce$Divorce_est, \n  m_est = WaffleDivorce$Marriage_est, \n  edad_est = WaffleDivorce$MedianAgeMarriage_est)\n\n\nmod_mat_div &lt;- cmdstan_model(\"./src/matrimonio-divorcio-1.stan\")\nprint(mod_mat_div)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N]  d_est;\n  vector[N]  m_est;\n  vector[N]  edad_est;\n}\n\nparameters {\n  real alpha;\n  real  beta_M;\n  real  beta_E;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] w_media;\n  // determinístico dado parámetros\n  w_media = alpha + beta_M * m_est + beta_E * edad_est;\n}\n\nmodel {\n  // partes no determinísticas\n  d_est ~ normal(w_media, sigma);\n  alpha ~ normal(0, 1);\n  beta_M ~ normal(0, 0.5);\n  beta_E ~ normal(0, 0.5);\n  sigma ~ normal(0, 1);\n}\n\ngenerated quantities {\n  real dif;\n  {\n    //simulamos 50 estados\n    int M = 50;\n    array[M] real dif_sim;\n    for(i in 1:M){\n      real edad_sim_est = normal_rng(0, 1);\n      // fijamos el valor de M en 0 y 1 para el modelo con do(M)\n      real M_sim_0 = normal_rng(alpha * beta_M * 0 + beta_E * edad_sim_est, sigma);\n      real M_sim_1 = normal_rng(alpha * beta_M * 1 + beta_E * edad_sim_est, sigma);\n      dif_sim[i] = M_sim_1 - M_sim_0;\n    }\n    dif = mean(dif_sim);\n  }\n\n}\n\n\n\nsims_mod &lt;- mod_mat_div$sample(data = datos_lista, \n                   chains = 4, \n                   init = 0.1, step_size = 0.1,\n                   iter_warmup = 1000, \n                   iter_sampling = 1000,\n                   refresh = 0)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nresumen &lt;- sims_mod$summary(c(\"alpha\", \"beta_M\", \"beta_E\", \"sigma\"))\n\n\nresumen |&gt; \n  ggplot(aes(x = variable, y = mean, ymin = q5, ymax = q95)) +\n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_point() +\n  geom_linerange() +\n  coord_flip()\n\n\n\n\n\n\n\n\nY el resultado que obtenemos es que no observamos un efecto considerable de las tasas de matrimonio en las tasas de divorcio, una vez que estratificamos por la causa común de edad de matrimonio. Este ejemplo es simple y podemos ver el efecto causal directo en un sólo coeficiente \\(\\beta_M\\), pero de todas formas haremos contrastes como hicimos en la parte anterior.\n\n\n5.5.1 Simulando intervenciones\nLa manera más directa de definir efecto causal, bajo nuestros supuestos causales, es a través de intervenciones (imaginarias o reales).\n\n\n\n\n\n\nNota\n\n\n\nDefiniremos el concepto de “medir un efecto causal” como una } predección correcta las consecuencias de una intervención particular en el sistema generador de datos.\n\n\nEn nuestro caso, el diagrama de arriba muestra nuestro modelo causal. Si nosotros alteramos este proceso causal, interviniendo en la tasa de matrimonio, la distribución de matrimonio ya no depende de la Edad (pues está bajo nuestro control). Esto quiere decir que ahora consideramos el siguiente diagrama, en donde la nueva dependendencia del divorcio del matrimonio la escribiremos como \\(p(D|do(M))\\):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    M\n    D\n    Edad\n  edge [minlen = 3]\n   Edad -&gt; D\n   M -&gt; D\n{rank=same; M; D;}\n\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEs decir, borramos todas las flechas que caen en \\(M\\) (pues la estamos interveniendo al valor que queramos), y luego simulando \\(D\\).\nEn nuestro ejemplo (ve el código de Stan de arriba, la parte de generated quantities) simularemos los 50 estados bajo dos intervenciones: todos tienen la tasa promedio de matrimonio vs. los 50 estados con tasa de matrimonio un error estándar por encima de la tasa promedio. Repetimos esta comparación sobre todas las simulaciones de la posterior:\n\nsims_tbl &lt;- sims_mod$draws(format = \"df\") |&gt; \n  select(dif) \nsims_tbl |&gt; summarize(\n  q5 = quantile(dif, 0.05),\n  q95 = quantile(dif, 0.95)\n)\n\n# A tibble: 1 × 2\n      q5   q95\n   &lt;dbl&gt; &lt;dbl&gt;\n1 -0.279 0.258\n\n\n\nggplot(sims_tbl, aes(x = dif)) +\n  geom_histogram(bins = 50) +\n  geom_vline(xintercept = 0, color = \"red\")\n\n\n\n\n\n\n\n\nEn este caso, vemos que el resultado de la intervención no tienen una tendencia clara hacia incrementar o disminuir la tasa de divorcio, aunque existe variabilidad por la incertidumbre que tenemos acerca de las relaciones modeladas.\n\n\n\n\n\n\nTip\n\n\n\nLa relación que vimos entre matrimonio y divorcio en nuestro ejemplo es probablemente producida por la causa común Edad, y no necesariamente es causal.\n\n\nFinalmente, antes de terminar sería apropiado hacer chequeos predictivos posteriores, pero por el momento los omitiremos para avanzar en los otros tipos de estructuras básicas en los DAGs.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#cadenas-o-mediación",
    "href": "05-dags.html#cadenas-o-mediación",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.6 Cadenas o mediación",
    "text": "5.6 Cadenas o mediación\nEn este caso tenemos:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -&gt; Z\n   Z -&gt; Y\n}\n\", width = 150, height = 20)\n\n\n\n\n\n\nEn este caso,\n\nExiste asociación entre \\(X\\) y \\(Y\\), pero no existe relación directa entre ellas. Decimos que \\(Z\\) es un mediador del efecto de \\(X\\) sobre \\(Y\\).\nSi condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) son condicionalmente independientes.\n\nPodemos pensar en \\(Z\\) como un mediador del efecto de \\(X\\) sobre \\(Y\\). Si no permitimos que \\(Z\\) varíe, entonces la información de \\(X\\) no fluye a \\(Y\\).\nPor ejemplo, si \\(X\\) tomar o no una medicina para el dolor de cabeza, \\(Z\\) es dolor de cabeza y \\(Y\\) es bienestar general, \\(X\\) y \\(Y\\) están relacionadas. Sin embargo, si condicionamos a un valor fijo de dolor de cabeza, no hay relación entre tomar la medicina y bienestar general.\nEn términos de factorización, podemos checar la independencia condicional: como \\(p(x,y,z) = p(x)p(z|x)p(y|z)\\), entonces\n\\[p(x, y | z) = p(x,y,z) / p(z) = (p(x)(z|x)) (p(y|z) / p(z))\\] y vemos que el lado izquierdo se factoriza en una parte que sólo involucra a \\(x\\) y \\(z\\) y otro factor que sólo tiene a \\(y\\) y \\(z\\): no hay términos que incluyan conjuntamente a \\(x\\), \\(y\\) y \\(z\\). Podemos de cualquier forma continuar notando\n\\[p(x)p(z|x)/p(z) = p(x,z)/p(z) = p(x | z)\\] de modo que\n\\[p(x, y | z) = p(x|z) p(y|z) \\]\nY mostramos un ejemplo simulado:\n\nrbern &lt;- function(n, prob){\n  rbinom(n, 1, prob = prob)\n} \nsimular_mediador &lt;- function(n = 10){\n  x &lt;- rbern(n, p = 0.5) |&gt; as.numeric()\n  z &lt;- rbern(n, p = x * 0.8 + (1 - x) * 0.3)\n  y &lt;- rbinom(n, 2, z * 0.7 + (1 - z) * 0.5)\n  tibble(x, z, y)\n}\nsims_mediador &lt;- simular_mediador(50000)\n\n\\(X\\) y \\(Y\\) son dependientes:\n\nsims_mediador |&gt; select(x, y) |&gt; \n  count(x, y) |&gt; \n  group_by(x) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\n\n\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_mediador |&gt; \n  count(x, y, z) |&gt; \n  group_by(x, z) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, z, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) sólo depende de \\(Z\\). Una consecuencia es por ejemplo que la correlación debe ser cero:\n\ncor(sims_mediador |&gt; filter(z == 1) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx  1.00 -0.01\ny -0.01  1.00\n\ncor(sims_mediador |&gt; filter(z == 0) |&gt; select(x,y)) |&gt; round(3)\n\n       x      y\nx  1.000 -0.004\ny -0.004  1.000\n\n\nPodemos también hacer un ejemplo continuo:\n\nsimular_mediador &lt;- function(n = 10){\n  x &lt;- rnorm(n, 100, 10)\n  prob &lt;- 1 / (1 + exp(-(x - 100)/5))\n  z &lt;- rbern(n, p = prob)\n  y &lt;- rnorm(n, 100 + 30 * z, 15)\n  tibble(x, z, y)\n}\nsims_mediador &lt;- simular_mediador(2000)\n\n\\(X\\) y \\(Y\\) son dependientes (por ejemplo si vemos la media condicional de \\(Y\\) dado \\(X\\):\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z)) + geom_point() +\n  geom_smooth(span = 1, se = FALSE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: The following aesthetics were dropped during statistical transformation:\ncolour.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\nSi condicionamos a \\(Z\\), no hay dependencia entre \\(X\\) y \\(Y\\)\n\nggplot(sims_mediador, aes(x = x, y = y, colour = z, group = z)) + \n  geom_point() +\n  geom_smooth(span = 2)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nNótese que en este ejemplo sí hay un efecto causal de \\(X\\) sobre \\(Y\\), pero está mediado por otra variable \\(Z\\). Si condicionamos a \\(Z\\), no hay relación entre \\(X\\) y \\(Y\\). El análisis condicionado podría llevarnos a una conclusión errónea de que \\(X\\) no influye sobre \\(Y\\).\n\n\n\n\n\n\nTip\n\n\n\nNota que no existe una diferencia estadística entre una bifurcación y una cadena: en ambos casos, las variables \\(X\\) y \\(Y\\) están correlacionadas, y son independientes una vez que condicionamos o estratificamos por \\(Z\\). Sin embargo, su tratamiento en inferencia causal es muy diferente.\n\n\n\nSesgo post-tratamiento\nEn McElreath (2020) se discute que en algunos estudios experimentales, se estratifica por variables que son consecuencia del tratamiento. Esto induce sesgo post-tratamiento, lo cual puede llevar a equivocaciones en donde parece que el tratamiento no tiene efecto cuando sí lo tiene. Incluso bajo condiciones de experimento (donde el tratamiento es asignado al azar) estratificar por mediadores es una mala idea. Ver más en McElreath (2020), donde por ejemplo cita una fuente que en estudios experimentales de Ciencia Política, casi la mitad de ellos sufre de este tipo de sesgo por estratificación por mediadores.\n\n\nEjemplo: Burks\nEste ejemplo es de Pearl y Mackenzie (2018). En 1926 Burks recolectó datos sobre qué tanto podría esperarse que la inteligencia de padres se hereda a los hijos (medido según una prueba de IQ). Construyó un diagrama parecido al de abajo:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape = circle]\n    U\n  node [shape=plaintext]\n  edge [minlen = 3]\n    IntPadres -&gt; NSE\n    NSE -&gt; IntHijos\n    U -&gt; NSE\n    U -&gt; IntHijos\n    IntPadres -&gt; IntHijos\n{rank = same; U}\n}\n\")\n\n\n\n\n\n\nComo el NSE es del hogar (una medida general de estatus social), se consideró en principio como una variable pre-tratamiento a la inteligencia de los niños por la que tradicionalmente se controlaba. Burks notó que hacer esto tenía no era apropiado, pues tiene como consecuencia cortar parte del efecto total de la inteligencia sobre el la inteligencia de los hijos. En otras palabras: la inteligencia de los padres hace más probable mejor NSE, y mejor NSE presenta mejores condiciones de desarrollo para sus hijos. Estatificar por esta variable bloquea este efecto.\nAdicionalmente, como veremos, condicionar a NSE abre un camino no causal entre Inteligencia de Padres e Hijos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#colisionador-o-causas-alternativas",
    "href": "05-dags.html#colisionador-o-causas-alternativas",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.7 Colisionador o causas alternativas",
    "text": "5.7 Colisionador o causas alternativas\nEn este caso, a \\(Z\\) también le llamamos un colisionador. Este es el caso que puede ser más difícil de entender en un principio. Consiste de la siguiente estructura:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n  edge [minlen = 3]\n   X -&gt; Z\n   Y -&gt; Z\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\n\nEn este caso \\(X\\) y \\(Y\\) son independientes. Tanto \\(X\\) como \\(Y\\) influyen en \\(Z\\).\nSin embargo, si condicionamos a \\(Z\\) entonces \\(X\\) y \\(Y\\) están asociados.\n\nPor ejemplo, si observamos que el pasto está mojado, entonces saber que no llovió implica que probablemente se encendieron los aspersores.\nComo la conjunta se factoriza como:\n\\[p(x,y,z) = p(x)p(y)p(z|x,y)\\] Entonces integrando sobre \\(Z\\):\n\\[p(x,y) = \\int p(x,y,z)dz = p(x)p(y)\\int p(z|x,y)\\, dz\\] pero \\(p(z|x,y)\\) integra uno porque es una densidad, de forma que \\(x\\) y \\(y\\) son independientes.\nMostramos un ejemplo simulado:\n\nsimular_colisionador &lt;- function(n = 10){\n  x &lt;- rbern(n, 0.5) \n  y &lt;- rbinom(n, 2, 0.7)\n  z &lt;- rbern(n, p = 0.1 + 0.7 * x * (y &gt; 1)) \n  tibble(x, z, y)\n}\nsims_colisionador &lt;- simular_colisionador(50000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nsims_colisionador|&gt; select(x, y) |&gt; \n  count(x, y) |&gt; \n  group_by(x) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") +\n  labs(subtitle = \"Condicional de Y dada X\")\n\n\n\n\n\n\n\ncor(sims_colisionador |&gt; select(x,y))\n\n             x            y\nx  1.000000000 -0.002340799\ny -0.002340799  1.000000000\n\n\nSin embargo, si condicionamos a \\(Z\\), que puede tomar los valores 0 o 1:\n\nsims_colisionador |&gt; \n  count(x, y, z) |&gt; \n  group_by(x, z) |&gt; \n  mutate(p_cond = n / sum(n)) |&gt;\n  select(x, y, z, p_cond) |&gt; \nggplot(aes(x = y, y = p_cond, fill = factor(x))) +\n  geom_col(position = \"dodge\") + facet_wrap(~ z) +\n  labs(subtitle = \"Condicional de Y dada X y Z\")\n\n\n\n\n\n\n\n\nY vemos que la condicional de \\(Y\\) dada \\(Z\\) y \\(X\\) depende de \\(X\\) y de \\(Z\\).\nLas correlaciones condicionales, por ejemplo, no son cero:\n\nprint(\"Dado Z = 0\")\n\n[1] \"Dado Z = 0\"\n\ncor(sims_colisionador |&gt; filter(z == 0) |&gt; select(x,y)) |&gt; round(3)\n\n       x      y\nx  1.000 -0.282\ny -0.282  1.000\n\nprint(\"Dado Z = 1\")\n\n[1] \"Dado Z = 1\"\n\ncor(sims_colisionador |&gt; filter(z == 1) |&gt; select(x,y)) |&gt; round(3)\n\n      x     y\nx 1.000 0.358\ny 0.358 1.000\n\n\nOtro ejemplo con variables continuas:\n\nsimular_colisionador_2 &lt;- function(n = 10){\n  x &lt;- rnorm(n, 100, 20) \n  y &lt;- rnorm(n, 100, 20)\n  z &lt;- rbern(n, p = 0.92 * ((x + y) &gt; 220) + 0.05) \n  tibble(x, z, y)\n}\nsims_colisionador &lt;- simular_colisionador_2(1000)\n\n\\(X\\) y \\(Y\\) son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y)) + geom_point()\n\n\n\n\n\n\n\n\nSin embargo, si condicionamos a un valor de \\(Z\\), \\(X\\) y \\(Y\\) ya no son independientes:\n\nggplot(sims_colisionador, aes(x = x, y = y, group = z, colour = factor(z))) + \n  geom_point() + geom_smooth(method = \"lm\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nY vemos que condicional a \\(Z\\), \\(X\\) y \\(Y\\) están correlacionadas, aunque no hay relación causal entre \\(X\\) y \\(Y\\).\n\n5.7.1 Ejemplos de colisionadores\nExisten muchos ejemplos de colisionadores en análisis de datos. Algunos ejemplos se deben a sesgo de selección (puedes dibujar diagramas para cada uno de estos):\n\nPodemos observar correlaciones entre habilidades que en realidad son independientes si observamos muestras de estudiantes seleccionados por un examen de admisión (por ejemplo, para entrar es necesario tener alta habilidad atlética y/o alta habilidad académica).\nEntre los artículos científicos publicados (ver McElreath (2020)), aquellos que son más tomados por las noticias son los menos confiables. Esta correlación puede aparecer aunque no exista relación en proyectos científicos entre confiabilidad e interés de los medios, pues lo que se fondea o publica puede tener dos razones: ser trabajo muy confiable, o ser trabajo que “está de moda” o atrae la atención de los medios.\n\nPero también puede ser consecuencia de condicionar a variables endógenos (que resultan ser colisionadores), y ocurren como parte del procesamiento o construcción de modelos. Un ejemplo interesante de McElreath (2020) es el siguiente:\n\nNos interesa saber si la edad influye en la felicidad o bienestar de las personas.\nAlgún investigador puede pensar que es necesario controlar por sí las personas están casadas o no, por ejemplo, para “quitar” ese efecto o algo así.\nEsto puede ser mala idea si consideramos que un diagrama apropiado puede ser \\(F \\rightarrow Matrim \\leftarrow Edad\\), que se basa en las observaciones de que personas más felices generalmente tienen mayor posibilidad de casarse, y también conforme pasa el tiempo, hay más oportunidades para casarse.\nEsto induce una correlación no causal entre edad y felicidad dentro de los grupos de casados y no casados, y puede llevar a conclusiones incorrectas.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#razonamiento-de-descendientes",
    "href": "05-dags.html#razonamiento-de-descendientes",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.8 Razonamiento de descendientes",
    "text": "5.8 Razonamiento de descendientes\nCondicionar a un descendiente puede entenderse como “condicionar parcialmente” o “débilmente” a los padres de ese descendiente.\nPor ejemplo, condicionar a un colisionador también produce dependencias condicionales:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X\n    Y\n    Z\n    A\n  edge [minlen = 3]\n   X -&gt; Z\n   Y -&gt; Z\n   Z -&gt; A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEn este caso,\n\n\\(X\\) y \\(Y\\) son independientes\n\\(X\\) y \\(Y\\) son dependientes si condicionamos a \\(A\\).\n\nDependiendo de la naturaleza de la asociación entre el colisionador \\(Z\\) y su descendiente \\(A\\), esta dependencia puede ser más fuerte o más débil.\nPor ejemplo, en nuestro ejemplo donde el pasto mojado es un colisionador entre cuánta agua dieron los aspersores y cuánta lluvia cayó, un descendiente del pasto mojado es el estado de las plantas del jardín. Aunque los aspersores trabajan independientemente de la lluvia, si observamos que las plantas se secaron entonces lluvia y aspersores están correlacionados: por ejemplo, si noto que los aspersores están descompuestos, entonces concluimos que no hubo lluvia.\n\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    X [label = lluvia]\n    Y [label = aspersores]\n    Z [label = humedad]\n    A [label = plantas]\n  edge [minlen = 3]\n   X -&gt; Z\n   Y -&gt; Z\n   Z -&gt; A\n}\n\", width = 200, height = 50)\n\n\n\n\n\n\nEjemplo\n\nsimular_desc &lt;- function(n = 10){\n  x &lt;- rbern(n, 0.5) \n  y &lt;- rbinom(n, 2, 0.7)\n  z &lt;- rbern(n, p = 0.1 + 0.7 * x * (y &gt; 1)) \n  a &lt;- rbern(n, p = 0.5 + 0.5 * z)\n  tibble(x, z, y, a)\n}\nsims_colisionador &lt;- simular_desc(50000)\n# No hay correlación\ncor(sims_colisionador$x, sims_colisionador$y)\n\n[1] 0.001632879\n\n\nSin embargo,\n\ncor(sims_colisionador |&gt; filter(a ==0) |&gt; select(x,y))\n\n           x          y\nx  1.0000000 -0.2742646\ny -0.2742646  1.0000000\n\n\n\ncor(sims_colisionador |&gt; filter(a ==1) |&gt; select(x,y))\n\n          x         y\nx 1.0000000 0.1106173\ny 0.1106173 1.0000000\n\n\n\n\n5.8.1 Ejemplo: dependencias de colisionador\nVerificamos que en nuestro modelo de Santa Clara, efectivamente nuestro modelo no implica ninguna dependencia no condicional entre sensibilidad de la prueba y prevalencia. Eso debería ser claro de la simulación, pero de todas formas lo checamos\n\nlibrary(cmdstanr)\nmod_sc &lt;- cmdstan_model(\"./src/sclara.stan\")\nprint(mod_sc)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n;\n  int&lt;lower=0&gt; kit_pos;\n  int&lt;lower=0&gt; n_kit_pos;\n  int&lt;lower=0&gt; kit_neg;\n  int&lt;lower=0&gt; n_kit_neg;\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; //seroprevalencia\n  real&lt;lower=0, upper=1&gt; sens; //sensibilidad\n  real&lt;lower=0, upper=1&gt; esp; //especificidad\n}\n\ntransformed parameters {\n  real&lt;lower=0, upper=1&gt; prob_pos;\n\n  prob_pos = theta * sens + (1 - theta) * (1 - esp);\n\n}\nmodel {\n  // modelo de número de positivos\n  n ~ binomial(N, prob_pos);\n  // modelos para resultados del kit\n  kit_pos ~ binomial(n_kit_pos, sens);\n  kit_neg ~ binomial(n_kit_neg, esp);\n  // iniciales para cantidades no medidas\n  theta ~ beta(1.0, 10.0);\n  sens ~ beta(2.0, 1.0);\n  esp ~ beta(2.0, 1.0);\n}\n\n\nEn este caso, no pondremos información acerca de positivos en la prueba:\n\ndatos_lista &lt;- list(N = 0, n = 0,\n kit_pos = 103, n_kit_pos = 122,\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nggplot(sims, aes(x = theta, y = sens)) + geom_point() +\n  scale_x_sqrt()\n\n\n\n\n\n\n\n\nNo vemos ninguna asocación entre estas dos variables.\nSin embargo, al condicionar al valor de Positivos, creamos una relación que no podemos interpretar como casual. En este caso particular supondremos prácticamente fija la sensibilidad para ver solamente lo que sucede en el colisionador de especificidad y número de positivos (la especificidad en este ejemplo es más crítica):\n\ndatos_lista &lt;- list(N = 3300, n = 50,\n kit_pos = 1030000, n_kit_pos = 1220000, # números grandes para que esté practicamente\n# fija la sensibilidad\n kit_neg = 399, n_kit_neg = 401)\najuste &lt;- mod_sc$sample(data = datos_lista, refresh = 1000, iter_sampling = 400)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 1 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 1 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 2 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 2 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 3 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 3 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 1400 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 1400 [ 71%]  (Warmup) \nChain 4 Iteration: 1001 / 1400 [ 71%]  (Sampling) \nChain 4 Iteration: 1400 / 1400 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\nsims &lt;- ajuste$draws(c(\"theta\", \"sens\", \"esp\"), format = \"df\")\nresumen &lt;- ajuste$summary(c(\"theta\"))\n\n\nggplot(sims, aes(x = theta, y = esp)) + geom_point() \n\n\n\n\n\n\n\n\nY vemos que condiconando al colisionador, obtenemos una relación fuerte entre prevalencia y especificidad de la prueba: necesitaríamos más datos de especificidad para obtener una estimación útil.\n\nLa razón de que la especificidad es más importante en este ejemplo es que la prevalencia es muy baja al momento del estudio, y los falsos positivos pueden introducir más error en la estimación\nTambién repetimos nótese que el análisis correcto de estos datos no se puede hacer con intervalos separados para cada cantidad, sino que debe examinarse la conjunta de estos parámetros.\n\n\nCon estas tres estructuras elementales podemos entender de manera abstracta la existencia o no de asociaciones entre nodos de cualquier gráfica dirigida.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#d-separación",
    "href": "05-dags.html#d-separación",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.9 d-separación",
    "text": "5.9 d-separación\nAhora buscaremos describir todas las posibles independendencias condicionales y no condicionales que pueden aparecer en una gráfica, para entender cómo aparecen asociaciones entre variables de nuestro modelo, dependiendo del tipo de condicionamiento que hacemos.\nVeremos que el criterio es algorítmico. Más adelante discutiremos cuáles de estas asociaciones se deben a efectos causales y cuáles no, y esto nos permitirá establecer estrategias de condicionamiento (qué variables controlar o no), recolección de datos y diseño de experimentos para construir los estimadores correctos de los efectos causales de interés.\n\n\n\n\n\n\nd-separación: Caminos activos y bloqueados\n\n\n\n\nUn camino \\(p\\) entre \\(X\\) y \\(Y\\) es una sucesión de aristas que conecta a \\(X\\) con \\(Y\\) (sin importar) la dirección de las aristas.\n\nAhora supongamos que \\(Z = \\{Z_1,Z_2,\\ldots, Z_q\\}\\) son una colección de nodos. Decimos que un camino \\(p\\) entre \\(X\\) y \\(Y\\) está activo condicional a los nodos en \\(Z\\) cuando:\n\nSiempre que hay un colisionador \\(X_i\\to U\\gets X_j\\) en el camino \\(p\\), entonces \\(U\\) o alguno de sus descendientes está en \\(Z\\)\nNingún otro nodo a lo largo de \\(p\\) está en \\(Z\\).\n\nEn caso contrario, decimos que el camino \\(p\\) está bloqueado.\nSi \\(Z\\) bloquea todos los caminos posibles entre \\(X\\) y \\(Y\\), decimos que \\(X\\) y \\(Y\\) están \\(d\\)-separados condicionalmente a \\(Z\\), o \\(d\\)-separados por \\(Z\\).\n\n\nSegún la discusión que tuvimos arriba de los modos de razonamiento en gráficas de modelos probabilísticos, el siguiente teorema no es sorpresa:\n\n\n\n\n\n\nCriterio de d-separación\n\n\n\nEn una DAG \\(G\\):\n\nSi dos variables están d-separadas por las variables \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes dadas las variables en \\(Z\\) para cualquier conjunta representada por \\(G\\).\nSi dos variables no están d-separadas por \\(Z\\), entonces existen conjuntas representadas por \\(G\\) tales que \\(X\\) y \\(Y\\) tienen dependencia condicional dado \\(Z\\).\n\n\n\nNota 1: nótese que este teorema nos da una manera abstracta de razonar acerca de la asociación en un modelo gráfico: no es necesario saber la forma particular de las condicionales para utilizarlo.\nNota 2: Vale la pena mencionar que el segundo inciso en general es una implicación más fuerte: cuando no hay \\(d\\)-separación, existe algún tipo de dependencia casi seguro (en el sentido probabilístico de posible conjuntas).\nNota 3: Las independencias condicionales también pueden ser útiles para checar los supuestos de nuestro modelo: si encontramos asociaciones fuertes (condicionales o no) entre variables que nuestra estructura implica independencia condicional, entonces puede ser que nuestra estructura causal requiera revisión. Qué tanto podemos probar esto depende del tamaño de los datos que tengamos y de el tipo de condicionamiento que estamos haciendo.\nFinalmente (ver por ejemplo Koller y Friedman (2009), p 75), existe un algoritmo eficiente para encontrar todas las posibles independencias condicionales implicadas por una gráfica:\n\n\n\n\n\n\nCálculo de d-separación\n\n\n\nExiste un algoritmo de complejidad lineal en el tamaño de la gráfica para encontrar todos los nodos con caminos activos a un nodo \\(X\\) condicional a las variables \\(A\\).\n\n\nVer por ejemplo el sitio dagitty.net, donde podemos poner nuestra gráfica y enlistar todas los supuestos de independencia condicional implicados por un modelo.\n\nEjemplo\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n  edge [minlen = 3]\n    Z -&gt; W\n    X -&gt; W\n    X -&gt; Y\n    W -&gt; U\n    S -&gt; Y\n    UZ -&gt; Z\n    V -&gt; Z\n    V -&gt; S\n}\n\")\n\n\n\n\n\n\nConsideremos la relación entre Z y Y. Primero vemos que hay dos caminos entre \\(Z\\) y \\(Y\\), que son \\(p_1:X\\gets V \\to S \\to Y\\) y \\(p_2: Z\\to W \\gets X \\to Y\\)\n\nEn primer lugar, ¿son independientes si no condicionamos a ninguna variable? No, pues el camino \\(p_1\\) es activo, e induce correlación.\n¿Son condicionalmente independientes si condicionamos a \\(V\\)? En este caso, condicionar a \\(V\\) bloquea el camino \\(p_1\\). El camino \\(p_2\\) está bloqueado por el colisionador \\(W\\), así que todos los caminos están bloqueados si condicionamos a \\(V\\). Por lo tanto \\(Z\\) y \\(Y\\) son condicionalmente independientes dado \\(V\\), o \\(Z\\perp\\!\\!\\!\\perp Y|V\\).\nSi condicionamos a \\(W y V\\), ¿son independientes \\(Z\\) y \\(Y\\)? No. El camino \\(p_1\\) está bloqueado, así que ese no induce asociación. Sin embargo, al condicionar al colisionador \\(W\\) activamos el camino \\(p_2\\).\nAhora supongamos que tenemos datos condicionales a algún valor de \\(W\\) solamente. Condicionando a \\(V\\) bloqueamos el camino \\(p_1\\), pero el camino \\(p_2\\) está activo. ¿Qué pasaría si condicionamos adicionalmente a \\(X\\)? En este caso, el conjunto de condicionamiento es \\(\\{V, W, X\\}\\). El camino \\(p_2\\) está bloqueado. Y aunque condicionamos al colisionador, \\(X\\) bloque el camino. Por lo tanto \\(Z\\) y \\(Y\\) son condicionalmente independientes dado \\(\\{V, W, X\\}\\).\n\n\n\nEjercicio\nRepite el ejemplo anterior para la siguiente gráfica. Analiza que pasa si condicionamos o no a valores de \\(T\\), y qué pasa si adicionalmente condicionamos a \\(W\\), y luego repite los pasos del ejemplo anterior.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    Z \n    W \n    X\n    Y \n    U\n    T\n  edge [minlen = 3]\n    T -&gt; Z\n    T -&gt; Y\n    Z -&gt; W\n    X -&gt; W\n    X -&gt; Y\n    W -&gt; U\n    S -&gt; Y\n    UZ -&gt; Z\n}\n\")\n\n\n\n\n\n\n\n\nEjemplo (análisis de factores)\nEn análisis de factores intentamos expresar variables observadas \\(X_i\\) en función de relativamente pocas variables latentes \\(F_j\\). El diagrama que representa sus supuestos básicos es uno como el siguiente:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=circle]\n    F1 [label = &lt;F&lt;sub&gt;1&lt;/sub&gt; &gt; ]\n    F2 [label = &lt;F&lt;sub&gt;2&lt;/sub&gt; &gt; ]\n  node [shape=plaintext]\n    X1 [label = &lt;X&lt;sub&gt;1&lt;/sub&gt; &gt; ]\n    X2 [label = &lt;X&lt;sub&gt;2&lt;/sub&gt; &gt; ]\n    X3 [label = &lt;X&lt;sub&gt;3&lt;/sub&gt; &gt; ]\n    X4 [label = &lt;X&lt;sub&gt;4&lt;/sub&gt; &gt; ]\n    X5 [label = &lt;X&lt;sub&gt;5&lt;/sub&gt; &gt; ]\n  edge [minlen = 3]\n    F1 -&gt; X1\n    F1 -&gt; X2\n    F1 -&gt; X3\n    F1 -&gt; X4\n    F1 -&gt; X5\n    F2 -&gt; X1\n    F2 -&gt; X2\n    F2 -&gt; X3\n    F2 -&gt; X4\n    F2 -&gt; X5\n}\n\")\n\n\n\n\n\n\n\n\\(F_1\\) y \\(F_2\\) son independientes\n\\(X_i\\) y \\(X_j\\) son condicionalmente independientes dadas \\(F_1\\) y \\(F_2\\)\n\nUsualmente hacemos supuestos adicionales como linealidad \\[E[X_i|F_1, F_2] = \\lambda_{i,1}F_1+  \\lambda_{i,1}F_1\\] y por ejemplo normalidad de \\(X_i\\) condicional a los factores.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "05-dags.html#caminos-causales",
    "href": "05-dags.html#caminos-causales",
    "title": "5  Modelos gráficos y causalidad",
    "section": "5.10 Caminos causales",
    "text": "5.10 Caminos causales\nSi el DAG que consideramos representa relaciones causales (mecanísticas) entre las variables, es decir, qué variable “escucha” a qué otras para decidir su valor, entonces podemos hacer la siguiente definición:\n\n\n\n\n\n\nCaminos causales\n\n\n\nEn un DAG, los caminos causales entre \\(X\\) y \\(Y\\) son de la forma \\(X\\to U_1\\to U_2 \\to \\cdots U_j \\to Y\\). Puede haber varios de ellos en un diagrama dado, y cada uno representa un mecanismo en que cambios en \\(X\\) producen cambios en \\(Y\\)\nSi nos interesa el efecto total de \\(X\\) sobre \\(Y\\),\n\nQueremos que todos los caminos causales de \\(X\\) a \\(Y\\) estén activos,\nQueremos condicionar para que todos los caminos no causales estén bloqueados, en particular, no queremos condicionar a colisionadores o sus descendientes que introduzcan relaciones no causales, y queremos bloquear caminos no casuales creados por bifurcaciones.\n\nSi nos interesa el efecto directo de \\(X\\) sobre \\(Y\\),\n\nAdicionalmente a los puntos del efecto directo, queremos condicionar para bloquear también todos los caminos causales que no sean directos.\n\n\n\n\n5.10.1 Ejemplo\nEn la tarea vimos un diagrama como sigue para el problema de los zorros:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=plaintext]\n    A\n    F\n    G\n    W\n  edge [minlen = 3]\n    A -&gt; F\n    F -&gt; G\n    F -&gt; W\n    G -&gt; W\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nVimos que para calcular el efecto directo de \\(F\\) sobre \\(W\\), por ejemplo, es necesario bloquear el camino que pasa por \\(G\\) (estratificar por este nodo). Para el efecto total no es necesario condicionar a ningún otro nodo.\nAhora supongamos que creemos que \\(G\\) y \\(W\\) tienen una causa común \\(U\\) no observada.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape = circle]\n  U\n  node [shape=plaintext]\n    A\n    F\n    G\n    W\n  edge [minlen = 3]\n    A -&gt; F\n    F -&gt; G\n    F -&gt; W\n    G -&gt; W\n    U -&gt; G\n    U -&gt; W\n{rank=same U;G}\n\n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nEn este caso:\n\nPodemos estimar el efecto total de \\(F\\) sobre \\(W\\) sin condicionar a nada. La adición de \\(U\\) no crea ningún nuevo camino no causal activo entre \\(F\\) y \\(W\\).\nSin embargo, no es posible estimar el efecto directo de \\(F\\) sobre \\(W\\): la razón es que si condicionamos a \\(G\\), entonces el camino no causal \\(F\\rightarrow G \\leftarrow U \\rightarrow W\\) se activa. Si conociéramos \\(U\\) podríamos bloquearlo.\n\n\n\n\n\nKoller, D., y N. Friedman. 2009. Probabilistic Graphical Models: Principles and Techniques. MIT Press.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.\n\n\nPearl, Judea, y Dana Mackenzie. 2018. The Book of Why: The New Science of Cause and Effect. New York: Basic Books.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos gráficos y causalidad</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html",
    "href": "06-calculo-do.html",
    "title": "6  Identificación y cálculo-do",
    "section": "",
    "text": "6.1 Cambiando el proceso generador de datos\nEn esta sección veremos cómo utilizar la lógica de los diagramas causales que vimos en la sección anterior para entender la posibilidad de identificar efectos causales, es decir, entender si es posible desarrollar estrategias para estimar esos efectos causales. Enfatizamos que este proceso es uno lógico que se deriva de nuestro análisis de las estructuras básicas en DAGs que vimos anteriormente, más que de una colección de “trucos” o “recetas”.\nComenzamos con el ejemplo más simple de una variable confusora:\ngrViz(\"\n  digraph {\n    node [shape = plaintext];\n    X [label = 'X'];\n    Y [label = 'Y'];\n    U [label = 'U'];\n    X -&gt; Y;\n    U-&gt; X ;\n    U -&gt; Y;\n  {rank = same; X; Y;}\n  }\n  \", width = 200, height = 50)\nNos interesa estimar el efecto causal de \\(X\\) sobre \\(Y\\). Sucede que en muchas ocasiones existen variables como \\(U\\) que son causas comunes de \\(X\\) y \\(Y\\). Como vimos, esto implica que no podemos simplemente ver la correlación entre \\(X\\) y \\(Y\\) para entender el efecto de \\(X\\) sobre \\(Y\\), pues una causa común de variación conjunta entre estas dos variables. Esta variable \\(U\\) puede ser observada o no.\nEste tipo de confusores ocurren muchas veces en datos observacionales (es decir, de un proceso o sistema que funcione sin intervención de los investigadores). Por ejemplo, si un estudio observa que aquellos que se aplicaron (voluntariamente) un tratamiento \\(X\\), tienen menor riesgo de hospitalización \\(Y\\) por cierta enfermedad. Sin embargo, se observa también que aquellos que se aplicaron el tratamiento tienen menos riesgo de tener accidentes viales. Esto indica que la observación de la reducción de riesgo de hospitalización entre los que escogieron el tratamiento probablemente se debe al menos en parte a una variable confusora (por ejemplo, qué tipo de actividades hacen, qué tan cautelosos son, etc.)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#cambiando-el-proceso-generador-de-datos",
    "href": "06-calculo-do.html#cambiando-el-proceso-generador-de-datos",
    "title": "6  Identificación y cálculo-do",
    "section": "",
    "text": "6.1.1 Experimentación\nCuando es posible, podemos proponer generar nuevos datos donde alteramos el proceso generador. Una forma muy efectiva y útil, que es muy conveniente cuando es posible, es controlar la asignación del tratamiento. Si en el diagrama anterior, diseñamos un estudio donde observamos a un grupo de personas para las cuales el tratamiento se asignó de acuerdo a un proceso aleatorio, entonces el nuevo diagrama para este nuevo proceso generador es:\n\ngrViz(\"\n  digraph {\n    node [shape = plaintext];\n    X [label = 'X'];\n    Y [label = 'Y'];\n    R\n    U [label = 'U'];\n    R -&gt; X\n    X -&gt; Y;\n    U -&gt; Y;\n  {rank = same; R;X; Y;}\n  }\n  \")\n\n\n\n\n\nNótese que:\n\nLa variable \\(R\\) no puede ser endógena (es decir, ninguna flecha del sistema puede incidir en ella), pues se utiliza un dado o algo totalmente no relacionado al sistema para asignar el tratamiento. Por ejemplo, también podríamos asignar el tratamiento otra manera determinística como si el día de nacimiento de la persona es par o impar.\nEn este nuevo diseño, por definición, la variación en \\(X\\) no responde causalmente a ninguna otra variable en el sistema que pueda influir también en \\(Y\\) (como \\(U\\) en el diagrama anterior).\nSi construimos modelos estadísticos para esta diagrama, para saber el efecto causal sólo tenemos que ver cómo cambia la condicional \\(p(y|x)\\) cuando cambiamos la \\(x\\), pues la variación natural o observada entre \\(x\\) y \\(y\\) corresponde a solamente a un camino causal.\n\n\n\n\n\n\n\nExperimentos\n\n\n\nEsto describe la idea básica de un experimento simple: es una herramienta para modificar el proceso generador de datos que nos permite identificar efectos causales de manera relativamente simple.\nCuando es posible hacer experimentos de calidad, esta puede ser la mejor forma de estimar efectos causales.\n\n\nEn muchos casos, sin embargo, no es posible hacer experimentos de calidad. Hay varias diversas razones, por ejemplo cuando se trata de experimentos que involucran personas:\n\nNo es ético aleatorizar: es totalmente inaceptable asignar aleatoriamente a personas a un tratamientos como fumar 20 cigarros al día, o aleatorizar a niños a recibir educación o no.\nAleatorización imposible o imperfecta: no es posible lograr un control total sobre la asignación del tratamiento, y la adherencia al tratamiento asignado de las personas puede variar (por ejemplo, uso de tapabocas en escuelas).\n\nAsí que muchas preguntas causales no están sujetas a modificaciones del proceso generador de datos mediante aleatorización, y es necesario recurrir a otras estrategias.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#el-operador-do",
    "href": "06-calculo-do.html#el-operador-do",
    "title": "6  Identificación y cálculo-do",
    "section": "6.2 El operador do",
    "text": "6.2 El operador do\nRegresamos al diagrama original donde \\(U\\) es una causa común de \\(X\\) y \\(Y\\), y que no tenemos recursos o no es posible hacer un experimento. ¿Existe algún procedimiento estadístico que nos permita estimar el efecto causal de \\(X\\) sobre \\(Y\\)?\nEscribiremos la distribución condicional de la respuesta \\(Y\\) dada una manipulación de \\(X\\) como sigue (es decir, en la situación experimental):\n\\[p(Y| do(X=x))\\]\nEsto significa: ¿cómo se distribuye la \\(Y\\) dado que intervenimos en la población completa (aunque podemos también considerar subpoblaciones más adelante) para poner en \\(X=x\\)? En primer lugar, notemos que esto no es lo mismo que la distribución condicional usual\n\\[p(Y|X=x),\\] que siempre podemos estimar directamente de los datos, y no es la que nos interesa. En el siguiente ejemplo vemos la distinción entre las dos distribuciones:\n\nEjemplo\nSupongamos que tenemos el siguiente diagrama causal. Supondremos también que conocemos todas las relaciones funcionales involucradas.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   T -&gt; A\n   T -&gt; Z\n   \n   \n}\n\", width = 100, height = 50)\n\n\n\n\nGráfica de datos observacionales\n\n\ndonde \\(T\\) es la temperatura, \\(A\\) son las unidades de agua embotellada vendidas y \\(Z\\) es la actividad de los mosquitos (medido con muestreo, por ejemplo).\nNo interesa contestar la pregunta: ¿qué tanto influyen las ventas de agua embotellada en la actividad de los mosquitos? Del diagrama, sabemos que no hay ningún camino causal de \\(Z\\) a \\(A\\), por lo que nuestra respuesta debería ser igual a 0.\nSin embargo, sabemos que estas dos variables están asociadas (por el análisis de DAGs), de manera que describir cómo cambia \\(p(Z|A)\\) cuando condicionamos a distintos valores de \\(A\\) no responde nuestra pregunta. La distribución \\(p(Z|do(A = a))\\) nos dice cómo se distribuye \\(Z\\) cuando manipulamos \\(a\\) artificialmente. Por ejemplo, si cerramos todas las tiendas un día haciendo \\(do(A=0)\\), veríamos que esta variable no tiene efecto sobre la actividad de mosquitos, por ejemplo comparado con \\(do(A = 10000)\\).\nIlustramos la diferencia entre \\(p(Y|X)\\) y \\(p(Y|do(X))\\) simulando del ejemplo anterior. Supondremos que sólo consideramos un día del año a lo largo de varios años, para no modelar el comportamiento cíclo de la temperatura:\n\nsimular_t &lt;- function(n = 10, dia = 150){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  mosquitos &lt;- rpois(n, 250 + 10 * (t_maxima - 28))\n  a_unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)\n  tibble(t_maxima, a_unidades, mosquitos)\n}\nset.seed(128)\nsimular_dias &lt;- simular_t(50)\n\nSi simulamos, vemos que \\(mosquitos\\) y \\(unidades\\) son dependientes, pues tenemos un camino abierto dado por la bifurcación en temperatura:\n\nggplot(simular_dias, aes(x = a_unidades, y = mosquitos)) + geom_point() +\n  geom_smooth(method = \"loess\", method.args = list(degree = 1)) +\n  xlab(\"Ventas de agua embotellada\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nSabemos que esta asociación no es causal, pues no hay caminos causales entre estas variables dos variables, pero que hay una dependencia debido a la bifurcación en \\(T\\). La gráfica muestra que la media condicional \\(E[M|A=a]\\) depende fuertemente de \\(a\\), lo que quiere decir que \\(p(m|a)\\) depende de \\(a\\) fuertemente.\nEn este caso, nos interesaría saber qué sucede si alteramos artificalmente el número de botellas de agua vendidas (puedes imaginar distintas maneras de hacer esto).\nComo en este ejemplo conocemos todas las relaciones funcionales, y. nuestros supuesto es que el diagrama mostrado es correcto, podemos cambiar nuestra simulación para simular el proceso generador de datos del experimento asociado.\nComo veremos, esto se puede entender como una cirugía de la gráfica original donde quitamos las aristas que inciden en \\(A\\). Desde el punto de vista del proceso generador, si intervenimos el proceso generador deberíamos excluir cómo \\(A\\) responde a otras variables, pues ahora la estamos fijando:\n\nsimular_cirugia &lt;- function(n = 10, a_unidades = a_unidades){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  #### cirugía #########\n  # ahora a_unidades es fijado por nosotros:\n  # a_unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28), 2000)\n  a_unidades &lt;- a_unidades\n  ######################\n  mosquitos &lt;- rpois(n, 250 + 10 * (t_maxima - 28))\n  tibble(t_maxima, a_unidades, mosquitos)\n}\n\nY ahora simulamos y graficamos \\(p(Z|do(A=a))\\) para distintos valores de \\(a\\):\n\nset.seed(128)\nsimular_dias_2 &lt;- map_df(seq(10000, 30000, 1000),\n  \\(u) simular_cirugia(50, a_unidades = u))\n\n\nggplot(simular_dias_2, aes(x = a_unidades, y = mosquitos)) +\n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\ncor(simular_dias_2$mosquitos, simular_dias_2$a_unidades)\n\n[1] -0.05055934\n\n\ny vemos, como esperaríamos, que no hay relación entre unidades de agua embotellada y mosquitos.\nDesde el punto de vista de la gráfica, la manipulación donde fijamos manualmente \\(A\\) consiste en quitar las aristas que van hacia \\(A\\), pues \\(A\\) ya no está determinado por el proceso generador de datos. Tenemos entonces la nueva gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n   A\n  edge [minlen = 3]\n   T -&gt; Z\n{ rank = same; A; Z }\n}\n\", width = 100, height = 50)\n\n\n\n\nGráfica con intervención en A\n\n\nEn esta nueva gráfica, \\(A\\) y \\(Z\\) son independientes, que es la respuesta correcta. Como cambiamos la gráfica, su proceso generador es diferente al original de los datos observados. Sin embargo, en este ejemplo puedes ver por qué es claro que el cambio que hicimos (manipular \\(A\\) en lugar de que esté determinado por su proceso generador original) no cambia el modelo de \\(Z\\), de manera que podemos simular de nuestro nuevo proceso generador donde manipulamos \\(A\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#cálculo-do-de-pearl",
    "href": "06-calculo-do.html#cálculo-do-de-pearl",
    "title": "6  Identificación y cálculo-do",
    "section": "6.3 Cálculo-do de Pearl",
    "text": "6.3 Cálculo-do de Pearl\nEl cálculo do nos da reglas para operar con probabilidades que incluyen nuestro operador do de intervención, y nos dice cómo pasar de cantidades que incluyen manipulaciones do a cantidades estadísticas que se pueden estimar directamente de los datos.\nEn este ejemplo anterior, veremos cómo es el argumento:\nNótese que al intervenir \\(A\\) hemos modificado el proceso generador. Si la conjunta original tiene distribución \\(p\\), escribimos \\(p_m\\) para la conjunta de la gráfica modificada, de manera que \\(p(Z|do(A)) = p_m(Z|A)\\): con esto podemos pasar de una pregunta causal (lado izquierdo con operador do) a una estadística (lado derecho).\nAunque intuitivamente vimos cómo simular de esta distribución arriba, especificamos abajo qué reglas son las que nos permiten hacer esto: ¿cómo calculamos \\(p_m\\)?\nEn primer lugar, consideremos la marginal \\(p_m(T)\\). Esta marginal es invariante a nuestra cirugía, pues la arista \\(T\\to A\\) que eliminamos \\(T\\) no afecta el proceso que determina \\(T\\). De modo que la marginal del proceso modificado es igual a la marginal observada:\n\\[p_m(T) = p(T)\\] En segundo lugar, tenemos que\n\\[p_m(Z|T=t,A=a) = p(Z|T=t,A=a),\\] Pues el proceso por el cual \\(Z\\) responde a \\(T\\) y \\(A\\) es el mismo, no importa si \\(A\\) fue modificada artificalmente o no.\nJuntamos estos argumentos. Primero, por definición,\n\\[p(Z|do(A=a)) = p_m(Z|A=a).\\]\nAhora por la regla de probabilidad total, podemos condicionar todo a \\(T\\) y marginalizar. La segunda igualdad la obtenemos por la independencia entre \\(T\\) y \\(Z\\) en nuestra gráfica modificada (están \\(d\\) separadas):\n\\[p_m(z|a) = \\int p_m(z|a,t)p_m(t|a)dt = \\int p_m(z|a,t)p_m(t)dt\\] En segunda igualdad, nótese que cambiamos \\(p_m(t|a) = p_m(t)\\), lo cual podemos verificar pues en la gráfica modificada \\(A\\) y \\(T\\) están \\(d\\)-separados, lo que implica que son condicionalmente independientes.\nFinalmente, las últimas dos distribuciones podemos extraerlas de los datos, como explicamos arriba \\(p_m(z|t,a) = p(z|t,a)\\) y \\(p_m(t) = p(t),\\) y terminamos con la fórmula:\n\\[p(z|do(a))=p_m(z|a) = \\int p(z|a,t)p(t)dt \\]\nLas dos distribuciones de la derecha están en el contexto de \\(p\\), el proceso generador de datos original. Así que podemos estimarlas de los datos observados.\n\nEste argumento justifica el proceso que hicimos arriba: simulamos primero \\(T\\) con su proceso generador, y después simulamos \\(Z\\) condicional a \\(A\\) y \\(T\\) según el proceso generador original, el cual no depende de \\(A\\) en este ejemplo.\n\nEn el caso de arriba, simulamos de la distribución para entender cómo se distribuía \\(Z\\) dependiendo de modificaciones a \\(A\\). Muchas veces nos interesa calcular solamente la esperanza condicional, es decir, cuál es el valor esperado de la variable de interés dado el nivel intervenido, es decir:\n\\(E(Z|do(A=a)) = E_m(Z|A =a),\\)\nque mostramos arriba con la línea ajustada. También quisiéramos calcular contrastes particulares, como qué pasaría si las ventas de agua las aumentamos en 10 mil unidades:\n\\[E(Z|do(A=30000)) - E(Z|do(A=20000)),\\]\n\nEjemplo\nAhora hagamos otro ejemplo donde hay una relación causal que queremos estimar. Imaginemos una ciudad en donde temperaturas altas producen desabasto de agua en algunos hogares, debido a un aumento del riego y uso de agua en general. Nos interesa estimar el efecto del desabasto en las compras de agua embotellada. Nuestro diagrama ahora es:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -&gt; T\n   T -&gt; A\n   T -&gt; D\n   D -&gt; A\n   U_a -&gt; A\n   U_d -&gt; D\n\n{ rank = same; A; D }\n\n}\n\")\n\n\n\n\n\n\n\nsimular_t &lt;- function(n = 10, dia = 150){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  u &lt;- rnorm(n, 0, 1)\n  desabasto_agua &lt;- 1/(1 + exp(-(t_maxima - 28) + u))\n  unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)\n  tibble(t_maxima, unidades, desabasto_agua)\n}\nset.seed(128)\nsimular_dias &lt;- simular_t(150)\n\n\nggplot(simular_dias, aes(x = desabasto_agua, y = unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLa correlación parece muy fuerte, sin embargo, sabemos que hay un camino no causal de asociación entre estas dos variables.\nIgual que en ejemplo anterior, vamos a intervenir teóricamente en el desabasto de agua. Después de la cirugía, nuestro diagrama modificado es:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n   U_t -&gt; T\n   T -&gt; A\n   D -&gt; A\n   U_a -&gt; A\n{ rank = same; A; D }\n\n}\n\")\n\n\n\n\n\n\nAhora queremos calcular \\(p(a|do(d)) = p_m(a|d)\\) en función de los datos. Siguiendo el mismo argumento que en el ejemplo anterior, sabemos que tenemos que estratificar o condicionar a \\(T\\) para poder usar nuestro proceso generador de observaciones, y obtenemos:\n\\[p(a|do(d))=p_m(a|d) = \\int p(a|d,t)p(t)dt \\] Aunque a veces es posible calcular analíticamente el lado derecho analíticamente, podemos simular como hicimos en los ejemplos anteriores:\n\nsimular_cirugia &lt;- function(n = 10, da = 0){\n  # simular un año, alrededor del día 160 (en junio)\n  t_maxima &lt;- rnorm(n, 28, 2)\n  ### cirugía ####\n  #u &lt;- rnorm(n, 0, 1) \n  desabasto_agua &lt;- da\n  ######\n  unidades &lt;- rnorm(n, 20000 + 2000 * (t_maxima -  28) + 8000*desabasto_agua, 2000)\n  tibble(t_maxima, unidades, desabasto_agua)\n}\nset.seed(128)\nsimular_dias_c &lt;- map_df(seq(0, 1, 0.1), \\(da) simular_cirugia(1000, da = da))\n\n\nggplot(simular_dias_c, aes(x = desabasto_agua, y = unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nPodemos también resumir promediando:\n\nefecto_verdadero_desabasto &lt;- simular_dias_c |&gt; \n  group_by(desabasto_agua) |&gt; \n  summarise(media_unidades = mean(unidades)) |&gt; \n  rename(desabasto = desabasto_agua)\nggplot(efecto_verdadero_desabasto,\n       aes(x = desabasto, y = media_unidades)) + \n  geom_point() + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nY este es el efecto causal del desabasto de agua. No tenemos medidas de incertidumbre pues conocemos todos los parámetros de los modelos. La media condicional parece ser lineal, así que podríamos resumir con un modelo lineal:\n\n# Modelo 1 (con datos de intervención)\nlm(unidades ~ desabasto_agua, simular_dias_c)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua, data = simular_dias_c)\n\nCoefficients:\n   (Intercept)  desabasto_agua  \n         19831            8272  \n\n\nAproximadamente, cada incremento en puntos porcentuales de 10% en desabasto incrementa las ventas en unas 800 unidades. Compara con el análisis donde no estratificamos o controlamos por la temperatura:\n\n# Modelo 2\nlm(unidades ~ desabasto_agua, simular_dias)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua, data = simular_dias)\n\nCoefficients:\n   (Intercept)  desabasto_agua  \n         14102           19491  \n\n\nOtra forma de estratificar es ajustando un modelo que incluye la variable de temperatura. Podríamos hacer\n\n# Modelo 3\nlm(unidades ~ desabasto_agua + t_maxima, simular_dias)\n\n\nCall:\nlm(formula = unidades ~ desabasto_agua + t_maxima, data = simular_dias)\n\nCoefficients:\n   (Intercept)  desabasto_agua        t_maxima  \n        -35030            8648            1948",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#fórmula-de-ajuste",
    "href": "06-calculo-do.html#fórmula-de-ajuste",
    "title": "6  Identificación y cálculo-do",
    "section": "6.4 Fórmula de ajuste",
    "text": "6.4 Fórmula de ajuste\nEn resumen, tenemos la primera regla de Pearl de inferencia causal:\n\n\n\n\n\n\nFórmula de ajuste (Pearl)\n\n\n\nConsideramos una DAG donde los padres de \\(X\\) son \\(Z_1,Z_2\\). El efecto causal total de \\(X\\) en \\(Y\\) se puede calcular como\n\\[p(y|do(x)) = \\int p(y|x, z_1,z_2) p(z_1,z_2)\\, dz_1dz_2\\] Es decir, condicionamos al valor de \\(x\\) y todos los padres de \\(X\\) para calcular \\(p(y|x,z_1,z_2)\\), y después marginalizamos sobre los padres.\n\n\nEsta fórmula se extiende a más de dos padres \\(Z_1,Z_2,Z_3,\\ldots, Z_k\\).\n\n\n\n\n\n\nTip\n\n\n\nA este proceso se llama de diferentes maneras en distintos contextos:\n\nEstamos calculando el efecto causal estratificando por las variables \\(z\\).\nControlamos por las variables \\(z\\) para calcular el efecto causal.\n\n\n\nPodemos pensar en esta fórmula de dos maneras: en primer lugar, si estamos modelando toda nuestra gráfica causal, podemos simular de la conjunta de la gráfica mutilada:\n\nFijando el nivel del tratamiento \\(T\\)\nSimulando \\(p(z_1,z_2,\\ldots, z_k)\\) de nuestro modelo completo (y tomar sólo los valores de las \\(z\\)’s).\nUsar \\(t\\) y las \\(z\\) simuladas para simular \\(y\\).\nAl final, nótese que nos quedan simulaciones de \\(p_m(y|t)\\) (marginalizamos sobre las \\(z\\)).\n\nEl otro enfoque busca sólo construir modelos para la parte que nos interesa:\n\nConstruir un modelo separado para \\(p(z_1, z_2,\\ldots, z_k) = p(z)\\) (que puede ser difícil si tenemos muchas variables) a partir los datos. Podemos también simular tomando al azar esta variables de nuestros datos.\nConstruir un modelo \\(p(y|t, z)\\) para simular la \\(y\\) a partir de los datos.\nMarginalizar sobre las \\(z\\)’s para quedarnos con \\(p_m(y|t)\\)\n\nFinalmente, si tenemos un modelo \\(p(y| t, z)\\) podemos también investigar cómo se comporta \\(E[y|t_2,z] - E[y|t_1,z]\\) para distintos combinaciones de valores de \\(Z\\).\nNota 1: Con este principio podemos resolver algunos problemas, pero no todos. Veremos que en algunos casos existen padres que no son observados, por ejemplo, no es posible condicionar para usar la fórmula de ajuste y es necesario desarrollar otras estrategias.\nNota 2: En regresión lineal, cuando incluímos una variable en el modelo (que consideramos una variable control), estamos estratificando por ella: por ejemplo, en el modelo lineal \\(U\\sim N(m_u(d,t), \\sigma_u)\\), donde\n\\[m_u = \\beta_0 +\\beta_1 d + \\beta_2 t\\] Estamos calculando un estimador para cada valor de \\(T=t\\), que es:\n\\[m_u = (\\beta_0 + \\beta_2 t) + \\beta_1 d = \\gamma_0 + \\gamma_1 d\\] Esta es una de las maneras más simples de obtener el efecto de \\(d\\) estratificando por, o controlando por \\(t\\), siempre y cuando los modelos lineales sean apropiados.\nNótese que en este último caso, tenemos que el efecto de \\(d\\) no depende de las covariables, de forma que no es necesario hacer el promedio sobre la conjunta, es decir, suponemos que el efecto causal es el mismo independientemente de los valores de las variables de control. Sin embargo, este no siempre es el caso.\nNota 3 Si nuestro modelo \\(p(y|t,z)\\) es lineal, y nos interesa calcular el efecto causal promedio de la variable \\(t\\), no es necesario promediar por la conjunta de \\(p(z)\\). Bajo estas condiciones, el efecto causal promedio está simplemente dado por el coeficiente de \\(t\\) en el modelo lineal. Sin embargo, si este no es el caso, entonces para estimar el efecto causal promedio es necesario promediar apropiadamente según la fórmula de ajuste.\n\nEjemplo: variación de efectos causales\nEn McElreath (2020), McElreath presenta un ejemplo interesante de por qué es necesario marginalizar sobre las variables de estratificación que no son el tratamiento. En su diagrama causal, la cantidad de guepardos afecta la población de babuinos y de gacelas, y también la población de babuinos afecta la población de gacelas. Cuando hay muchos guepardos, los babuinos no cazan, de forma que el efecto \\(Babuinos\\to Gazelas\\) es débil. Cuando hay pocos guepardos, sin embargo, el efecto \\(Babuinos\\to Gazelas\\) es fuerte pues los babuinos pueden aventurarse a cazar. Podemos obtener un efecto causal promedio marginalizando sobre la cantidad de guepardos.\nOtro ejemplo que podríamos considerar es el de intervenir por ejemplo un semáforo para agilizar la vialidad. El tráfico previo influye la decisión de intervenir un semáforo, y también influye en el tráfico actual. Cuando el tráfico previo es bajo, la intervención tiene poco efecto, pero cuando el tráfico previo es alto, al intervención tiene un efecto más fuerte.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#bloqueando-puertas-traseras",
    "href": "06-calculo-do.html#bloqueando-puertas-traseras",
    "title": "6  Identificación y cálculo-do",
    "section": "6.5 Bloqueando puertas traseras",
    "text": "6.5 Bloqueando puertas traseras\nEn las partes anteriores vimos que estratificando por los padres de la variable de tratamiento \\(X\\) podemos construir un estimador del efecto de \\(X\\) sobre otra variable \\(Y\\), pasando de una distribución observacional a una conceptualmente experimental (dado que los supuestos causales sean aproximadamente correctos).\nSin embargo, esta aplicación de la fórmula de ajuste no funciona si existen padres que no fueron observados, y por tanto no podemos estratificar por ellos. El siguiente método (ajuste por “puerta trasera”) nos da una generalización que podemos usar dado ciertos tipos de estructura en nuestro modelo causal (veremos también por ejemplo, que a veces podemos usar menos variables que padres de la variable de interés). Nótese que una vez más, este criterio sólo depende de la gráfica causal \\(G\\) asociada a nuestro modelo, y no los modelos locales que utilizemos para modelar la condicional de cada nodo.\n\n\n\n\n\n\nAjuste de puerta trasera (Pearl)\n\n\n\nSi tenemos dos variables \\(T\\) y \\(Y\\) en una gráfica \\(G\\), un conjunto \\(Z\\) de variables satisface el criterio de puerta trasera relativo a \\(T\\) y \\(Y\\) cuando \\(Z\\) bloquea cualquier camino entre \\(T\\) y \\(Y\\) que tenga una arista que incida en \\(T\\), y ninguna variable de \\(Z\\) es descendiente de \\(T\\).\nEn tal caso, podemos utilizar la fórmula de ajuste, pero en lugar de estratificar por los padres de \\(T\\), estratificamos por las variables en \\(Z\\)\n\n\nLa idea es:\n\nQueremos bloquear todos los caminos no causales entre \\(T\\) y \\(Y\\).\nQueremos no perturbar todos los caminos dirigidos de \\(T\\) a \\(Y\\) (caminos causales).\nNo queremos activar caminos no causales entre \\(T\\) y \\(Y\\) al condicionar.\n\nCumplimos 1 al estratificar por variables que bloquean los caminos que son causas de \\(T\\), pues estos caminos no son causales y distorsionan la relación entre \\(T\\) y \\(Y\\). Al mismo tiempo, no bloqueamos caminos causales porque ningúna variable de \\(Z\\) es descendiente de \\(T\\), de modo que se satisface el criterio 2 (todos los caminos causales comienzan con \\(T\\to\\)). Finalmente, al excluir descendientes de \\(T\\) también implica que no condicionamos a colisionadores del tipo \\(T\\to \\cdots \\to Z_1\\gets  Y\\), pues esto activa un camino no causal entre \\(T\\) y \\(Y\\) (se cumple 3).\n\nEjemplo (Pearl)\nConsideramos primero este ejemplo simple, donde queremos evaluar la efectividad de un tratamiento en cierta enfermedad. Los datos que tenemos disponibles son si una persona recibió o no un tratamiento, y si se recuperó o no. No se registró el nivel socioeconómico, pero sabemos que el tratamiento es caro, de forma que fue accedido más por gente de NSE más alto. También que sabemos que para este tipo de tratamiento, el peso de la persona es un factor importante. Nuestros supuestos están en la siguiente gráfica:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Trata\n    Res\n  node [shape = circle]\n    NSE\n    Peso\n    U\n  edge [minlen = 3]\n    NSE -&gt; Peso\n    NSE -&gt; Trata\n    Trata -&gt; Res\n    Peso -&gt; Res\n    U -&gt; NSE\n    U -&gt; Peso\n}\n\")\n\n\n\n\n\n\nObservamos que no podemos directamente usar la fórmula de ajuste pues NSE no es una variable observada.\nEn esta circunstancia no podríamos identificar el efecto causal, pues existen un caminos abiertos no causales. Quizá el tratamiento no es muy efectivo, y parece ser bueno pues fue aplicado a personas con menor peso que las que no recibieron el tratamiento, a través del efecto de NSE. Sin embargo, supón que tuviéramos disponible la variable Peso:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Trata\n    Res\n    Peso\n  node [shape = circle]\n    NSE\n    U\n  edge [minlen = 3]\n    NSE -&gt; Peso\n    NSE -&gt; Trata\n    Trata -&gt; Res\n    Peso -&gt; Res\n    U -&gt; NSE\n    U -&gt; Peso\n}\n\")\n\n\n\n\n\n\nEn este caso, todavía no podemos aplicar la fórmula original de ajuste pues no conocemos \\(NSE\\). Sin embargo, podemos bloquear los caminos no causales estratificando por Peso, y entonces podemos usar el criterio de puerta trasera para identificar el efecto del tratamiento, aún cuando no tengamos NSE.\n\n\nEjemplo\nPrimero consideramos un modelo generador:\n\ninv_logit &lt;- function(x) 1 / (1 + exp(-x))\nsimular_bd &lt;- function(n = 10){\n  nse &lt;- sample(c(0, 1), n, replace = TRUE)\n  peso &lt;- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)\n  trata &lt;- rbinom(n, 1, 0.8 * nse + 0.2 * (1 - nse))\n  p_trata &lt;- inv_logit(1 * trata - 0.2 * (peso - 70))\n  res &lt;- rbinom(n, 1, p_trata)\n  tibble(nse, peso, trata, res)\n}\ndatos_bd &lt;- simular_bd(10000)\nhead(datos_bd)\n\n# A tibble: 6 × 4\n    nse  peso trata   res\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1     1  71.9     0     0\n2     0  45.0     0     1\n3     0  73.5     0     0\n4     0  66.1     0     1\n5     1  49.4     1     1\n6     0  69.0     1     1\n\n\nVeamos qué sucede si cruzamos tratamiento con resultado (es una muestra grande y el error de estimación no es importante):\n\ndatos_bd |&gt; \n  count(trata, res) |&gt;\n  group_by(trata) |&gt; \n  mutate(p = n / sum(n)) |&gt; \n  filter(res == 1) |&gt; \n  ungroup() |&gt; \n  mutate(dif = p - lag(p))\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0     1  2678 0.533 NA    \n2     1     1  3686 0.741  0.208\n\n\nSabemos que esta diferencia en respuesta puede estar confundida por un camino no causal. El verdadero efecto casual podemos calcularlo en nuestras simulaciones como sigue a partir de nuestro modelo (igualmente, usamos una muestra muy grande):\n\nsimular_efecto &lt;- function(n = 10, peso = NULL){\n  # cómo es la población\n  nse &lt;- sample(c(0, 1), n, replace = TRUE)\n  if(is.null(peso)){\n    peso &lt;- rnorm(n, 70 - 7 * nse, 12 + 2 * nse)\n  }\n  # asignar al azar\n  trata &lt;- rbinom(n, 1, 0.5)\n  p_trata &lt;- inv_logit(1 * trata - 0.2 * (peso - 70))\n  res &lt;- rbinom(n, 1, p_trata)\n  tibble(nse, peso, trata, res)\n}\nsims_efecto &lt;- simular_efecto(20000)\nresumen &lt;- sims_efecto |&gt; \n  count(trata, res) |&gt;\n  group_by(trata) |&gt; \n  mutate(p = n / sum(n)) |&gt; \n  filter(res == 1) |&gt; \n  ungroup() |&gt; \n  mutate(dif = p - lag(p))\ndif_real &lt;- resumen$dif[2]\nresumen\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0     1  5929 0.590 NA    \n2     1     1  6996 0.703  0.113\n\n\nLa estimación ingenua del cruce simple es mucho más grande que el verdadero efecto.\nPodemos también calcular el efecto para un peso particular:\n\nsims_efecto &lt;- simular_efecto(20000, peso = 70)\nres_70 &lt;- sims_efecto |&gt; \n  count(trata, res) |&gt;\n  group_by(trata) |&gt; \n  mutate(p = n / sum(n)) |&gt; \n  filter(res == 1) |&gt; \n  ungroup() |&gt; \n  mutate(dif = p - lag(p))\ndif_70 &lt;- res_70$dif[2]\nres_70\n\n# A tibble: 2 × 5\n  trata   res     n     p    dif\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     0     1  5002 0.500 NA    \n2     1     1  7344 0.735  0.235\n\n\nSuponiendo nuestro diagrama, queremos estimar estratificando por peso. Podríamos usar un sólo modelo logístico, pero pueden ser más simples los cálculos si construimos nuestro modelo en stan. En este caso, podríamos calcular las diferencias para un peso particular, por ejemplo 70 kg (en lugar de modelar estaturas para producir una estimación de diferencia promedio).\nUsaremos una muestra de 2 mil personas:\n\nmod_trata &lt;- cmdstan_model(\"./src/trata-backdoor.stan\")\nprint(mod_trata)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] trata;\n  array[N] int res;\n  vector[N] peso;\n\n}\n\ntransformed data {\n  real media_peso;\n\n  // centrar\n  media_peso = mean(peso);\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n}\n\ntransformed parameters {\n  vector[N] p_logit_res;\n\n  p_logit_res = gamma_0 + gamma_1 * trata + gamma_2 * (peso - media_peso);\n\n}\n\nmodel {\n  // modelo de resultado\n  res ~ bernoulli_logit(p_logit_res);\n  gamma_0 ~ normal(0, 2);\n  gamma_1 ~ normal(0, 1);\n  gamma_2 ~ normal(0, 0.2);\n\n\n}\ngenerated quantities {\n  real dif_trata;\n  real p_trata;\n  real p_no_trata;\n\n  real peso_sim = 70;\n  {\n    array[2000] int res_trata;\n    array[2000] int res_no_trata;\n    for(k in 1:2000){\n      res_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 1 +\n              gamma_2 * (peso_sim - media_peso)));\n      res_no_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 0 +\n              gamma_2 * (peso_sim - media_peso)));\n    }\n    dif_trata = mean(res_trata) - mean(res_no_trata);\n  }\n}\n\n\n\nset.seed(915)\ndatos_bd &lt;- simular_bd(2000)\ndatos_lista &lt;- list(N = nrow(datos_bd),\n  trata = datos_bd$trata, res = datos_bd$res,\n  peso = datos_bd$peso)\najuste &lt;- mod_trata$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.8 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.8 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.8 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.8 seconds.\nTotal execution time: 7.5 seconds.\n\nsims &lt;- ajuste$draws( format = \"df\")\nresumen &lt;- ajuste$summary(c( \"dif_trata\"))\n\n\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean    q5   q95\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 dif_trata 0.215 0.160 0.266\n\nsims |&gt; select(dif_trata) |&gt; \n  ggplot(aes(x = dif_trata)) + geom_histogram() +\n  geom_vline(xintercept = dif_70, colour = \"red\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY obtenemos una estimación correcta del efecto en 70 kg. Podríamos también calcular el efecto en distintos pesos (nuestro estimador es una curva), promediar estimando una distribución de pesos modelada, o tomar una distribución fija de pesos para modelar (cada una de estas estrategias tiene propósitos diferentes).\nSi queremos tener un efecto promedio, podemos modelar los pesos. Otra estrategia es promediar sobre los valores observados de la muestra. Nótese que esto ignora una parte de la incertidumbre proveniente de la muestra particular usada.\n\nmod_trata &lt;- cmdstan_model(\"./src/trata-backdoor-promedio.stan\")\nprint(mod_trata)\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] trata;\n  array[N] int res;\n  vector[N] peso;\n\n}\n\ntransformed data {\n  real media_peso;\n\n  // centrar\n  media_peso = mean(peso);\n}\n\nparameters {\n  real gamma_0;\n  real gamma_1;\n  real gamma_2;\n}\n\ntransformed parameters {\n  vector[N] p_logit_res;\n\n  p_logit_res = gamma_0 + gamma_1 * trata + gamma_2 * (peso - media_peso);\n\n}\n\nmodel {\n  // modelo de resultado\n  res ~ bernoulli_logit(p_logit_res);\n  gamma_0 ~ normal(0, 2);\n  gamma_1 ~ normal(0, 1);\n  gamma_2 ~ normal(0, 0.2);\n\n\n}\ngenerated quantities {\n  real dif_trata;\n  real p_trata;\n  real p_no_trata;\n  vector[N] probs;\n\n  for(i in 1:N){\n    probs[i] = 1.0 / N;\n  }\n\n  {\n    array[2000] int res_trata;\n    array[2000] int res_no_trata;\n    for(k in 1:2000){\n      real peso_sim = peso[categorical_rng(probs)];\n      res_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 1 +\n              gamma_2 * (peso_sim - media_peso)));\n      res_no_trata[k] = bernoulli_rng(\n        inv_logit(gamma_0 + gamma_1 * 0 +\n              gamma_2 * (peso_sim - media_peso)));\n    }\n    p_trata = mean(res_trata);\n    p_no_trata = mean(res_no_trata);\n  }\n  dif_trata = p_trata - p_no_trata;\n\n}\n\n\n\ndatos_lista &lt;- list(N = nrow(datos_bd),\n  trata = datos_bd$trata, res = datos_bd$res,\n  peso = datos_bd$peso)\najuste &lt;- mod_trata$sample(data = datos_lista, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 10.6 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 10.5 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 10.6 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 10.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 10.6 seconds.\nTotal execution time: 42.7 seconds.\n\nsims &lt;- ajuste$draws(c(\"dif_trata\"), format = \"df\")\n\n\nresumen &lt;- ajuste$summary(c( \"dif_trata\"))\nresumen |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable   mean     q5   q95\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 dif_trata 0.111 0.0795 0.142\n\nsims |&gt; select(dif_trata) |&gt; \n  ggplot(aes(x = dif_trata)) + geom_histogram() +\n  geom_vline(xintercept = dif_real, colour = \"red\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY recuperamos nuevamente el efecto verdadero que mostramos arriba.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#reglas-del-cálculo-do-opcional",
    "href": "06-calculo-do.html#reglas-del-cálculo-do-opcional",
    "title": "6  Identificación y cálculo-do",
    "section": "6.6 Reglas del cálculo-do (opcional)",
    "text": "6.6 Reglas del cálculo-do (opcional)\nExisten tres axiomas básicos del cálculo-do de las que se derivan los demás resultados, como veremos en el siguiente ejemplo del criterio de la puerta delantera.\nAntes de verlas, un resumen rápido de las reglas es el siguiente:\n\nLa regla 1 nos dice que las distribuciones asociadas a intervenciones satisfacen también la equivalencia de \\(d\\)-separación e independencia condicional: si \\(Y\\) y \\(Z\\) están \\(d\\)-separadas dado \\(X\\) en la gráfica manipulada, entonces \\(p(y | do(x), z) = p(y|do(x))\\).\nLa regla 2 es el criterio de la puerta trasera: si condicionamos a variables \\(W\\) que bloquean toda puerta trasera de \\(X\\) a \\(Y\\), podemos cambiar \\(do(x)\\) por \\(x\\): \\(p(y | do(x), w) = p(y | x, w)\\).\nLa regla 3 expresa que si no hay caminos causales de \\(X\\) a \\(Y\\), entonces \\(p(y|do(x)) = p(y)\\).\n\n\n\n\n\n\n\nCompletitud (Shpitser, Pearl)\n\n\n\nSi un efecto causal es identificable (puede expresarse en términos de cantidades observacionales), entonces puede derivarse una estrategia de identificación a partir de las tres reglas del cálculo-do.\n\n\nNota: esto no excluye que bajo ciertas hipótesis adicionales a las de nuestra gráfica causal (por ejemplo cómo se comportan las distribuciones particulares que componen el modelo), sea posible identificar efectos causales con otros medios que van más allá del cálculo-do.\nCon más generalidad, abajo están estas reglas (donde condicionamos a más variables o hacemos más intervenciones, y afinamos las condiciones):\nDenotamos por \\(G_m\\) la gráfica mutilada por \\(do(x)\\), donde quitamos todas las aristas que entran en \\(X\\). Los tres axiomas son:\nRegla 1 Ignorar observaciones: Si \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\),\n\\[ p(y|do(x), z, w) = p(y|do(x), w)\\] O en otras palabras, si \\(p_m\\) es la conjunta para \\(G_m\\),\n\\[p_m(y|x,z,w) = p_m(y|x, w)\\] es cierto si \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\) (condicionalmente independientes). Así que esta regla es independencia condicional dado \\(d\\)-separación, pero para la gráfica intervenida.\nRegla 2 Usando observaciones como intervenciones:\nSi \\(Y\\) y \\(Z\\) están \\(d\\)-separados por \\(X\\) y \\(W\\) en \\(G_m\\) quitándole todas las aristas que salen de \\(Z\\), entonces\n\\[ p(y|do(x), do(z), w) = p(y|do(x), z, w)\\] Regla 3 Ignorar intervenciones:\nSi \\(Z\\) y \\(Y\\) están \\(d\\)-separadas por \\(X\\) y \\(W\\) en la gráfica \\(G_m\\) donde además quitamos cualquier arista a \\(Z\\) si \\(Z\\) no es antecesor de \\(W\\) en \\(G_m\\), entonces:\n\\[ p(y|do(x), do(z), w) = p(y|do(x), w)\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "06-calculo-do.html#el-criterio-de-puerta-delantera",
    "href": "06-calculo-do.html#el-criterio-de-puerta-delantera",
    "title": "6  Identificación y cálculo-do",
    "section": "6.7 El criterio de puerta delantera",
    "text": "6.7 El criterio de puerta delantera\nEn algunos casos, puede ser que no sea posible bloquear algún camino no causal con variables observadas. Un ejemplo clásico es el de la discusión acerca de la relación de fumar con cáncer de pulmón. Algunos estadísticos plantearon que los estudios de asociación entre fumar y cáncer de pulmón podrían tener efectos gravemente confundidos, por ejemplo, por aspectos genéticos que hacen a una persona propensa a fumar al mismo tiempo que aumenta su probabilidad de fumar:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    F\n    C\n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    U -&gt; F\n    U -&gt; C\n    F -&gt; C\n{rank= same; C; F}\n}\n\")\n\n\n\n\n\n\nEn este caso, el efecto de fumar (\\(F\\)) sobre cáncer (\\(C\\)) no es identificable pues no podemos condicionar a la variable de Genotipo (\\(U\\)). Supongamos que tenemos una medida adicional, que es la cantidad de depósitos de alquitrán den los pulmones de los pacientes. Este es es afectado por \\(F\\), y a su vez, el alquitrán incrementa la probabilidad de cáncer:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n  node [shape=plaintext]\n    F\n    C\n    A\n  node [shape = circle]\n    U\n  edge [minlen = 3]\n    U -&gt; F\n    U -&gt; C\n    F -&gt; A\n    A -&gt; C\n{rank= same; C; F; A}\n}\n\")\n\n\n\n\n\n\nLa idea es primero estimar el efecto de \\(F\\) sobre \\(A\\), y después estimar el efecto de \\(A\\) sobre \\(C\\). La “composición” de estos dos efectos, dado el diagrama, debe darnos el estimador correcto. Primero consideramos el efecto de \\(F\\) sobre \\(A\\), y tenemos que (regla 2)\n\\[p(a|do(f)) = p(a|f),\\] La igualdad se debe a que una vez que condicionamos a \\(F\\) no hay puertas traseras entre \\(F\\) y \\(A\\) (pues no condicionamos a \\(C\\)). Esta dependencia causal la podemos entonces estimar de los datos.\nEl efecto de \\(A\\) sobre \\(C\\) también es identificable, pues el camino no causal se bloquea cuando condicionamos a \\(F\\), de forma que por la fórmula de ajuste:\n\\[p(c|do(a)) = \\int p(c|a, f') p(f')\\, df'\\]\nAhora encadenamos estas dos ecuaciones:\n\\[p(c|do(f)) = \\int p(c|do(a))p(a|f)\\,da\\]\nque equivale en simulación a: dado un valor de \\(F\\), simulamos \\(A\\) con nuestro modelo ajustado con datos naturales. Ahora intervenimos \\(A\\) con el valor \\(a\\) que obtuvimos y simulamos \\(C\\). Sin embargo, para hacer este último paso con datos naturales, necesitamos usar el criterio de puerta trasera como explicamos arriba: simulamos entonces \\(f´\\) de \\(p(f)\\), y después simulamos \\(C\\) en función de \\(a\\) y \\(f´\\) (con una distribución construida a partir de datos).\nRequerimos en este caso construir y estimar la condicional \\(p(c|a, f)\\) basado en los datos.\nEn fórmula, en general, se escribe como:\n\n\n\n\n\n\nCriterio de fuerta delantera (Pearl)\n\n\n\nDecimos que un conjunto de variables \\(A\\) satisface el criterio de puerta delantera en relación a las variables \\(F\\) y \\(C\\) cuando:\n\n\\(A\\) intercepta todos las cadenas dirigidos de \\(F\\) a \\(C\\)\nNo hay ningún camino activo de puerta trasera de \\(F\\) a \\(A\\)\nTodos los caminos de puerta trasera de \\(A\\) a \\(C\\) están bloqueados por \\(F\\).\n\nSi \\(A\\) satisface el criterio de puerta delantera en relación a \\(F\\) y \\(C\\), entonces el efecto causal de \\(F\\) en \\(C\\) es identificable y está dado por la fórmula:\n\\[p(c|do(f)) = \\int \\left [ \\int p(c|a,f´)p(f´)\\,df´ \\right ] p(a|f)\\,da\\]\n\n\nTodas estas cantidades puede estimarse de los datos.\n\nEjemplo: proceso generador\nAntes de aplicar este nuevo procedimiento, describamos el proceso generador que utilizaremos:\n\n# simular distribución natural\nsimular_fd &lt;- function(n = 10, efecto_a = 0.3){\n  ## causa común\n  u &lt;- rnorm(n, 0, 1);\n  # cantidad que fuma\n  f &lt;- exp(rnorm(n, 1 + 0.2 * u, 0.1))\n  # acumulación de alquitrán\n  a &lt;- rnorm(n,  4 * f, 2)\n  # probabilidad de cancer\n  p_c &lt;- inv_logit(-6 + efecto_a * a +  2 * u)\n  c &lt;- rbinom(n, 1, p_c)\n  tibble(f, a, c, u)\n}\n# simular datos intervenidos (suponiendo que conocemos todo)\nsim_int_f &lt;- function(n = 100, do_f = 0.3, efecto_a = 0.3){\n  a &lt;- rnorm(n,  4 * do_f, 2)\n  u &lt;- rnorm(n, 0, 1)\n  p_c &lt;-  inv_logit(-6 + efecto_a * a +  2 * u)\n  c &lt;- rbinom(n, 1, p_c)\n  tibble(do_f = do_f, media_c = mean(c))\n}\n\n\nset.seed(4481)\nsims_fd &lt;- simular_fd(5000)\nsims_fd_1 &lt;- simular_fd(10000)\nqplot(sims_fd$f, sims_fd$a)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\n¿Cómo se ve la relación de fumador con cáncer? En esta gráfica mostramos también el valor de la variable no observada \\(U\\). Nótese que parte de la correlación positiva que existe es debido a esta variable \\(U\\).\n\nggplot(sims_fd, aes(x = f, y = c, colour = u)) + \n  geom_jitter() + scale_colour_continuous(type = \"viridis\")\n\n\n\n\n\n\n\n\nAhora veamos cómo se ve el efecto de \\(F\\) sobre \\(C\\) y también cómo se ve el cruce de \\(F\\) y \\(C\\) en los datos naturales:\n\nsims_1 &lt;- map_df(seq(1, 4, 0.5), ~ sim_int_f(100000, .x))\n\nsims_1 |&gt; \n  ggplot() + geom_line(aes(x = do_f, y = media_c)) +\n  geom_smooth(data = sims_fd_1, aes(x = f, y = c), method = \"loess\", span = 0.3, se = FALSE, colour =\"red\") + xlab(\"Grado de tabaquismo\") +\n  xlim(c(1,4))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 376 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\n\n\n\n\nEn efecto causal promedio de fumar, en cada nivel, sobre la incidencia de cáncer de pulmón, suponiendo nuestro proceso generador. Nótese que la relación no es tan fuerte como observamos en los datos naturales (en rojo). Esto se debe a que en los datos naturales, las personas existe una causa común entre no fumar y prevenir cáncer de pulmón.\n\n\nEjemplo: estimación con puerta delantera\nVeamos cómo sería la estimación si tuviéramos datos disponible, y si es que podemos recuperar el efecto correcto dados los datos observados y la técnica de puerta delantera.\nNótese que sólo necesitamos \\(p(c|a, f), p(a|f)\\) y \\(p(f)\\). Estos son modelos estadísticos con el que podemos identificar el efecto que nos interesa. Una vez que los estimemos, podemos usar simulación:\n\nFijamos una \\(f\\).\nSimulamos una \\(a\\) del modelo \\(p(a|f)\\)\nPara calcular \\(\\int p(c|a,f')p(f')\\), tenemos que simular un valor \\(f'\\) de la marginal de \\(p(f)\\), y luego, sustituir junto la \\(a\\) de 1 para simular una \\(c\\) de \\(p(c|a, f')\\).\nConsideramos solamente \\(c\\) y \\(f\\) para resumir el efecto.\n\n\nset.seed(481)\nsims_fd &lt;- simular_fd(2000)\nmod_front_door &lt;- cmdstan_model(\"./src/front-door.stan\")\nprint(mod_front_door)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; n_f;\n  vector[N] f;\n  vector[N]  a;\n  array[N]  int&lt;lower=0, upper=1&gt; c;\n  array[n_f] real do_f;\n\n}\n\ntransformed data {\n  real media_a;\n  real media_f;\n\n  media_a = mean(a);\n  media_f = mean(f);\n}\n\nparameters {\n  real&lt;lower=0&gt; alpha;\n  real alpha_a;\n  real&lt;lower=0&gt; alpha_f;\n  real int_a;\n  real beta_0;\n  real&lt;lower=0&gt; beta_1;\n  real&lt;lower=0&gt; beta;\n  real&lt;lower=0&gt; a_f;\n  real&lt;lower=0&gt; b_f;\n  real&lt;lower=0&gt; sigma_a;\n  real&lt;lower=0&gt; sigma_f;\n\n}\n\n\n\ntransformed parameters {\n\n\n}\n\nmodel {\n  f ~ gamma(a_f, b_f);\n  a ~ normal(beta * f, sigma_a);\n  c ~ bernoulli_logit(int_a + alpha_a * a + alpha_f * f);\n  alpha_a ~ normal(0, 1);\n  alpha_f ~ normal(0, 1);\n  int_a ~ normal(0, 3);\n  sigma_a ~ normal(0, 1);\n  sigma_f ~ normal(0, 0.1);\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  beta_0 ~ normal(0, 3);\n  beta_1 ~ normal(0, 1);\n\n}\ngenerated quantities {\n  array[n_f] real mean_c;\n\n  for(i in 1:n_f){\n    array[2000] real res_sim;\n    for(j in 1:2000){\n      real a_sim = normal_rng(beta * (do_f[i]), sigma_a);\n      real f_sim = gamma_rng(a_f, b_f);\n      res_sim[j] = bernoulli_rng(inv_logit(int_a + alpha_a * a_sim + alpha_f * f_sim));\n    }\n    mean_c[i] = mean(res_sim);\n  }\n\n}\n\n\n\ndo_f &lt;- seq(1, 4, 0.1)\nn_f &lt;- length(do_f)\nsims &lt;- mod_front_door$sample(data = list(N = nrow(sims_fd),\n      f = sims_fd$f, a = sims_fd$a,\n      c = sims_fd$c, do_f = do_f, n_f = n_f),\n  init = 0.01, step_size = 0.01, \n  refresh = 1000,\n  parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 39.1 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 40.0 seconds.\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 41.7 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 42.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 40.8 seconds.\nTotal execution time: 42.4 seconds.\n\n\n\nsims_efecto_tbl &lt;- sims$draws(\"mean_c\", format = \"df\") |&gt; \n  pivot_longer(cols = contains(\"mean_c\"), values_to = \"media_c\") |&gt; \n  separate(name, c(\"nom\", \"id\"), \n    sep = \"[\\\\[\\\\]]\", convert = TRUE, extra = \"drop\") |&gt; \n  left_join(tibble(f = do_f) |&gt; \n  mutate(id = seq_along(f))) \nresumen_tbl &lt;- sims_efecto_tbl |&gt; \n  group_by(id, f) |&gt; \n  summarise(media = mean(media_c), \n    q5 = quantile(media_c, 0.05),\n    q95 = quantile(media_c, 0.95))\n\n\nggplot(resumen_tbl) + \n  geom_linerange(aes(x= f, ymax = q95, ymin = q5), colour = \"red\") + \n  geom_point(aes(x = f, y = media), colour = \"red\") +\n  geom_line(data = sims_1, aes(x = do_f, y = media_c)) +\n  xlab(\"Nivel de tabaquismo\") + ylab(\"Prop afectada\")\n\n\n\n\n\n\n\n\nY parece que hemos obtenido una estimación razonable del efecto causal de fumar sobre cáncer. Recordemos también que debemos ser cuidadosos al comparar intervalos que salen del mismo modelo por su nivel de traslape.\nPor ejemplo, si quisiéramos calcular contrastes con el nivel 2 de tabaquismo:\n\nefecto_2 &lt;- sims_efecto_tbl |&gt; filter(f == 2) |&gt; \n  select(.draw, efecto_2 = media_c)\ncomp_tbl &lt;- left_join(sims_efecto_tbl, efecto_2) |&gt; \n  mutate(dif_2 = media_c - efecto_2)\n\nJoining with `by = join_by(.draw)`\n\ncomp_tbl |&gt; group_by(f) |&gt; \n  summarise(media = mean(dif_2), q5 = quantile(dif_2, 0.05),\n            q95 = quantile(dif_2, 0.95)) |&gt; \nggplot() + geom_linerange(aes(x= f, ymax = q95, ymin = q5)) + geom_point(aes(x = f, y = media))  +\n  xlab(\"Nivel de tabaquismo\") + ylab(\"Prop afectada\")\n\n\n\n\n\n\n\n\nNota: nótese como en este ejemplo hemos evitado incluir en nuestro modelo la variable no observada \\(U\\), gracias al procedimiento de puerta delantera descrito arriba.\nEs posible sin embargo intentar un modelo completo bayesiano, sin necesidad de recordar la fórmula. El procedimiento, que es más difícil de ajustar: considera una variable latente \\(U\\) no observada, y es necesario definir cómo puede ser su relación con sus descendientes. Es necesario más cuidado en definir formas funcionales e iniciales apropiadas para que los muestreadores funcionen apropiadamente.\n\n\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Identificación y cálculo-do</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html",
    "href": "07-buenos-malos-controles.html",
    "title": "7  Buenos y malos controles",
    "section": "",
    "text": "7.1 Controles buenos o neutros\nEn esta parte discutiremos una guía para decidir cuáles son buenos o malos “controles” para identificar efectos causales.\nSi nos interencia inferencia causal, estas son malas maneras de seleccionar variables o controles:\nComo hemos discutido, la decisión debe basarse primero en los supuestos causales (gráfica causal). Adicionalmente, también podemos considerar que, sujeto al anterior criterio, algunos modelos son más precisos o fáciles de estimar que otros.\nEjemplos de buenos controles son los de la fórmula de ajuste o los del criterio de puerta trasera que vimos en la sección anterior. Consideraremos los patrones que se presentan en Cinelli, Forney, y Pearl.\nConsideramos el siguiente diagrama: en este caso, \\(Z\\) causa variación en \\(Y\\). Controlar por \\(Y\\) puede mejorar la precisión de nuestras estimaciones causales, sin abrir ningún camino no causal (Modelo 8 en Cinelli, Forney, y Pearl, A Crash Course in Good and Bad Controls) :\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Z -&gt; Y\n    T -&gt; Y\n  }\n}\n', width = 250, height = 60)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#controles-buenos-o-neutros",
    "href": "07-buenos-malos-controles.html#controles-buenos-o-neutros",
    "title": "7  Buenos y malos controles",
    "section": "",
    "text": "7.1.1 Ejemplo\nQueremos probar un tratamiento para reducir peso. Aleatorizaremos las personas al tratamiento (por ejemplo una medicina), y antes de comenzar el estudio registramos su peso inicial y estatura. Nuestro diagrama es el siguiente, donde incluímos también el peso inicial que influye en el peso final después del tratamiento, y otras variables no observadas que influyen tanto en peso final como peso inicial (por ejemplo, si las personas estuvieron haciendo alguna dietas o no). También medimos una cantidad, al final del experimento, que es bienestar general de la persona (o una calificación de su estado de salud general). Adicionalmente medimos una variable \\(C\\) (cansancio), pues sabemos que esta medicina puede tener ese efecto. El cansancio puede afectar el peso final pues los niveles de actividad pueden cambiar. \\(B\\) puede ser en este caso una medición de circunferencia de abdomen, por ejemplo.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node[shape=circle]\n      U\n      V\n  node [shape=plaintext]\n    Z\n    T\n  edge [minlen = 3]\n   #G -&gt; H\n   #H -&gt; PI\n   Z -&gt; T\n   T -&gt; PF\n   #G -&gt; PF\n   PI -&gt; PF\n   U -&gt; PI\n   U -&gt; PF\n   V -&gt; PF\n   T -&gt; C -&gt; PF\n   PF -&gt; B\n}\n\")\n\n\n\n\n\n\nNo hay ninguna variable confusora, y una estrategia de estimación es comparar \\(PF\\) entre los grupos.\n\nsim_peso &lt;- function(n){\n  Z &lt;- rnorm(n, 0, 0.5)\n  p &lt;- inv_logit( Z)\n  T &lt;- rbinom(n, 1, p)\n  C &lt;- rbinom(n, 1, 1/(1+exp(-(-2 + 4 * T))))\n  U &lt;- rnorm(n, 0, 5)\n  G &lt;- rbinom(n, 1, 0.5)\n  H &lt;- rnorm(n, 170 - 10 * G, 20)\n  PI &lt;- rnorm(n, -20 +  0.5 * H + U, 10)\n  PF &lt;- rnorm(n, PI + U - 20 * T + 3 * C , 5)\n  #V &lt;- PF - (PI + U - 10 * T + 2 * C)\n  B &lt;- rbinom(n, 1, 1/(1 + exp(-(PF-50)/2)))\n  tibble(G, H, T, PI, PF, B, C, Z)\n}\nset.seed(226)\npeso_tbl &lt;- sim_peso(1200)\npeso_tbl\n\n# A tibble: 1,200 × 8\n       G     H     T    PI    PF     B     C       Z\n   &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n 1     0  152.     0  53.8  46.8     0     0 -0.701 \n 2     0  211.     0  87.2  87.0     1     0 -0.328 \n 3     0  169.     1  71.8  48.1     0     1 -0.256 \n 4     0  174.     0  66.4  61.6     1     0  0.208 \n 5     1  164.     0  64.0  63.9     1     0 -0.470 \n 6     0  146.     0  46.9  48.9     0     0 -0.126 \n 7     1  201.     0  69.9  74.4     1     0 -0.892 \n 8     1  153.     0  40.2  28.7     0     1 -0.0218\n 9     0  168.     1  58.1  26.3     0     1  0.221 \n10     1  162.     0  56.0  63.4     1     0  0.126 \n# ℹ 1,190 more rows\n\n\nEn aplicaciones realidad, no sabemos cuál es el efecto causal, pero en ejemplos simulados sí podemos calcularlo. En este caso, hacemos la siguiente simulación para tener nuestra referencia:\n\npeso_sims_tbl &lt;- sim_peso(100000)\npeso_sims_tbl |&gt; group_by(T) |&gt; \n  summarise(peso_final_medio = mean(PF)) |&gt; \n  arrange(T) |&gt; \n  mutate(dif = peso_final_medio - lag(peso_final_medio))\n\n# A tibble: 2 × 3\n      T peso_final_medio   dif\n  &lt;int&gt;            &lt;dbl&gt; &lt;dbl&gt;\n1     0             62.8  NA  \n2     1             45.2 -17.6\n\n\nPodemos hacer simplemente\n\nlm(PF ~ T, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     64.1     0.774      82.8 0       \n2 T              -18.7     1.11      -16.9 1.38e-57\n\n\ny el coeficiente de \\(T\\) sería una estimación del efecto causal promedio. Sin embargo, si condicionamos a \\(PI\\) tampoco creamos ninguna ruta no causal entre \\(T\\) y \\(PF\\). Podemos hacer también\n\nlm(PF ~ T + PI, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    -7.30    0.855      -8.54 3.91e- 17\n2 T             -17.8     0.404     -44.1  5.19e-253\n3 PI              1.13    0.0127     88.5  0        \n\n\nY notamos que nuestra estimación es más precisa. Esto es porque \\(PI\\) absorbe una parte importante de la variación de PF. Al incluir este control no cambiamos la cantidad que estamos estimando, pero sí el estimador particular, que en este caso tiene menos incertidumbre.\n\n\n\n\n\n\nFalacia de la Tabla 2\n\n\n\nNótese que no necesariamente podemos interpetar el coeficiente de \\(PI\\) fácilmente, pues existen rutas no casuales activas entre \\(PF\\) y \\(PI\\). Como explicamos antes, un modelo que se usa para identificar un efecto causal particular no implica que puedan interpretarse como causales otros coeficientes.\n\n\nNota: este error se llama “Falacia de Tabla 2” porque muchas veces se presenta, después de una tabla de descriptivos de los grupos de tratamiento y de no-trameinto, una tabla con los resultados de un modelo de regresión que identifica el efecto causal de interés. Aunque la identificación puede ser correcta, esto no quiere decir que podamos interpretar el coeficiente de las variables de estratificación o control.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#malos-controles-sobrecontrol",
    "href": "07-buenos-malos-controles.html#malos-controles-sobrecontrol",
    "title": "7  Buenos y malos controles",
    "section": "7.2 Malos controles: sobrecontrol",
    "text": "7.2 Malos controles: sobrecontrol\nEn los siguientes diagramas, condicionar por \\(Z\\) corta parte del efecto causal de \\(T\\) sobre \\(Y\\) (modelos 11 y 12 de Cinelli, Forney, y Pearl):\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    T -&gt; Z\n    Z -&gt; Y\n    T -&gt; Y\n  }\n  \n  subgraph caso_2 {\n    node [shape=plaintext]\n    Ya [label=\"Y\"]\n    Ta [label=\"T\"]\n    Za [label=\"Z\"][fontcolor=\"red\"]\n    edge [minlen = 3]\n    Ta -&gt; M\n    M -&gt; Ya\n    M -&gt; Za\n    Ta -&gt; Ya\n  }\n}\n', width = 250, height = 120)\n\n\n\n\n\n\n\nlm(PF ~ T +  C, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   64.0       0.805    79.5   0       \n2 T            -19.1       1.69    -11.3   2.38e-28\n3 C              0.514     1.69      0.305 7.60e- 1\n\nlm(PF ~ T +  PI + C, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    -7.77    0.856      -9.08 4.41e- 19\n2 T             -19.8     0.610     -32.4  7.57e-166\n3 PI              1.13    0.0126     89.2  0        \n4 C               2.59    0.610       4.25 2.32e-  5\n\n\nY vemos que nuestra estimación del efecto del tratamiento está sesgada, aparentando ser más efectiva de lo que es. La razón es que el camino que pasa por \\(C\\) “daña” en lugar de ayudar. El efecto causal total toma en cuenta tanto beneficios como daños.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#malos-controles-variables-post-tratamiento",
    "href": "07-buenos-malos-controles.html#malos-controles-variables-post-tratamiento",
    "title": "7  Buenos y malos controles",
    "section": "7.3 Malos controles: variables post-tratamiento",
    "text": "7.3 Malos controles: variables post-tratamiento\nVariables que son efectos de la variable respuesta que nos interesa son en general malos controles. Es un caso particular de cómo se produce sesgo casos-control (por ejemplo, cuando seleccionamos individuos para observar dependiendo de una variable post-tratamiento). Para entender eso, agregamos explícitamente nodos que usualmente no mostramos en nuestros diagramas (están ahí implícitamente), que son efectos sobre \\(Y\\) que no tienen conexiones causales con otras partes del diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node[shape= circle]\n    U_y\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Y -&gt; Z\n    T -&gt; Y  \n    U_y -&gt; Y\n  }\n}\n', width = 250, height = 120)\n\n\n\n\n\n\nHemos añadido un nodo implícito (otros factores que afectan \\(Y\\) y no tienen relación con otras variables del sistema) para explicar qué es lo que pasa cuando condicionamos a \\(Z\\): como \\(Z\\) es un descendiente del colisionador en \\(Y\\), se activa una ruta no causal entre \\(U_y\\) y \\(T\\), y estas dos cantidades aparecen como correlacionadas (es una correlación no causal). Esto en consecuencia modifica la correlación entre \\(T\\) y \\(Y\\).\n\nEjemplo\nEn nuestro ejemplo, podemos comparar las pendientes condicionando o no a la variable \\(B\\): vemos que dentro de cada grupo de \\(B\\), la pendiente es más chica que la que sugiere el efecto del tratamiento:\n\nggplot(peso_tbl, aes(x = T, y = PF, colour = factor(B))) +\n  geom_jitter() + \n   geom_smooth(method = \"lm\") +\n  geom_smooth(formula = \"y~ 1+x\", method = \"lm\", colour = \"red\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nComo vemos, la pendiente en cada grupo de \\(B\\) es más baja que la que obtendríamos si no condicionáramos a \\(B\\). Podemos explicarlo así, bajo el supuesto de que el tratamiento tiene algún efecto:\n\nEn el grupo \\(B=0\\): tiende a haber gente de peso más bajo. Para los que no recibieron el tratamiento, esto quiere decir que otros factores externos \\(U_y\\) fueron los explican por qué que cayeran en un nivel bajo (tienen \\(U_y\\) bajas. Por otro lado, el peso bajo de los que recibieron el tratamiento se debe también al tratamiento, por lo tanto, este grupo tiene \\(U_y\\) parecidas más parecidas a la población. Esto implica que estamos comparando grupos distintos de personas, y negamos ventajas de la aleatorización.\nEn el grupo \\(B=1\\): el argumento es similar. Aquí tiene a haber gente de peso más alto. Para los que recibieron tratamiento, esto implica que tienden a tener \\(U_y\\)’s más altas que la población. Para el grupo que no recibió el tratamiento, sus \\(U_y\\) son más parecidas a la población.\n\nEn ambos casos, obtenemos una estimación sesgada del efecto causal. En una regresión, \\(B\\) absorbe entonces parte de la variación que en realidad le corresponde al tratamiento:\n\nlm(PF ~ T +  B, peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    40.3      0.810     49.8  4.04e-294\n2 T              -7.68     0.798     -9.62 3.73e- 21\n3 B              31.0      0.811     38.2  1.09e-209\n\n\nEn la regresión el coeficiente de \\(T\\) está contaminado por esa asociación que creamos al condicionar a un descendiente de un colisionador: este coeficiente “explica” otra variación del peso final que no tiene qué ver con el tratamiento, en lugar de explicar solamente la variación por el tratamiento.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#malos-controles-sesgo-de-colisionador",
    "href": "07-buenos-malos-controles.html#malos-controles-sesgo-de-colisionador",
    "title": "7  Buenos y malos controles",
    "section": "7.4 Malos controles: sesgo de colisionador",
    "text": "7.4 Malos controles: sesgo de colisionador\nLos modelo 16 y 17 ya los hemos examinado antes: cuando condicionamos a un colisionador activamos no causales que distorsionan la asociación.\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    T -&gt; Z\n    Y -&gt; Z\n    T -&gt; Y\n  }\n  \n  subgraph caso_2 {\n    node [shape=circle]\n    U\n    node [shape=plaintext]\n    Ya [label=\"Y\"]\n    Ta [label=\"T\"]\n    Za [label=\"Z\"][fontcolor=\"red\"]\n    edge [minlen = 3]\n    U -&gt; Za\n    U -&gt; Ya\n    Ta -&gt; Ya\n    Ta -&gt; Za\n  {rank=same; Za; Ta}\n  }\n}\n', width = 250, height = 140)\n\n\n\n\n\n\n\nEjemplo: la paradoja de peso de recién nacidos\nPara ilustrar la primera de estas gráficas referimos al caso de la paradajo del peso bajo de los recién nacidos (Hernández-Díaz, Schisterman, y Hernán (2006)), The Birth Weight “Paradox” Uncovered?\nEn 1991, se observó que bebés nacidos de madres fumadoras tenían tanto peso más bajo como más alta mortalidad. Sin embargo, si excluíamos el análisis a bebés nacidos con bajo peso, los bebés de fumadoras tenían menos mortalidad que los de no fumadoras. Aunque hubo algunas especulaciones si fumar “protegía” a niños de bajo peso, podemos explicar la aparición de esta correlación por la activación de una ruta no causal al condicionar a niños de bajo peso.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    T [label = 'T']\n    Y [label = 'Y']\n    Z [label = 'Z'][fontcolor = 'red']\n    node [shape=circle]\n    U\n    edge [minlen = 3]\n    T -&gt; Y\n    T -&gt; Z\n    Z -&gt; Y\n    U -&gt; Z\n    U -&gt; Y\n  }\n}\")\n\n\n\n\n\n\nEn la gráfica de arriba, \\(T\\) indica si la madre es fumadora o no, y \\(Y\\) la mortalidad. \\(Z\\) si el bebé nació con bajo peso o no.\n\\(U\\) son posibles defectos de nacimiento no observados, que causan peso bajo e incrementan el riesgo de muerte. Cuando observamos a mujeres fumadoras, tenemos una explicación para el peso bajo, lo cual hace más improbable que se trate de un defecto grave de nacimiento. En consecuencia, el riesgo de muerte es más bajo.\nEsta es una asociación no causal creada por condicionar a un colisionador.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "07-buenos-malos-controles.html#controles-neutros-o-malos-parásito-de-precisión",
    "href": "07-buenos-malos-controles.html#controles-neutros-o-malos-parásito-de-precisión",
    "title": "7  Buenos y malos controles",
    "section": "7.5 Controles neutros o malos: parásito de precisión",
    "text": "7.5 Controles neutros o malos: parásito de precisión\nConsideramos el siguiente diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    edge [minlen = 3]\n    Z -&gt; T\n    T -&gt; Y\n  }\n}', width = 100, height = 50)\n\n\n\n\n\n\nEn este caso, condicionar a \\(Z\\) no sesga nuestras estimaciones, pues no activamos ninguna ruta no causal. La dificultad es que típicamente disminuye la precisión de la estimación (usamos un modelo más grande donde no es necesario):\n\nlm(PF ~ T + Z, data = peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   64.1       0.784    81.8   0       \n2 T            -18.8       1.14    -16.5   2.21e-55\n3 Z              0.446     1.15      0.388 6.98e- 1\n\nlm(PF ~ T, data = peso_tbl) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     64.1     0.774      82.8 0       \n2 T              -18.7     1.11      -16.9 1.38e-57\n\n\nEstos parásitos en ciertas circunstancias pueden empeorar estimaciones causales y causar sesgo adicional. Consideremos el siguiente diagrama:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  subgraph caso_1 {\n    node [shape=plaintext]\n    Z [fontcolor=\"red\"]\n    X\n    Y\n    node [shape = circle]\n    U\n    edge [minlen = 3]\n    U -&gt; X\n    U -&gt; Y\n    Z -&gt; X\n    X -&gt; Y\n  }\n}', width = 100, height = 50)\n\n\n\n\n\n\nEn este caso, tenemos una variable confusora \\(U\\) que no nos permite estimar sin sesgo el efecto de \\(T\\) sobre \\(Y\\). Sin embargo, si condicionamos a \\(Z\\), la situación puede emperorar (amplificación de sesgo), pues dentro de cada nivel de \\(Z\\) hay menos variación de \\(X\\), y eso implica que la covarianza entre \\(X\\) y \\(Y\\), en cada nivel de \\(Z\\), se debe más a la variable confusora.\nPodemos hacer un ejemplo simulado (ver más en McElreath (2020)):\n\nn &lt;- 5000\nz &lt;- rbinom(n, 1, 0.5)\nu &lt;- rnorm(n)\nx &lt;- rnorm(n, 5 * z + u, 1)\ny &lt;- rnorm(n, x +  u, 1)\ndatos &lt;- tibble(x = x, z = z, u = u, y = y) \nlm(y ~ x, datos) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -0.278   0.0265      -10.5 1.47e-25\n2 x              1.12    0.00697     161.  0       \n\nlm(y ~ x + z, datos) |&gt; broom::tidy()\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   0.0254    0.0250      1.02 3.09e-  1\n2 x             1.51      0.0124    121.   0        \n3 z            -2.56      0.0708    -36.2  1.78e-254\n\n\nEl efecto causal es de 1 unidad. Los modelos presentan estimaciones sesgadas, pero es peor el que incluye la variable parásito.\n\n\n\n\nCinelli, Carlos, Andrew Forney, y Judea Pearl. «A Crash Course in Good and Bad Controls». Sociological Methods & Research 0 (0): 00491241221099552. https://doi.org/10.1177/00491241221099552.\n\n\nHernández-Díaz, Sonia, Enrique F. Schisterman, y Miguel A. Hernán. 2006. «The Birth Weight “Paradox” Uncovered?» American Journal of Epidemiology 164 (11): 1115-20. https://doi.org/10.1093/aje/kwj275.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Buenos y malos controles</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html",
    "href": "08-mcmc.html",
    "title": "8  Markov Chain Monte Carlo",
    "section": "",
    "text": "8.1 Algoritmos Metropolis-Hastings\nEn esta sección exlicaremos brevemente cómo funcionan paquetes como Stan para producir simulaciones de una posteriores complicadas en dimensión alta.\nEn primer lugar, recordemos que si queremos calcular la posterior de un modelo (generalmente para calcular después resúmenes que involucran integrales de esta posterior) tenemos los siguiente enfoques:\nStan utiliza 3, y hay variedad de algoritmos MCMC. Ya discutimos que 1, la aproximación analítica, es en general imposible (a menos fuera de ciertos modelos restringidos). La aproximación 2 excesivamente intensiva, al grado que sólo para modelos muy chicos y con pocos parámetros es posible utilizarla. Existen otros métodos también como aproximaciones cuadráticas que en ciertos casos funcionan, pero son limitados en su aplicación.\nLa idea de simulación de variables aleatorias es ahora fundamental en muchas áreas científicas, incluyendo la estadística, y los métodos que la utilizan se llaman métodos de Monte Carlo. Por ejemplo, considera el método bootstrap, pruebas de permutaciones, validación cruzada, y en general simulación para cálculo de resúmenes que son difíciles de calcular directamente (por ejemplo, la mediana de una distribución Gamma, ver Median approximations and bounds aquí).\nUno de los primeros algoritmos MCMC fue el de Metropolis-Hastings, que veremos primero en algunos ejemplos. Veremos también por qué ahora tenemos mejores opciones que MH para estimar posteriores de nuestros modelos.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#algoritmos-metropolis-hastings",
    "href": "08-mcmc.html#algoritmos-metropolis-hastings",
    "title": "8  Markov Chain Monte Carlo",
    "section": "",
    "text": "Ejemplo: dos implementaciones de Metropolis\nSupongamos que queremos simular de una variable aleatoria \\(X\\) con distribución discreta sobre los valores \\(1,2\\ldots, k\\) con probabilidades \\(p(1),p(2),\\ldots,p(k)\\). Este problema puede resolverse fácilmente de varias maneras, pero utilizaremos un método de Monte Carlo tipo Metropolis. Supongamos que podemos simular de una variable aleatoria \\(U\\) que es uniforme en \\(1,2,\\ldots, k\\) (con probabilidades iguales a 1/k).\nLo que podemos hacer es lo que sigue, para \\(i=1,\\ldots, M\\):\n\nPara \\(i=1\\), comenzamos fijando un valor \\(x_1\\) en \\(1,2,\\ldots, k\\).\n\nPara cada \\(i\\),\n\nSimulamos una uniforme en \\(1,2,\\ldots, k\\). Al valor \\(u_i\\) obtenido le llamamos valor propuesto.\nCalculamos \\(q = p(u_i)/p(x_i)\\) (el cociente de la probabilidad del valor propuesto entre la probabilidad del valor actualo).\nSi \\(q &gt; 1\\), aceptamos el valor propuesto y ponemos \\(x_{i+1} = u_i\\).\nSi \\(q &lt; 1\\), aceptamos el valor propuesto con probabilidad \\(q\\) (\\(x_{i+1} = u_i\\)), y con probabilidad \\(1-q\\) rechazamos (\\(x_{i+1} = x_i\\)).\n\nEl resultado es una sucesión de valores \\(x_1,x_2,\\ldots, x_M\\). Es posible demostrar que la distribución de estas \\(x_i\\) converge a la distribución \\(p(1),\\ldots, p(k)\\) si \\(M\\) es suficientemente grande.\nEste método se llama Metropolis-Hastings. Es un método de Monte Carlo, y como podemos ver, se trata de una cadena de Markov, pues la distribución cada siguiente lugar \\(x_{i+1}\\), condicionada al valor actual \\(x_i\\) no depende de valores anteriores de las \\(x\\).\n\nset.seed(45123)\n# definimos estas p\nk &lt;- 40\np &lt;- exp(-(1:k - k/3)^2 / 10)\np &lt;- p /sum(p)\ndist_obj &lt;- tibble(x = 1:k, p = p)\n# simulamos\nM &lt;- 200000\nx &lt;- numeric(M)\nx[1] &lt;- 20\nfor(i in 1:M){\n  u &lt;- sample(1:k, 1)\n  q &lt;- p[u] / p[x[i]]\n  if(runif(1) &lt; q){\n    x[i+1] &lt;- u\n  } else {\n    x[i+1] &lt;- x[i]  \n  }\n}\n\nEn rojo mostramos las probabilidades objetivo que queremos estimar, y en negro las estimadas con nuestro método de arriba.\n\nresultados_sim &lt;- tibble(x = x) |&gt; \n  mutate(n_sim = row_number())\nresumen_sim &lt;- resultados_sim |&gt; count(x) |&gt; \n  right_join(tibble(x = 1:k, p = p)) |&gt; \n  mutate(n = ifelse(is.na(n), 0, n)) |&gt; \n  mutate(p_aprox = n / sum(n))\n\nJoining with `by = join_by(x)`\n\nggplot(dist_obj, aes(x = x)) +\n    geom_point(aes(y = p)) +\n  geom_point(data = resumen_sim, \n             aes(y = p_aprox), color = \"red\", size = 3, alpha = 0.5) \n\n\n\n\n\n\n\n\nComo vemos, los valores de \\(x_1,\\ldots, x_M\\) se distribuyen aproximadamente como la distribución \\(p\\) objetivo. Esta es una manera de simular valores de esta distribución discreta \\(p\\). Podemos ver cómo se ven las simulaciones sucesivas:\n\nggplot(resultados_sim |&gt; filter(n_sim &lt; 400), aes(x = n_sim, y = x)) +\n  geom_line() + scale_y_continuous(breaks = 1:20)\n\n\n\n\n\n\n\n\nEl defecto que tiene este algoritmo es que puede ser relativamente lento, pues vemos que hay periodos largos donde se “atora” en valores de probabilidad relativamente alta. La razón es que en muchos pasos, estamos proponiendo “saltos al vacío” a lugares de probabilidad muy baja, que rara vez se aceptan.\nPodemos hacer más eficiente nuestro algoritmo si le permitimos explorar con mayor facilidad los posibles valores de \\(x\\). Esto se logra proponiendo saltos locales: si estamos en \\(x_i\\), entonces proponemos los valores \\(x_i - 1\\) y \\(x_i + 1\\) con la misma probabilidad 1/2 (excepto en los extremos donde sólo proponemos \\(x_i,x_i+1\\) o \\(x_i-1,x_i\\)).\nProponemos entonces la suguiente modificación del paso 1 de propuesta:\n\nPara \\(i=1\\), comenzamos fijando un valor \\(x_1\\) en \\(1,2,\\ldots, k\\).\n\nPara cada \\(i\\),\n\nSi \\(1&lt; x_i&lt;k\\), escogemos al azar un salto a la derecha o al izquierda con igual probabilidad 1/2. En los extremos \\(x_i=1\\) o \\(x_i=k\\) escogemos entre \\(1,2\\) o \\(k-1,k\\) respectivamente. Al valor \\(u_i\\) obtenido le llamamos valor propuesto.\nCalculamos \\(q = p(u_i)/p(x_i)\\) .\nSi \\(q &gt; 1\\), aceptamos el valor propuesto y ponemos \\(x_{i+1} = u_i\\).\nSi \\(q &lt; 1\\), aceptamos el valor propuesto con probabilidad \\(q\\) (\\(x_{i+1} = u_i\\)), y con probabilidad \\(q\\) rechazamos(\\(x_{i+1} = x_i\\)).\n\nEsto lo escribimos como sigue:\n\n#set.seed(4511)\n# simulamos\nx &lt;- numeric(M)\nx[1] &lt;- 20\nfor(i in 1:M){\n  u &lt;- sample(c(x[i] - 1,  x[i] + 1), 1)\n  if(u == k+1) u &lt;- k\n  if(u == 0) u &lt;- 1\n  q &lt;- p[u] / p[x[i]]\n  if(runif(1) &lt; q){\n    x[i+1] &lt;- u\n  } else {\n    x[i+1] &lt;- x[i]  \n  }\n}\n\nObtenemos:\n\nresultados_sim_2 &lt;- tibble(x = x) |&gt; \n  mutate(n_sim = row_number())\nresumen_sim_2 &lt;- resultados_sim_2 |&gt; count(x) |&gt; \n  mutate(p_aprox = n / sum(n))\nggplot(dist_obj, aes(x = x)) +\n    geom_point(aes(y = p)) +\n  geom_point(data = resumen_sim_2, \n             aes(y = p_aprox), color = \"red\", size = 3, alpha = 0.5) \n\n\n\n\n\n\n\n\nY podemos ver cómo evoluciona nuestra cadena de Markov:\n\nggplot(resultados_sim_2 |&gt; filter(n_sim &lt; 400), aes(x = n_sim, y = x)) +\n  geom_line() + scale_y_continuous(breaks = 1:20)\n\n\n\n\n\n\n\n\n¿Cómo se comparan estos dos métodos? Podemos ver por ejemplo cómo se comparan las distribuciones aproximadas hasta cierto número de iteraciones con la verdadera distribución objetivo:\n\napprox_sim &lt;- map_df(seq(200, 30000, by = 200), function(n_sims){\n  resumen_1 &lt;- resultados_sim |&gt; filter(n_sim &lt;= n_sims) |&gt; \n    count(x) |&gt;\n    mutate(p_aprox = n / sum(n)) |&gt;\n    select(-n) |&gt;\n    right_join(dist_obj, by = \"x\") |&gt; \n    mutate(metodo = \"MH-1\") |&gt; \n    mutate(n_sims = n_sims) \n  resumen_2 &lt;- resultados_sim_2 |&gt; filter(n_sim &lt;= n_sims) |&gt;\n    count(x) |&gt;\n    mutate(p_aprox = n / sum(n)) |&gt;\n    select(-n) |&gt;\n    right_join(dist_obj, by = \"x\") |&gt; \n    mutate(metodo = \"MH-2\") |&gt; \n    mutate(n_sims = n_sims) \n  bind_rows(resumen_1, resumen_2) |&gt; \n    mutate(p_aprox = ifelse(is.na(p_aprox), 0, p_aprox))\n})\n\n\napprox_sim |&gt; \n  mutate(dif_abs = abs (p_aprox-p)) |&gt;\n  group_by(metodo, n_sims) |&gt; \n  summarise(dif_abs = sum(dif_abs)) |&gt; \nggplot(aes(n_sims, dif_abs, color = metodo)) +\n  geom_line() \n\n`summarise()` has grouped output by 'metodo'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nEn este caso, considera qué es lo que sucede en cada uno de estos casos:\n\nEl algoritmo que da saltos grandes muchas veces rechaza porque las propuestas caen con demasiada frecuencia en área de probabilidad (objetivo) muy baja. Tasas muy altas de rechazo son ineficientes.\nEl algoritmo que da saltos chicos puede tardar en explorar regiones de probabilidad relativamente alta con suficiente frecuencia (tarda un moverse de un lugar a otro), por su naturaleza de “caminata aleatoria”. Pero sus tasas de aceptación son más altas. En este caso, es ineficiente porque la cadena tarda en explorar el espacio de parámetros.\n\nEste es el primer trade-off que existe en este algoritmo: tomar pasos grandes y balancear las probabilidades quizá rechazando muy frecuentemente (no es eficiente), o tomar pasos chicos y vagar más tiempo para visitar regiones de alta probabilidad, aunque con menos tasa de rechazo. Dependiendo de la distribución que queremos aproximar podemos inclinarnos más por una o por otra opción. En dimensiones altas generalmente ninguna combinación es muy buena para Metropolis Hastings.\n\n\n\n\n\n\nIdea básica de MCMC\n\n\n\nEn MCMC, buscamos un cadena de Markov que, en el largo plazo, visite cada posible valor del parámetro proporcionalmente a la probabildad posterior del parámetro. En el caso multivariado es la misma idea: cada combinación de parámetros debe ser visitada por la cadena en proporción a su probabilidad posterior.\n\n\n\n\nBalance detallado\n¿Por qué funcionan estos algoritmos? Supongamos que en cada paso, se cumple que (balance detallado): \\[{q(x|y)}p(y) = {q(y|x)}{p(x)}\\] donde \\(q(x|y)\\) son las probabilidades de transición de nuestra cadena de Markov propuesta. Esta ecuación dice que la proporción de transiciones de \\(y\\) a \\(x\\) en relación a las transiciones de \\(x\\) a \\(y\\) es la misma que la proporción de probabilidad que hay entre \\(y\\) y \\(x\\) en la distribución objetivo.\nEsta ecuación implica que si la probabilidad se distribuye como \\(p(x)\\), entonces al transicionar con \\(q\\) la probabilidad fluje de manera que se mantiene estática en \\(p\\), es decir \\(p\\) es una distribución estacionaria para la cadena de Markov producida por las transiciones.\nEsto es fácil de demostrar pues \\[\\sum_{y} q(x|y)p(y) = \\sum_{y} q(y|x)p(x) = p(x) \\sum_{y} q(y|x) = p(x).\\]\nBajo otros supuestos adicionales de ergodicidad (aperiodicidad y tiempos de recurrencia finitos, es decir, las transiciones mezclan bien los estados), entonces podemos simular la cadena de Markov por un tiempo suficientemente largo y con esto obtener una muestra de la distribución objetivo \\(p\\), es decir, la distribución estacionaria \\(p(x)\\) también es la distribución de largo plazo para cualquier cadena que simulemos.\n¿Cómo podemos diseñar entonces las \\(q(x|y)\\) correspondientes?\nComenzamos considerando distribuciones propuesta \\(q_0(x|y)\\) que no necesariamente satisfacen la ecuación de balance, y supondremos como en los ejemplos de arriba (verifícalo) que nuestras transiciones tienen probabilidades simétricas \\(q_0(y|x) = q_0(x|y)\\). Entonces, cuando \\(p(y)/p(x) &gt; 1\\), queremos transicionar de \\(x\\) a \\(y\\) con más frecuencia que de \\(y\\) a \\(x\\). Tiene sentido entonces que, comenzando en \\(x\\), si la propuesta de \\(q_0(y|x)\\) es \\(y\\), pongamos que el sistema transicione con probabilidad 1 a \\(y\\). Sin embargo, si empezamos en \\(y\\) y la propuesta es \\(x\\), ponemos que el sistema sólo transiciona de \\(y\\) a \\(x\\) con probabilidad \\(p(x)/p(y)\\) (esta el la descripción de Metropolis Hastings).\nDe esta manera, obtenemos que bajo \\(q(y|x)\\), \\(x\\) transiciona a \\(y\\) con probabilidad \\(q_0(y|x)\\) multiplicada por \\(\\min\\{1, p(y)/p(x)\\}\\). Entonces, el cociente \\(\\frac{q(y|x)}{q(x|y)}\\) (usando también la simetría de \\(q_0(y|x)\\), es igual a \\(\\frac{p(y)}{p(x)}\\) si \\(p(y)&gt;p(x)\\). Si \\(p(x)&gt;p(y)\\), entonces siguiendo el mismo argumento, y por simetría de \\(q_0(y|x)\\), se cumple que el cociente de probabilidades es tambien igual a \\(\\frac{p(y)}{p(x)}\\). Esto demuestra que se cumple el balance detallado.\nDe esta forma, balanceamos las transiciones de \\(q_0(y|x)\\) modificando con el proceso de aceptación y rechazo, para que la cadena de Markov resultante tenga la distribución estacionaria \\(p(x)\\), que es la distribución objetivo.\nNótese adicionalmente que basta con conocer \\(p(x)\\) módulo una constante de proporcionalidad para poder usar este algoritmo. Cuando lo usamos para simular posteriores esto es importante, pues podemos utilizar \\(p(\\theta|D)\\propto p(D|\\theta)p(\\theta)\\) sin tener que calcular la integral \\(p(D)\\) que normaliza el lado derecha de esta ecuación.\n\n\nEjemplo: Metropolis bivariado\nSupongamos ahora que quisiéramos simular de una normal multivariada con media en c(2,3) y matriz de covarianza \\(\\Sigma\\), que supondremos es tal que la desviación estándar de cada variable es 1 y la correlación es 0.8. La matriz \\(\\Sigma\\) tiene 1 en la diagonal y 0.8 fuera de la diagonal.\nLa distribución objetivo \\(p\\) está dada entonces (módulo una constante de proporcionalidad):\n\nconstruir_log_p &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(z){\n    - 0.5 * (t(z-m) %*% Sigma_inv %*% (z-m))\n  }\n}\nSigma &lt;- matrix(c(1, 0.8, 0.8, 1), nrow = 2)\nm &lt;- c(2, 3)\nlog_p &lt;- construir_log_p(m, Sigma)\n\nNótese que como Metropolis hace cocientes de probabilidades, sólo es necesario conocer la densidad objetivo módulo una constante de proporcionalidad.\nUna algoritmo de Metropolis podría ser el siguiente:\n\n# simulamos\nM &lt;- 50000\nmetropolis_mc &lt;- function(M, z_inicial = c(0,0), log_p, delta_x, delta_y){\n  z &lt;- matrix(nrow = M, ncol = 2)\n  z[1, ] &lt;-z_inicial\n  colnames(z) &lt;- c(\"x\", \"y\")\n  rechazo &lt;- 0\n  for(i in 1:(M-1)){\n    x_prop &lt;- rnorm(1, z[i, 1], delta_x)\n    y_prop &lt;- rnorm(1, z[i, 2], delta_y)\n    z_prop &lt;- c(x_prop, y_prop)\n    q &lt;- exp(log_p(z_prop) - log_p(z[i, ]))\n    if(runif(1) &lt; q){\n      z[i + 1, ] &lt;- z_prop\n    } else {\n      rechazo &lt;- rechazo + 1\n      z[i + 1, ] &lt;- z[i, ]\n    } \n  }\n  print(rechazo / M)\n  z_tbl &lt;- as_tibble(z) |&gt; \n    mutate(n_sim = row_number())\n  z_tbl\n}\nz_tbl &lt;- metropolis_mc(M, c(2.5, 3.5), log_p, 1.0, 1.0)\n\n[1] 0.59752\n\n\nVemos que tenemos una tasa alta de rechazos. ¿Por qué? Veamos cómo se ven las simulaciones hasta 500 iteraciones:\n\n\nCódigo\n# estas las usamos para graficar\nsims_normal &lt;- mvtnorm::rmvnorm(100000, mean = m, sigma = Sigma)\ncolnames(sims_normal) &lt;- c(\"x\", \"y\")\nsims_normal &lt;- as_tibble(sims_normal)\nelipses_normal &lt;-list(stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.9), type = \"norm\", colour = \"salmon\"),\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.5), type = \"norm\", colour = \"salmon\"), \n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.2), type = \"norm\", colour = \"salmon\"))\n\n\n\ngraf_tbl &lt;- map_df(seq(10, 500, 20), function(i){\n  z_tbl |&gt; filter(n_sim &lt;= i) |&gt; mutate(num_sims = i)\n})\nggplot(graf_tbl, aes(x, y)) + \n  elipses_normal +\n  geom_point(alpha = 0.1) +\n  facet_wrap(~num_sims) + theme_minimal()\n\n\n\n\n\n\n\n\n\nlibrary(gganimate)\nanim_mh_1 &lt;- z_tbl |&gt; filter(n_sim &lt; 50) |&gt; \n  ggplot() + \n  geom_point(aes(x, y, group = n_sim), size = 3) +\n  transition_reveal(n_sim) +\n  elipses_normal +\n  labs(title = 'Iteración: {frame_along}') +\n  theme_minimal()\nanim_save(animation = anim_mh_1, filename = \"figuras/mh-1-normal.gif\", \n          renderer = gifski_renderer())\n\n\n\n\nMetropolis Hastings\n\n\nObservaciones:\n\nLos puntos que tienen intensidad alta son puntos donde hubo varios rechazos. Esto es porque las propuestas a veces caen en elipses de baja probabilidad (en la gráfica mostramos una elipse de 50% probabilidad y otra de 95%).\nEsto se debe a que los saltos en cada dirección son de desviación estándar 1, y esto fácilmente nos lleva a una zona de alta probabilidad a una de baja probabilidad.\nSin embargo, a largo plazo, vemos cómo la cadena está visitando las regiones de alta probabilidad con aparentemente la frecuencia correcta.\n\nPodemos entonces proponer saltos más chicos, por ejemplo:\n\nz_tbl &lt;- metropolis_mc(M, c(2.5, 3.5), log_p, 0.2, 0.2)\n\n[1] 0.15584\n\ngraf_tbl &lt;- map_df(seq(10, 500, 20), function(i){\n  z_tbl |&gt; filter(n_sim &lt;= i) |&gt; mutate(num_sims = i)\n})\nggplot(graf_tbl, aes(x, y)) + \n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c( 0.9), type = \"norm\", colour = \"salmon\") +\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c( 0.5), type = \"norm\", colour = \"salmon\") +\n  geom_point(alpha = 0.1) +\n  facet_wrap(~num_sims) + theme_minimal()\n\n\n\n\n\n\n\n\n\nanim_mh_2 &lt;- z_tbl |&gt; filter(n_sim &lt; 150) |&gt; \n  ggplot() + \n  geom_point(aes(x, y, group = n_sim), size = 3) +\n  transition_reveal(n_sim) +\n  elipses_normal +\n  labs(title = 'Iteración: {frame_along}') +\n  theme_minimal()\nanim_save(animation = anim_mh_2, filename = \"figuras/mh-2-normal.gif\", \n          renderer = gifski_renderer())\n\n\n\n\nMetropolis Hastings salto chico\n\n\nObservaciones:\n\nEn este caso tenemos una tasa de aceptación más alta.\nSin embargo, la cadena parece “vagar” en la regiones de probabilidad alta, y tiene dificultades para explorar correctamente estas regiones: se comporta localmente como una caminata aleatoria.\nSin embargo, a largo plazo, vemos cómo la cadena está visitando las regiones de alta probabilidad con aparentemente la frecuencia correcta.\n\n\n\n\n\n\n\nMetropolis-Hastings\n\n\n\nEn el algoritmo de Metropolis Hastings hay una tensión natural entre el tamaño de salto y la tasa de aceptación. Si el tamaño de los saltos es muy grande, la tasa de aceptación puede ser baja y esto producen ineficiencias. Si el tamaño de los saltos es muy chico, la tasa de aceptación es más alta, pero esto también es ineficiente pues la cadena puede explorar muy lentamente el espacio de parámetros.\n\n\nExisten métodos que pueden superar este problema, como son muestreo de Gibbs y Monte Carlo Hamiltoniano. El primero no lo discutiremos, pues requiere poder simular fácilmente de cada parámetro dados los otros, y esto no siempre es posible. Veremos más el segundo, donde usaremos información del gradiente de la distribución objetivo para proponer exploración más eficiente.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#monte-carlo-hamiltoniano",
    "href": "08-mcmc.html#monte-carlo-hamiltoniano",
    "title": "8  Markov Chain Monte Carlo",
    "section": "8.2 Monte Carlo Hamiltoniano",
    "text": "8.2 Monte Carlo Hamiltoniano\nUna manera de mejorar la exploración de Metropolis es utilizar una distribución de propuestas más apropiada. La intuición en el caso anterior es:\n\nHay direcciones de más curvatura de la posterior que otras: movimientos relativamente chicos en las direcciones de alta curvatura nos llevan a regiones de probabilidad demasiado baja, y entonces tendemos a rechazar. Pero hacer movimientos aún más chicos para evitar rechazos nos lleva a explorar muy lentamente el espacio de parámetros.\nPodríamos evitar esto si nuestros saltos siguieran la curvatura natural de la distribución, como una pelota que rueda por la superficie de la distribución objetivo (con signo negativo, de forma que regiones de probabilidad alta sean valles o regiones bajas).\n\nLa idea de HMC es considerar el problema de muestrear de una distribución como un problema físico, donde introducimos aleatoridad solamente en cuanto a la “energía” de la pelota que va a explorar la posterior. Inicialmente impartimos un momento tomado al azar a la pelota, seguimos su trayectoria por un tiempo y el lugar a donde llega es nuestra nueva simulación. Esto permite que podamos dar saltos más grandes, sin “despeñarnos” en regiones de probabilidad muy baja y al menos teóricamente, evitar del todo los rechazos (veremos que en la implementación de todas formas necesitaremos implementar algunos rechazos para mejorar eficiencia).\nAdicionalmente, veremos que si definimos el sistema físico apropiadamente, es posible obtener ecuaciones de balance detallado, lo cual en teoría nos garantiza una manera de transicionar que resultará a largo plazo en una muestra de la distribución objetivo.\n\nFormulación Hamiltoniana 1: introducción\nPrimero veremos cuál es la formulación Hamiltoniana (muy simple) de un sistema físico que nos sirve para encontrar la trayectoria de partículas del sistema. Consideremos una sola partícula cuya posición está dada por \\(q\\), que suponemos en una sola dimensión. La partícula rueda en una superficie cuya altura describimos como \\(V(q)\\), y tiene en cada instante tiene momento \\(p = m\\dot{q}\\).\nEl Hamiltoniano es la energía total de este sistema, en el espacio fase que describe el estado de cada partícula dadas su posición y momento \\((p,q)\\), y es la suma de energía cinética más energía potencial:\n\\(H(p,q) = T(p) + V(q)\\)\ndonde \\(V(q) = q^2/2\\) está dada y \\(T(p) = \\frac{p^2}{2m}\\), de modo que\n\\[H(p, q) = \\frac{p^2}{2m} + V(q) = \\frac{p^2}{2m} + \\frac{q^2}{2}\\]\nAhora consideremos las curvas de nivel de \\(H\\) (energía total constante), que en este caso se conservan a lo largo del movimiento de la partícula. Como sabemos por cálculo, estas curvas son perpendiculares al gradiente del Hamiltoniano, que es \\((\\partial{H}/\\partial{p}, \\partial{H}/\\partial{q})\\). El movimiento de las partículas, sin embargo, es a lo largo de las curvas de nivel, de manera que el flujo instantáneo debe estar dado por el gradiente de \\(H\\) rotado 90 grados, es decir, por \\((\\partial{H}/\\partial{q}, -\\partial{H}/\\partial{p})\\).\nEntonces tenemos que el movimiento de la partícula debe cumplir las ecuaciones de Hamilton:\n\\[\\frac{dp}{dt} = \\frac{\\partial{H}}{\\partial{q}}, \\frac{dq}{dt} = -\\frac{\\partial{H}}{\\partial{p}}\\] Simplificando y usando la definición de \\(H\\), obtenemos que \\[\\frac{dq}{dt} = \\frac{p}{m}, \\frac{dp}{dt} = -\\frac{\\partial{V}}{\\partial{q}} = -q\\] Ilustramos este campo vectorial en la siguiente gráfica, donde escogemos \\(V(q) = q^2/2\\), \\(m=1\\), y dibujamos algunas curvas de nivel del Hamiltoniano:\n\n\nCódigo\nespacio_fase_1 &lt;- tibble(p = seq(-3, 3, length.out = 1000), q = seq(-3, 3, length.out = 1000)) |&gt; \n  expand(p, q) |&gt; \n  mutate(dq = p, dp = -q) |&gt; \n  mutate(H = p^2/2 + q^2/2)\nespacio_fase &lt;- tibble(p = seq(-3, 3, length.out = 10), q = seq(-3, 3, length.out = 10)) |&gt; \n  expand(p, q) |&gt; \n  mutate(dq = p, dp = -q)\nespacio_fase |&gt; \n  ggplot(aes(p, q)) +\n  geom_contour(data = espacio_fase_1, aes(x = p, y = q, z = H)) +\n  geom_segment(aes(xend = p + dp/5, yend = q + dq/5), \n               arrow = arrow(length = unit(0.1, \"inches\"))) +\n  theme_minimal() +\n  labs(subtitle = \"Movimiento en espacio fase: 1 dimensión\")\n\n\n\n\n\n\n\n\n\nOjo: este no es le movimiento de una partícula en dimensión 2: es el movimiento de la partícula en el espacio fase \\((p,q)\\), y la variable de posición \\(q\\) es de dimensión 1. Los ciclos de la gráfica muestran como conforme la partícula se mueve, energía potencial y cinética se intercambian a lo largo de su trayectoria en un “hilo” o curva de nivel.\n\n\nFormulación Hamiltoniana 2: densidades de probabilidad\nConsideremos una partícula en el espacio de parámetros \\(\\theta\\). En esta formulación, si \\(\\theta\\) son los parámetros de interés, consideramos la energía potencial del sistema como \\(V(p) = -\\log p(\\theta)\\), donde \\(p(\\theta)\\) es la distribución objetivo.\nBuscamos simular del sistema con ecuaciones de movimiento para \\(\\theta\\). Como hicimos antes, vamos a “levantar” al espacio fase incluyendo el momento, que denotaremos como \\(\\rho\\). La energía cinética, en el caso más simple, podemos definirla (en la práctica existen reescalamientos) como como \\(T(\\rho) =\\frac{1}{2}\\sum_i \\rho_i^2\\) (la energía cinética es proporcional al momento cuadrado, pues el momento es masa por velocidad).\nEl Hamiltoniano por definición \\(H(\\rho, \\theta) = T(\\rho) + V(\\theta)\\), y las ecuaciones de Hamilton son las mismas que arriba, que en este caso nos dan\n\\[\\frac{d\\theta}{dt} = \\rho, \\frac{d\\rho}{dt} = \\nabla(\\log(p(\\theta)).\\]\nSi resolvemos estas ecuaciones, podemos entonces simular del sistema como sigue:\n\nDado un punto inicial \\(\\theta\\), escogemos un momento inicial \\(\\rho\\) al azar, por ejemplo cada componente normal \\(N(0,1)\\) (en la práctica existe un reescalamiento, pero en general queremos que \\(p(\\rho) = p(-\\rho)\\)). Es decir, agregamos inicialmente una cantidad aleatoria de energía a la partícula.\nUsando las ecuaciones de Hamilton, actualizamos la posición \\(\\theta\\) y el momento de la partícula un cierto tiempo \\(t\\) fijo, de manera que no quedemos muy cerca del valor inicial, pero tampoco hagamos demasiado trabajo computacional.\nLa posición nueva \\(\\theta^*\\) es aceptada como nuestra nueva simulación (si el paso 2 es exacto, pero frecuentemente no lo es).\nRepetimos los pasos 1-3 un número suficiente de veces para obtener simulaciones de la posterior.\n\nEste método produce simulaciones de la distribución objetivo bajo condiciones de regularidad. Podemos demostrar por ejemplo, que se cumple el balance detallado.\n\n\nBalance detallado para HMC\nSupongamos que las transiciones que da este sistema son \\(q(y|x)\\). Nótese que dado el momento simulado, tenemos el estado \\((\\rho, x)\\), y la transición \\(x\\to y\\) es determinista, gobernada por las ecuaciones de Hamilton. Escribimos la transición como \\[(\\rho, x) \\to (\\rho^*, y).\\] Nótese que \\(\\rho\\) y \\(x\\) determinan la transición, de modo que\n\\[p(x)q(y|x) = p(x)p(\\rho) = \\exp(-H(\\rho, x)) = \\exp(-H(\\rho^*, y))\\] Que es cierto por conservación de la energía total y la transición sigue exactamente trayectorias del Hamiltoniano. Esta última cantidad, usando un argumento similar, es igual a\n\\[p(y)p(\\rho^*) = p(y)p(-\\rho^*) = p(y) q(x|y)\\] La segunda igualdad se da porque \\(p(\\rho)\\) es Gaussiana (simétrica). Y finalmente, la última igualdad se da porque si necesitamos momento \\(\\rho\\) para llegar de \\(x\\) a \\((\\rho^*, y)\\), entonces necesitamos \\(-\\rho^*\\) (volteamos la velocidad ifnal) para llegar de \\(y\\) a \\((\\rho, x)\\), pues el sistema físico es reversible.\nNótese que este argumento se rompe si por ejemplo si es imposible transicionar de un punto a otro (por ejemplo, cuando la distribución objetivo \\(p\\) tiene dos regiones separadas de probabilidad positiva).\n\n\nIntegración de las ecuaciones de Hamilton\nPara aproximar soluciones de estas ecuaciones diferenciales utilizamos el integrador leapfrog, en el que hacemos actualizaciones alternadas de posición y momento con un tamaño de paso \\(\\epsilon\\) chico. Hacemos este paso un número \\(L\\) de veces, para no quedar muy cerca del valor inicial.\nEn nuestro ejemplo, actualizaríamos por ejemplo el momento a la mitad del paso:\n\\[\\rho_{t+\\epsilon/2} = \\rho_t - \\frac{\\epsilon}{2}\\nabla(\\log(p(\\theta_t)))\\] Seguido de una actualización de la posición:\n\\[\\theta_{t+\\epsilon} = \\theta_t + \\epsilon \\rho_{t+\\epsilon/2}\\] y finalmente otra actualización del momento:\n\\[\\rho_{t+\\epsilon} = \\rho_{t+\\epsilon/2} - \\frac{\\epsilon}{2}\\nabla(\\log(p(\\theta_{t+\\epsilon})))\\] Al final de este proceso, encontraremos que por errores numéricos, quizá el Hamiltoniano varió un poco. Si esto sucede, podemos hacer un paso de aceptación y rechazo como en Metropolis Hastings, donde la probabilidad de aceptar es\n\\[\\min\\left(1, \\exp(H(\\rho,\\theta) - H(\\rho^{*},\\theta^{*}))\\right)\\] donde \\(\\rho^{*}\\) y \\(\\theta^{*}\\) son los valores de momento y posición nuevos y \\(H(\\rho,\\theta)\\) es el Hamiltoniano en el paso anterior.\nObservaciones:\n\nUn caso posible obtengamos desbordes o casi desbordes numéricos del momento o la posición (el Hamiltoniano en el punto inicial es órdenes de magnitud diferente que el inicial, ver el manual de Stan ). Esto indica problemas graves con el algoritmo de integración, y en general marcamos estas iteraciones como divergentes. Estas fallas pueden producir, como veremos, exploración insuficiente de la distribución objetivo.\nSi queremos usar HMC directamente, es delicado afinar el tamaño de paso, la distribución de propuesta para el momento, y el número de saltos \\(L\\). En Stan, que usa una variación de HMC, estos valores son ajustados en el periodo de calentamiento o warmup, antes de\n\n\n\nEjemplo: HMC en una distribución normal bivariada\nPrimero calculamos el gradiente que requerimos. En este caso, podemos hacerlo analíticamente:\n\nconstruir_log_p &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(z){\n    - 0.5 * (t(z-m) %*% Sigma_inv %*% (z-m))\n  }\n}\nSigma &lt;- matrix(c(1, 0.8, 0.8, 1), nrow = 2)\nm &lt;- c(2, 3)\nlog_p &lt;- construir_log_p(m, Sigma)\n# en diferenciación automática, el siguiente constructor\n# puede tomar como argumento log_p, pero aquí la escribimos\n# explícitamente\nconstruir_grad_log_p &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(theta){\n    - Sigma_inv %*% (theta-m)\n  }\n}\ngrad_log_p &lt;- construir_grad_log_p(m, Sigma)\nconstruir_H &lt;- function(m, Sigma){\n  Sigma_inv &lt;- solve(Sigma)\n  function(theta, rho){\n    - log_p(theta) + 0.5 * sum(rho^2)\n  }\n}\nH &lt;- construir_H(m, Sigma)\nlog_p(c(1,3))\n\n          [,1]\n[1,] -1.388889\n\ngrad_log_p(c(1,3))\n\n          [,1]\n[1,]  2.777778\n[2,] -2.222222\n\n\nAhora, implementamos el algoritmo de HMC. Primero, definimos una función\n\nhamilton_mc &lt;- function(n, theta_0 = c(0,0), log_p, grad_log_p, epsilon, L){\n  p &lt;- length(theta_0)\n  theta &lt;- matrix(0, n, p)\n  theta[1, ] &lt;- theta_0\n  rho &lt;- matrix(0, n, p)\n  theta_completa &lt;- matrix(0, n*L, p)\n  theta_completa[1, 0] &lt;- theta_0\n  rho_completa &lt;- matrix(0, n*L, p) \n  indice_completa &lt;- 2\n  rechazo &lt;- 0\n  for(i in 2:n){\n    prop_rho &lt;- rnorm(p)\n    rho[i-1, ] &lt;- prop_rho\n    prop_theta &lt;- theta[i-1, ]\n    for(t in 1:L){\n      prop_rho &lt;- prop_rho + 0.5 * epsilon * grad_log_p(prop_theta)\n      prop_theta &lt;- prop_theta + epsilon * prop_rho \n      prop_rho  &lt;- prop_rho + 0.5 * epsilon * grad_log_p(prop_theta)\n      theta_completa[indice_completa,] &lt;- prop_theta\n      rho_completa[indice_completa,] &lt;- prop_rho\n      indice_completa &lt;- indice_completa + 1\n    }\n  \n    q &lt;- min(1, exp(H(theta[i-1, ], rho[i-1, ]) - \n                  H(prop_theta, prop_rho))) \n    if(runif(1) &lt; q){\n      theta[i, ] &lt;- prop_theta\n    } else {\n      rechazo &lt;- rechazo + 1\n      theta[i, ] &lt;- theta[i-1, ]\n      rho[i, ] &lt;- rho[i-1, ]\n      theta_completa[indice_completa - 1,] &lt;- theta[i-1, ]\n      rho_completa[indice_completa - 1,] &lt;- rho[i-1, ]\n    } \n  }\n  print(rechazo / n)\n  list(sims = tibble(x = theta[,1], y = theta[,2]),\n       trayectorias = tibble(x = theta_completa[,1], y = theta_completa[,2]) |&gt;\n         mutate(iteracion = rep(1:n, each = L), paso = rep(1:L, times = n)))\n}\n\nRevisamos que la muestra aproxima apropiadamente nuestra distribución\n\nset.seed(10)\nhmc_salida &lt;- hamilton_mc(1000, c(0,0), log_p, grad_log_p, 0.2, 12)\n\n[1] 0.016\n\nggplot(hmc_salida$sims, aes(x = x, y = y)) + geom_point() +\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c(0.9), type = \"norm\", colour = \"salmon\") +\n  stat_ellipse(data = sims_normal, aes(x, y), \n               level = c( 0.5), type = \"norm\", colour = \"salmon\") +\n  stat_ellipse(level = c( 0.9), colour = \"green\", type = \"norm\") +\n  stat_ellipse(level = c( 0.5), colour = \"green\", type = \"norm\") \n\n\n\n\n\n\n\n\n\ntray_tbl &lt;- hmc_salida$trayectorias\nhead(tray_tbl)\n\n# A tibble: 6 × 4\n        x      y iteracion  paso\n    &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt; &lt;int&gt;\n1  0      0              1     1\n2 -0.0185 0.0409         1     2\n3 -0.0757 0.231          1     3\n4 -0.148  0.545          1     4\n5 -0.201  0.940          1     5\n6 -0.192  1.37           1     6\n\n\n\nlibrary(gganimate)\nanim_hmc &lt;- ggplot(tray_tbl |&gt; mutate(iter = 4*as.numeric(paso == 1), \n                          s = as.numeric(paso == 2)) |&gt; \n         filter(iteracion &lt; 30) |&gt; \n         mutate(tiempo = row_number()) |&gt; \n         mutate(tiempo = tiempo + cumsum(50 * s)), \n       aes(x = x, y = y)) + \n    geom_point(aes(colour = iter, alpha = iter, size = iter, group = tiempo)) +\n    geom_path(colour = \"gray\", alpha = 0.5) +\n  transition_reveal(tiempo) +\n  elipses_normal +\n  theme(legend.position = \"none\") \nanim_save(animation = anim_hmc, filename = \"figuras/hmc-normal.gif\", \n          renderer = gifski_renderer())\n\n\n\n\nHMC\n\n\nObservaciones:\n\nNótese que ahora podemos dar pasos más grandes a lo largo de los lugares donde concentra mayor probabilidad.\nEsto implica dos cosas: evitamos el comportamiento de caminata aleatoria (pasos muy cortos), y también tasas de rechazo alto (cuando los pasos son muy grandes en MH)\nEl algoritmo utiliza información adicional: además de calcular la posterior, como en metropolis, es necesario calcular también el gradiente de la posterior.\nEste algoritmo hace más trabajo para cada iteración (requiere la integración leapfrog), pero cada iteración es más informativa\nBien afinado, funciona para problemas de dimensión alta (cientos o miles de parámetros), donde geométricamente la densidad está concentrada en un espacio geométricamente chico. Existen todavía dificultades que discutiremos en otros modelos más adelante.\n\n\n\n\n\n\n\nTip\n\n\n\nObservamos que hasta ahora no hemos aplicado estos algoritmos para simular de la posterior de un modelo: hemos tomado distribuciones fijas y usamos MCMC para simular de ellas. El proceso para una posterior es el mismo, pero usualmente más complicado pues generalmente involucra mucho más parámetros y una posterior que no tiene una forma analítica conocida.\nSin embargo, la aplicación para una posterior es la misma: siempre podemos calcular el logaritmo de la posterior (al menos hasta una constante de proporcionalidad), y siempre podemos usar diferenciación automática para calcular el gradiente de la log posterior. Podemos aplicar entonces HMC o Metropolis.\n\n\n\n\nComparación de HMC y Metropolis\nFinalmente, haremos una comparación entre el desempeño de HMC y Metropolis en el caso de la distribución normal. Utilizaremos otra normal bivariada con más correlación.\n\nset.seed(737)\nSigma &lt;- matrix(c(1, -0.9, -0.9, 1), nrow = 2)\nm &lt;- c(1, 1)\nlog_p &lt;- construir_log_p(m, Sigma)\ngrad_log_p &lt;- construir_grad_log_p(m, Sigma)\nsystem.time(hmc_1 &lt;- hamilton_mc(1000, c(1,2), log_p, grad_log_p, 0.2, 12))\n\n[1] 0.042\n\n\n   user  system elapsed \n  0.062   0.001   0.063 \n\nsystem.time(metropolis_1 &lt;- metropolis_mc(1000, c(1,2), log_p, 0.2, 0.2))\n\n[1] 0.204\n\n\n   user  system elapsed \n  0.015   0.000   0.015 \n\nsystem.time(metropolis_2 &lt;- metropolis_mc(1000, c(1,2), log_p, 1, 1))\n\n[1] 0.692\n\n\n   user  system elapsed \n  0.015   0.000   0.016 \n\n\n\nsims_hmc &lt;- hmc_1$sims |&gt; mutate(n_sim = row_number()) |&gt; \n  mutate(algoritmo = \"hmc\")\nsims_metropolis_1 &lt;- metropolis_1 |&gt; \n  mutate(algoritmo = \"metropolis (corto)\") \nsims_metropolis_2 &lt;- metropolis_2 |&gt; \n  mutate(algoritmo = \"metropolis (largo)\") \nsims_comp &lt;- bind_rows(sims_hmc, sims_metropolis_1, sims_metropolis_2)\nanim_comp &lt;- ggplot(sims_comp |&gt; filter(n_sim &lt; 200)) + \n  transition_reveal(n_sim) +\n  theme(legend.position = \"none\") +\n  geom_path(aes(x, y), colour = \"gray\", alpha = 0.2) + \n    geom_point(aes(x, y, group = n_sim)) +\n  facet_wrap(~algoritmo)\nanim_save(animation = anim_comp, filename = \"figuras/comparacion-normal.gif\", height = 250, width = 500,\n          units = \"px\",\n          renderer = gifski_renderer())\n\n\n\n\nComparación\n\n\n\n\n\n\n\n\nComparaciones de eficiencia\n\n\n\nNótese que en general no tiene sentido comparar algoritmos usando el número de simulaciones que puede producir por unidad de tiempo. La comparación correcta involucra comparar cuánto tiempo requerimos para aproximar con cierto grado de precisión a la posterior (o más bien, resúmenes de la posterior). Algunos algoritmos son pueden ser rápidos porque producen rápidamente muchas simulaciones poco informativas, y otros son rápidos porque cada simulación que producen es muy informativa. Veremos más adelante el concepto de muestra efectiva.\n\n\n\n\nHMC en Stan\nEn Stan se incluyen tres componentes adicionales importantes para estimar posteriores de manera eficiente:\n\nPeriodos de warm-up (calentamiento) y sampling (muestreo). En el periodo de calentamiento, el muestreador afina tamaños de paso, escalamiento de la distribución de propuesta (normal multivariada), y otros parámetros de manera automática.\nImplementación de diferenciación automática para no tener que calcular el grandiente de la log posterior directamente. A partir del código que damos, se crean automáticamente funciones que calculan el grandiente (no es una aproximación numérica).\nImplementación de HMC sin vueltas en U (NUTS): una afinación adicional es dinámicamente adaptar el número de pasos de integración para evitar “regresos”, como vimos que sucedía en los ejemplos de arriba. Ver por ejemplo aquí, o la documentación de Stan.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#diagnósticos-de-convergencia",
    "href": "08-mcmc.html#diagnósticos-de-convergencia",
    "title": "8  Markov Chain Monte Carlo",
    "section": "8.3 Diagnósticos de convergencia",
    "text": "8.3 Diagnósticos de convergencia\nAunque casi nunca es posible demostrar rigurosamente que las simulaciones de un algoritmo MCMC dan buena aproximación de la distribución posterior de interés, especialmente con HMC y NUTS, tenemos muchos diagnósticos que fallan cuando existen problemas serios.\nEn primer lugar, será útil correr distintas cadenas con valores iniciales aleatorios diferentes, analizamos cada una y las comparamos entre sí. Recordamos que cada una de estas cadenas tiene como distribución estacionaria límite la distribución posterior. Diagnósticos que indican que las cadenas se comportan de manera muy distinta, explorando distintas regiones del espacio de parámetros, o que no han convergido porque exploran lentamente el espacio de parámetros, son señales de problemas.\nLos diagnósticos más comunes son:\n\nTraza de cadenas\nMedida R-hat de convergencia: mide la variabilidad entre cadenas y dentro de cadenas.\nNúmero de muestras efectivas (ESS) y autocorrelación.\nTransiciones divergentes.\n\n\nModelos con variables latentes\nVeremos el ejemplo de calificación de vinos de distintos países de McElreath (2020), sus diagnósticos, y aprovecharemos para introducir variables no observadas o latentes para enriquecer nuestras herramientas de modelación.\nNuestra pregunta general es si el país de origen de los vinos influye en su calidad. Los datos que tenemos son calificaciones de vinos de distintos países por distintos jueces. La calidad del vino no la observamos directamente, sino que es causa de las calificaciones que recibe. Para construir nuestro diagrama, las consideraciones básicas son:\n\nEl origen del vino es una causa del calidad del vino (es nuestra cantidad a estimar).\nLos jueces tienen distintas maneras de calificar, de manera que son causa de variación en las calificaciones (hay jueces más duros, otros más barcos, etc.) No observamos directamente que tan “duro” es cada juez.\nLos jueces califican vinos de distintos países de manera ciega. Sin embargo es posible que reconozcan el país de origen por las características de los vinos, de manera que puede existir un efecto directo de Origen en Calificación (no pasa por Calidad).\nEs posible que Jueces de distintos países tienen distintos estándares de calificación.\n\n\n\nCódigo\nlibrary(DiagrammeR)\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir = LR]\n  node [shape=plaintext]\n    Origen\n    Score\n    Origen_Juez\n  node [shape = circle]\n    Q\n    J\n  edge [minlen = 3]\n    Origen -&gt; Q\n    Origen -&gt; Score\n    Q -&gt; Score\n    J -&gt; Score\n    Origen_Juez -&gt; J\n}\n\")\n\n\n\n\n\n\nY vemos, por nuestro análisis del DAG, que podemos identificar el efecto de Origen sobre Calidad sin necesidad de estratificar por ninguna variable (no hay puertas traseras). Sin embaergo, podemos estratificar por Juez para obtener más precisión (ver sección anterior de buenos y malos controles).\n\n8.3.0.1 Primera iteración: modelo simple\nComenzamos con un modelo simple, y lo iremos construyendo para obtener la mejor estimación posible de la influencia del país de origen en la calidad del vino. Nuestro primer modelo consideramos que la calificación de cada vino depende de su calidad, y modelamos con una normal:\n\\[S_i \\sim \\text{Normal}(\\mu_i, \\sigma)\\] donde \\[\\mu_i = Q_{vino(i)}\\]. Nuestra medida de calidad tiene escala arbitaria. Como usaremos la calificación estandarizada, podemos poner \\[Q_j \\sim \\text{Normal}(0, 1).\\] finalmente, ponemos una inicial para \\(\\sigma\\), por ejemplo \\(\\sigma \\sim \\text{Exponential}(1)\\) (puedes experimentar con una normal truncada también)\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\nmod_vinos_1 &lt;- cmdstan_model(\"./src/vinos-1.stan\")\nprint(mod_vinos_1)\n\ndata {\n  int&lt;lower=0&gt; N; //número de calificaciones\n  int&lt;lower=0&gt; n_vinos; //número de vinos\n  int&lt;lower=0&gt; n_jueces; //número de jueces\n  vector[N]  S;\n  array[N]  int juez;\n  array[N]  int vino;\n}\n\nparameters {\n  vector[n_vinos] Q;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] media_score;\n  // determinístico dado parámetros\n  for (i in 1:N){\n    media_score[i] = Q[vino[i]];\n  }\n}\n\nmodel {\n  // partes no determinísticas\n  S ~ normal(media_score, sigma);\n  Q ~ std_normal();\n  sigma ~ exponential(1);\n}\n\n\n\n# Wines 2022 de Statistical Rethinking\nwines_2012 &lt;- read_csv(\"../datos/wines_2012.csv\")\n\nRows: 180 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): judge, flight, wine\ndbl (3): score, wine.amer, judge.amer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(wines_2012)\n\nRows: 180\nColumns: 6\n$ judge      &lt;chr&gt; \"Jean-M Cardebat\", \"Jean-M Cardebat\", \"Jean-M Cardebat\", \"J…\n$ flight     &lt;chr&gt; \"white\", \"white\", \"white\", \"white\", \"white\", \"white\", \"whit…\n$ wine       &lt;chr&gt; \"A1\", \"B1\", \"C1\", \"D1\", \"E1\", \"F1\", \"G1\", \"H1\", \"I1\", \"J1\",…\n$ score      &lt;dbl&gt; 10.0, 13.0, 14.0, 15.0, 8.0, 13.0, 15.0, 11.0, 9.0, 12.0, 1…\n$ wine.amer  &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,…\n$ judge.amer &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n\nwines_2012 &lt;- wines_2012 |&gt; \n  mutate(juez_num = as.numeric(factor(judge)),\n         vino_num = as.numeric(factor(wine))) |&gt; \n  mutate(score_est = (score - mean(score))/sd(score))\n\n\nn_jueces &lt;- length(unique(wines_2012$juez_num))\nn_vinos &lt;- length(unique(wines_2012$vino_num))\nc(\"num_vinos\" = n_jueces, \"num_jueces\" = n_vinos, \"num_datos\" = nrow(wines_2012))\n\n num_vinos num_jueces  num_datos \n         9         20        180 \n\n\n\ndatos_lst &lt;- list(\n  N = nrow(wines_2012),\n  n_vinos = n_vinos,\n  n_jueces = n_jueces,\n  S = wines_2012$score_est,\n  vino = wines_2012$vino_num,\n  juez = wines_2012$juez_num\n)\najuste_vinos_1 &lt;- mod_vinos_1$sample(\n  data = datos_lst,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000,\n  refresh = 1000,\n  step_size = 0.1,\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 1 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 2 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 3 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 4 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 2 finished in 0.4 seconds.\nChain 3 finished in 0.3 seconds.\nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 0.6 seconds.\n\n\nVemos que hay variabilidad en los vinos:\n\najuste_vinos_1$summary(c(\"Q\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, ess_bulk, ess_tail) |&gt; \n  filter(variable != \"lp__\") |&gt;\n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) |&gt; \n  kable()\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nQ[1]\n0.139\n0.320\n-0.382\n0.662\n1.000\n17902.83\n5855.730\n\n\nQ[2]\n0.102\n0.319\n-0.426\n0.619\n1.001\n21604.99\n5800.131\n\n\nQ[3]\n0.270\n0.311\n-0.235\n0.776\n1.000\n19573.56\n6007.763\n\n\nQ[4]\n0.552\n0.320\n0.028\n1.071\n1.001\n17416.81\n5796.906\n\n\nQ[5]\n-0.123\n0.315\n-0.641\n0.384\n1.000\n16630.99\n5928.784\n\n\nQ[6]\n-0.365\n0.318\n-0.893\n0.167\n1.001\n19249.44\n6280.410\n\n\nQ[7]\n0.291\n0.310\n-0.216\n0.799\n1.002\n17612.31\n5819.676\n\n\nQ[8]\n0.272\n0.316\n-0.244\n0.790\n1.001\n19262.19\n5803.780\n\n\nQ[9]\n0.079\n0.323\n-0.453\n0.610\n1.002\n17524.38\n5548.291\n\n\nQ[10]\n0.120\n0.320\n-0.414\n0.644\n1.000\n18782.27\n5822.424\n\n\nQ[11]\n-0.008\n0.313\n-0.514\n0.511\n1.000\n18564.38\n5446.550\n\n\nQ[12]\n-0.029\n0.319\n-0.549\n0.489\n1.000\n17498.02\n6069.144\n\n\nQ[13]\n-0.102\n0.317\n-0.627\n0.418\n1.001\n16981.20\n6315.917\n\n\nQ[14]\n0.005\n0.319\n-0.522\n0.527\n1.000\n18420.52\n5600.778\n\n\nQ[15]\n-0.220\n0.315\n-0.736\n0.296\n1.000\n17599.63\n5609.862\n\n\nQ[16]\n-0.196\n0.320\n-0.726\n0.337\n1.001\n19785.29\n5920.591\n\n\nQ[17]\n-0.143\n0.318\n-0.668\n0.380\n1.001\n17013.66\n5337.378\n\n\nQ[18]\n-0.854\n0.323\n-1.382\n-0.323\n1.001\n17794.77\n5844.933\n\n\nQ[19]\n-0.161\n0.315\n-0.678\n0.349\n1.000\n19621.52\n6297.323\n\n\nQ[20]\n0.382\n0.321\n-0.140\n0.896\n1.001\n17177.78\n5375.556\n\n\nsigma\n0.997\n0.054\n0.912\n1.090\n1.000\n12573.39\n6491.467\n\n\n\n\n\n\n\n\n8.3.1 Diagnóstico: Trazas de cadenas\nPara hacer diagnósticos, podemos comenzar con las trazas de una cadena para todas las estimaciones de calidad de vino. Cada cadena se inicia con distintos valores aleatorios, pero cumplen en teoría que su distribución de equilibrio es la posterior de interés pues sus transiciones usan el mismo mecanismo.\n\nlibrary(bayesplot)\nmcmc_trace(ajuste_vinos_1$draws(\"Q\", format = \"df\") |&gt; filter(.chain == 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nLa traza de una cadena es la gráfica de las simulaciones de cada parámetro. Generalmente buscamos que: no tenga tendencia, que no se quede “atorada” en algunos valores, y que no muestre oscilaciones de baja frecuencia (la cadena “vaga” por los valores que explora).\n\n\nSi incluímos todas las cadenas, nos fijemos en que todas ellas exploren regiones similares del espacio de parámetros:\n\ncolor_scheme_set(\"viridis\")\nmcmc_trace(ajuste_vinos_1$draws(\"Q\", format = \"df\")) \n\n\n\n\n\n\n\n\nLo que no queremos ver es lo siguiente, por ejemplo:\n\najuste_vinos_malo &lt;- mod_vinos_1$sample(\n  data = datos_lst,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 5,\n  iter_sampling = 100,\n  refresh = 1000,\n  step_size =1 ,\n  seed = 123\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 WARNING: No variance estimation is \nChain 1          performed for num_warmup &lt; 20 \nChain 1 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 1 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 1 Iteration: 105 / 105 [100%]  (Sampling) \nChain 2 WARNING: No variance estimation is \nChain 2          performed for num_warmup &lt; 20 \nChain 2 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 2 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 2 Iteration: 105 / 105 [100%]  (Sampling) \nChain 3 WARNING: No variance estimation is \nChain 3          performed for num_warmup &lt; 20 \nChain 3 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 3 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 3 Iteration: 105 / 105 [100%]  (Sampling) \nChain 4 WARNING: No variance estimation is \nChain 4          performed for num_warmup &lt; 20 \nChain 4 Iteration:   1 / 105 [  0%]  (Warmup) \nChain 4 Iteration:   6 / 105 [  5%]  (Sampling) \nChain 4 Iteration: 105 / 105 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n\n\nWarning: 192 of 400 (48.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 1 of 4 chains had an E-BFMI less than 0.3.\nSee https://mc-stan.org/misc/warnings for details.\n\n\n\ncolor_scheme_set(\"viridisA\")\nmcmc_trace(ajuste_vinos_malo$draws(\"Q\", format = \"df\")) \n\n\n\n\n\n\n\n\nHay varios problemas graves:\n\nAlgunas cadenas parecen “atoradas” en ciertos valores\nAlgunas cadenas parecen caminatas aleatorias (oscilaciones de baja frecuencia)\nLas cadenas no exploran de manera similar el espacio de parámetros\n\n\n\n\n\n\n\nTraza de cadenas\n\n\n\nEl diagnóstico de traza consiste en graficar las cadenas de los parámetros en el orden de la iteración. Buscamos ver que:\n\nLas cadenas no tienen tendencia o oscilaciones de frecuencia muy baja.\nLas cadenas no se atoran en valores específicos.\nLas distintas cadenas exploran de manera similar el espacio de parámetros.\n\nCuando falla alguna de estas, en el mejor de los casos las cadenas son ineficientes (veremos que requerimos un número mucho mayor de iteraciones), y en el peor de los casos dan resultados sesgados que no son confiables.\n\n\n\n\n8.3.2 Diagnóstico: valores R-hat\nCuando nuestro método de simulación converge a la distribución posterior, esperamos que las cadenas, durante todo su proceso, exploran la misma región del espacio de parámetros.\nPodemos entonces considerar, para cada parámetro:\n\nCuánta variación hay en cada cadena.\nQué tan distintas son las cadenas entre ellas.\n\nEsperamos que la variación entre cadenas es chica, y la variación dentro de cada cadena es similar para todas las cadenas. Calculamos entonces un cociente de varianzas: la varianza total sobre todas las simulaciones de todas las cadenas, y el promedio de varianzas de las cadenas. Si las cadenas están explorando regiones similares, esperamos que este cociente de varianzas sea cercano a 1.\nEscribiremos ahora esta idea para entender cómo se calculan estas cantidades. Supongamos que cada cadena se denota por \\(\\theta_m\\), para \\(M\\) cadenas, y las iteraciones de cada cadena son \\(\\theta_m^{(i)}\\) para \\(i=1,\\ldots, N\\) iteraciones. Definimos (ver el manual de Stan o Brooks et al. (2011) por ejemplo) primero la varianza entre cadenas, que es (ojo: usaremos definiciones aproximadas para entender más fácilmente):\n\\[b=\\frac{1}{M-1}\\sum_{m=1}^M (\\bar{\\theta}_m - \\bar{\\theta})^2\\] donde \\(\\bar{\\theta}_m\\) es el promedio de las iteraciones de la cadena \\(m\\), y \\(\\bar{\\theta}\\) es el promedio del las \\(\\bar{\\theta}_m\\).\nDefinimos también la varianza dentro de las cadenas, que es el promedio de la varianza de cada cadena:\n\\[w=\\frac{1}{M}\\sum_{m=1}^M \\frac{1}{N}\\sum_{i=1}^N (\\theta_m^{(i)} - \\bar{\\theta}_m)^2\\] Finalmente, la \\(R\\)-hat, o estadística de potencial de reducción de escala, es (para \\(N\\) grande),\n\\[\\hat{R} = \\sqrt{\\frac{b+w}{w}}\\]\nBuscamos entonces que este valor sea cercano a 1. Si es mayor a 1.05, es señal de posibles problemas de convergencia (pocas iteraciones u otras fallas en la convergencia). Si es menor que 1.01, generalmente decimos que “pasamos” esta prueba. Esto no es garantía de que la convergencia se ha alcanzado: la primera razón es que este diagnóstico, por ejemplo, sólo considera media y varianza, de forma que en principio podríamos pasar esta prueba aún cuando las cadenas tengan comportamiento distinto en otras estadísticas de orden más alto (por ejemplo, una cadena que oscila poco y de vez en cuando salta a un atípico vs otra que tiene variación moderada pueden ser similares en medias y varianzas).\nEn Stan, adicionalmente, se divide cada cadena en dos mitades, y el análisis se hace sobre \\(2M\\) medias cadenas. Esto ayuda a detectar por ejemplo problemas donde una cadena sube y luego baja, por ejemplo, de modo que puede tener el mismo promedio que otras que exploran correctamente.\nNota: Estas fórmulas pretenden explicar de manera simple el concepto de \\(R\\)-hat, y son correctas para \\(N\\) grande, lo cual casi siempre es el caso (al menos \\(N\\geq 100\\)). Puedes consultar una definición más estándar con correcciones por grados de libertad en el manual de Stan o cualquier libro de MCMC.\n\n\n\n\n\n\nDiagnóstico de R-hat\n\n\n\nEl diagnóstico de R-hat compara la varianza dentro de las cadenas y de cadena a cadena. Cuando este valor es relativamente grande (por ejemplo mayor a 1.05), es señal de que las cadenas no han explorado apropiadamente el espacio de parámetros (o decimos que no están “mezclando”). En general, buscamos que este valor sea menor a 1.02.\nSe llama también potencial de reducción a escala porque busca indicar cuánto se podría reducir la varianza de la distribución actual si dejáramos correr las cadenas por más iteraciones (pues a largo plazo no debe haber varianza entre cadenas).\n\n\nEn nuestro ejemplo apropiado, observamos valores muy cercanos a 1 para todos los parámetros:\n\najuste_vinos_1$summary(c(\"Q\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, ess_bulk, ess_tail) |&gt; \n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nQ[1]\n0.139\n0.320\n-0.382\n0.662\n1.000\n17902.83\n5855.730\n\n\nQ[2]\n0.102\n0.319\n-0.426\n0.619\n1.001\n21604.99\n5800.131\n\n\nQ[3]\n0.270\n0.311\n-0.235\n0.776\n1.000\n19573.56\n6007.763\n\n\nQ[4]\n0.552\n0.320\n0.028\n1.071\n1.001\n17416.81\n5796.906\n\n\nQ[5]\n-0.123\n0.315\n-0.641\n0.384\n1.000\n16630.99\n5928.784\n\n\nQ[6]\n-0.365\n0.318\n-0.893\n0.167\n1.001\n19249.44\n6280.410\n\n\nQ[7]\n0.291\n0.310\n-0.216\n0.799\n1.002\n17612.31\n5819.676\n\n\nQ[8]\n0.272\n0.316\n-0.244\n0.790\n1.001\n19262.19\n5803.780\n\n\nQ[9]\n0.079\n0.323\n-0.453\n0.610\n1.002\n17524.38\n5548.291\n\n\nQ[10]\n0.120\n0.320\n-0.414\n0.644\n1.000\n18782.27\n5822.424\n\n\nQ[11]\n-0.008\n0.313\n-0.514\n0.511\n1.000\n18564.38\n5446.550\n\n\nQ[12]\n-0.029\n0.319\n-0.549\n0.489\n1.000\n17498.02\n6069.144\n\n\nQ[13]\n-0.102\n0.317\n-0.627\n0.418\n1.001\n16981.20\n6315.917\n\n\nQ[14]\n0.005\n0.319\n-0.522\n0.527\n1.000\n18420.52\n5600.778\n\n\nQ[15]\n-0.220\n0.315\n-0.736\n0.296\n1.000\n17599.63\n5609.862\n\n\nQ[16]\n-0.196\n0.320\n-0.726\n0.337\n1.001\n19785.29\n5920.591\n\n\nQ[17]\n-0.143\n0.318\n-0.668\n0.380\n1.001\n17013.66\n5337.378\n\n\nQ[18]\n-0.854\n0.323\n-1.382\n-0.323\n1.001\n17794.77\n5844.933\n\n\nQ[19]\n-0.161\n0.315\n-0.678\n0.349\n1.000\n19621.52\n6297.323\n\n\nQ[20]\n0.382\n0.321\n-0.140\n0.896\n1.001\n17177.78\n5375.556\n\n\nsigma\n0.997\n0.054\n0.912\n1.090\n1.000\n12573.39\n6491.467\n\n\n\n\n\nEn nuestro ejemplo “malo”, obtenemos valores no aceptabels de R-hat para varios parámetros.\n\najuste_vinos_malo$summary(c(\"Q\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, ess_bulk, ess_tail) |&gt; \n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nQ[1]\n0.422\n0.482\n-0.294\n1.133\n1.685\n7.476\n133.368\n\n\nQ[2]\n-0.058\n0.290\n-0.402\n0.515\n1.536\n13.999\n285.888\n\n\nQ[3]\n0.326\n0.251\n-0.090\n0.770\n1.510\n40.498\n63.350\n\n\nQ[4]\n0.542\n0.431\n-0.174\n1.008\n1.564\n7.513\n8.439\n\n\nQ[5]\n-0.109\n0.273\n-0.495\n0.333\n1.216\n14.860\n219.484\n\n\nQ[6]\n-0.184\n0.353\n-0.780\n0.392\n1.640\n9.583\n28.087\n\n\nQ[7]\n0.499\n0.397\n-0.122\n1.004\n1.511\n7.971\n166.596\n\n\nQ[8]\n0.113\n0.469\n-0.560\n0.699\n1.773\n6.431\n4.348\n\n\nQ[9]\n0.408\n0.519\n-0.375\n1.366\n1.814\n6.312\n21.334\n\n\nQ[10]\n-0.056\n0.307\n-0.535\n0.444\n1.523\n11.471\n47.242\n\n\nQ[11]\n-0.190\n0.406\n-0.773\n0.332\n1.438\n8.605\n4.671\n\n\nQ[12]\n-0.342\n0.398\n-0.818\n0.299\n1.729\n6.610\n4.451\n\n\nQ[13]\n0.034\n0.374\n-0.580\n0.504\n1.375\n9.672\n218.063\n\n\nQ[14]\n0.023\n0.405\n-0.654\n0.458\n1.615\n7.154\n8.985\n\n\nQ[15]\n-0.135\n0.756\n-1.443\n0.886\n2.478\n5.211\n7.577\n\n\nQ[16]\n-0.256\n0.246\n-0.692\n0.168\n1.777\n21.764\n91.263\n\n\nQ[17]\n-0.238\n0.608\n-1.051\n0.687\n1.978\n5.952\n4.451\n\n\nQ[18]\n-0.366\n0.631\n-1.291\n0.717\n2.187\n5.540\nNA\n\n\nQ[19]\n-0.106\n0.267\n-0.563\n0.231\n1.469\n19.815\n157.400\n\n\nQ[20]\n0.502\n0.530\n-0.354\n1.220\n2.117\n5.636\n7.866\n\n\nsigma\n1.019\n0.141\n0.918\n1.414\n1.535\n7.852\nNA\n\n\n\n\n\nNota: si algunos parámetros tienen valores R-hat cercanos a 1 pero otros no, en general no podemos confiar en los resultados de las simulaciones. Esto es señal de problemas de convergencia y deben ser diagnosticados.\n\n\n8.3.3 Diagnóstico: Tamaño de muestra efectivo\nLas simulaciones de MCMC típicamente están autocorrelacionadas (pues comenzamos en una región y muchas veces nos movemos poco). Esto significa que la cantidad de información de \\(N\\) simulaciones MCMC no es la misma que la que obtendríamos con \\(N\\) simulaciones independientes de la posterior.\nEste concepto también se usa en muestreo: por ejemplo, existe menos información en una muestra de 100 personas que fueron muestreadas por conglomerados de 50 casas (por ejemplo, seleccionando al azar hogares y luego a dos adultos dentro de cada hogar) que seleccionar 100 hogares y escoger a un al azar un adulto de cada hogar. La segunda muestra tienen más información de la población, pues en la primera muestra parte de la información es “compartida” por el hecho de vivir en el mismo hogar. Para encontrar un número “efectivo” de muestra que haga comparables estos dos diseños, comparamos la varianza que obtendríamos del estimador de interes en cada caso. Si consideramos como base el segundo diseño (muestro aleatorio independiente), el primer diseño tendrá más varianza. Eso quiere decir que para que hubiera la misma varianza en los dos diseños, bastaría una muestra más chica (digamos 60 hogares) del segundo diseño independiente. Decimos que el tamaño efectivo de muestra del primer diseño es de 60 personas (el caso donde las varianzas de los dos diseños son iguales).\nEn el caso de series de tiempo, tenemos que considerar autocorrelación en la serie. Supongamos que quisiéramos estimar la media de una serie de tiempo (suponemos que a largo plazo el promedio de la serie de tiempo es una constante finita). Una muestra con autocorrelación alta produce malos estimadores de esta media incluso para tamaños de muestra relativamente grande:\n\nset.seed(123)\nmu_verdadera &lt;- 10\nsimular_series &lt;- function(T = 500, num_series = 100, ar = 0.9){\n  map_df(1:num_series, function(rep){\n    serie &lt;- 10 + arima.sim(n = T, list(ar = ar), n.start = 200, sd = sqrt(1-ar^2))\n    tibble(t = 1:T, serie = serie, serie_id = rep, ar = ar)\n  })\n}\nseries_1_tbl &lt;- simular_series(T= 200, n = 4, ar = 0.80)\nseries_2_tbl &lt;- simular_series(T= 200, n = 4, ar = 0.00001)\nseries_tbl &lt;- bind_rows(series_1_tbl, series_2_tbl)\nseries_tbl |&gt; \n  ggplot(aes(t, serie, group = serie_id, colour = factor(serie_id))) + \n  geom_line(alpha = 0.9) + \n  geom_hline(yintercept = mu_verdadera, linetype = 2) + \n  facet_wrap(~ar, ncol = 1)\n\n\n\n\n\n\n\n\nCalculamos las medias para un ejemplo con autocorrelación y otro sin ellas:\n\nseries_95_tbl &lt;- simular_series(T= 300, n = 500, ar = 0.80) \nseries_05_tbl &lt;- simular_series(T= 300, n = 500, ar = 0.00001) \nseries_tbl &lt;- bind_rows(series_95_tbl, series_05_tbl)\nseries_tbl |&gt; group_by(serie_id, ar) |&gt; \n  summarise(media = mean(serie)) |&gt; \n  ggplot(aes(media)) + geom_histogram() + \n  geom_vline(xintercept = mu_verdadera, linetype = 2) + \n  labs(title = \"Distribución de medias de series de tiempo\") +\n  facet_wrap(~ar)\n\n`summarise()` has grouped output by 'serie_id'. You can override using the\n`.groups` argument.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nY vemos que la precisión de la estimación cuando la correlación es relativamente baja es mucho más alta que cuando la correlación es alta. ¿Cuál es el tamaño efectivo de muestra para series con autocorrelación ar= 0.8? Vemos que es aproximadamente 35, o dicho de otra manera, la serie sin correlación nos da casi 10 veces más información por observación que la correlacionada:\n\nseries_95_tbl &lt;- simular_series(T= 300, n = 1000, ar = 0.8) \nseries_05_tbl &lt;- simular_series(T= 35, n = 1000, ar = 0.00001) \nseries_tbl &lt;- bind_rows(series_95_tbl, series_05_tbl)\nseries_tbl |&gt; group_by(serie_id, ar) |&gt; \n  summarise(media = mean(serie)) |&gt; \n  ggplot(aes(media)) + geom_histogram() + \n  geom_vline(xintercept = mu_verdadera, linetype = 2) + \n  labs(title = \"Distribución de medias de series de tiempo\") +\n  facet_wrap(~ar)\n\n`summarise()` has grouped output by 'serie_id'. You can override using the\n`.groups` argument.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nEs posible hacer una estimación teórica del tamaño efectivo de muestra. Para esto, podemos notar que la varianza del promedio de una serie de tiempo depende de la estructura de autocorrelación. Supondremos que la serie de tiempo es estacionaria y cada \\(y_t\\) tiene varianza \\(\\sigma^2\\) y correlación \\(\\rho\\) con \\(y_{t-1}\\). Entonces:\n\\[Var(\\bar{y})=\\frac{1}{n^2}\\text{Var} \\left(\\sum_{t=1}^n y_t \\right) =\n\\frac{n\\sigma^2}{n^2}\\sum_{t=1}^n \\text{Var}(y_t) + \\frac{2\\sigma^2}{n^2}\\sum_{t=1}^{n-1}\\sum_{s=t+1}^n\\text{Corr}(y_t, y_s)\\]\nQue se simplifica a (para \\(n\\) grande):\n\\[\\text{Var}(\\bar{y}) = \\frac{\\sigma^2}{n} + \\frac{2\\sigma^2}{n}\\sum_{h=1}^{n-1}(1-h/n)\\rho_{h} \\approx \\frac{\\sigma^2}{n}\\left (1+2\\sum_{h=1}^{n-1}\\rho_t\\right )\\] Si suponemos \\(\\rho_h = \\text{corr}(y_t, y_{t+h})\\) para cualquier \\(t\\). En nuestro caso anterior, el factor de corrección es aproximadamente:\n\n1 + 2*(0.8)^(1:1000) |&gt; sum()\n\n[1] 9\n\n\n\n\n\n\n\n\nTamaño efectivo de muestra\n\n\n\nSi hacemos \\(N\\) iteraciones en una cadena estacionaria con función de autocorrelación \\(\\rho_h\\), el tamaño efectivo de muestra teórico se define como\n\\[N_{eff} = \\frac{N}{1 + 2\\sum_{h=1}^{\\infty}\\rho_h}\\]\nSi pudiéramos hacer simulaciones independientes de la posterior, \\(N_{eff}\\) es el tamaño de muestra requerido para obtener la misma información que la cadena autocorrelacionada de tamaño \\(N\\). Usualmente, aunque no siempre, \\(N_{eff}&lt;N\\) para cadenas de MCMC.\n\n\nObservaciones:\n\nEsta es una definición teórica para entender el concepto. Para ver cómo se estima en la práctica puedes consultar el manual de Stan o (Brooks et al. 2011).\nEn algunos muestreadores que dan pasos cortos como en los ejemplos de Metropolis-Hastings que vimos, a veces es necesario hacer cientos de miles de iteraciones para obtener un tamaño efectivo de muestra apropiado para hacer inferencia. Stan generalmente obtiene tamaños efectivos de muestra mucho más altos con menos iteraciones (aunque cada iteración es más costosa).\nConsiderando experiencia y teoría, tamaños efectivos de muestra mínimos se considera de 400 o más (ver aquí).\n\nEn nuestro ejemplo, tenemos tamaños de muestra efectivos satisfactorios:\n\najuste_vinos_1$summary(c(\"Q\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, contains(\"ess\")) |&gt; \n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nQ[1]\n0.139\n0.320\n-0.382\n0.662\n1.000\n17902.83\n5855.730\n\n\nQ[2]\n0.102\n0.319\n-0.426\n0.619\n1.001\n21604.99\n5800.131\n\n\nQ[3]\n0.270\n0.311\n-0.235\n0.776\n1.000\n19573.56\n6007.763\n\n\nQ[4]\n0.552\n0.320\n0.028\n1.071\n1.001\n17416.81\n5796.906\n\n\nQ[5]\n-0.123\n0.315\n-0.641\n0.384\n1.000\n16630.99\n5928.784\n\n\nQ[6]\n-0.365\n0.318\n-0.893\n0.167\n1.001\n19249.44\n6280.410\n\n\nQ[7]\n0.291\n0.310\n-0.216\n0.799\n1.002\n17612.31\n5819.676\n\n\nQ[8]\n0.272\n0.316\n-0.244\n0.790\n1.001\n19262.19\n5803.780\n\n\nQ[9]\n0.079\n0.323\n-0.453\n0.610\n1.002\n17524.38\n5548.291\n\n\nQ[10]\n0.120\n0.320\n-0.414\n0.644\n1.000\n18782.27\n5822.424\n\n\nQ[11]\n-0.008\n0.313\n-0.514\n0.511\n1.000\n18564.38\n5446.550\n\n\nQ[12]\n-0.029\n0.319\n-0.549\n0.489\n1.000\n17498.02\n6069.144\n\n\nQ[13]\n-0.102\n0.317\n-0.627\n0.418\n1.001\n16981.20\n6315.917\n\n\nQ[14]\n0.005\n0.319\n-0.522\n0.527\n1.000\n18420.52\n5600.778\n\n\nQ[15]\n-0.220\n0.315\n-0.736\n0.296\n1.000\n17599.63\n5609.862\n\n\nQ[16]\n-0.196\n0.320\n-0.726\n0.337\n1.001\n19785.29\n5920.591\n\n\nQ[17]\n-0.143\n0.318\n-0.668\n0.380\n1.001\n17013.66\n5337.378\n\n\nQ[18]\n-0.854\n0.323\n-1.382\n-0.323\n1.001\n17794.77\n5844.933\n\n\nQ[19]\n-0.161\n0.315\n-0.678\n0.349\n1.000\n19621.52\n6297.323\n\n\nQ[20]\n0.382\n0.321\n-0.140\n0.896\n1.001\n17177.78\n5375.556\n\n\nsigma\n0.997\n0.054\n0.912\n1.090\n1.000\n12573.39\n6491.467\n\n\n\n\n\n\nNótese que versiones más recientes de Stan reportan dos tamaños efectivos de muestra (ESS), uno para cantidades que dependen del centro de la distribución, como la media y mediana (bulk ESS, que es similar a la definición que vimos arriba, pero usando valores normalizados por rango), y otro para cantidades que dependen de las colas, como percentiles extremos (tail ESS, que estima el tamaño de muestra efectivo para los percentiles 5% y 95% ). En este caso, ambos son altos.\n\nFinalmente, podemos checar el error montecarlo, que es error de estimación usual (por ejemplo, para la estimación de la media de los parámetros según las cadenas):\n\najuste_vinos_1$summary(c(\"Q\", \"sigma\"), \"mean\", \"rhat\", \"ess_bulk\", \"mcse_mean\") |&gt; \n  select(variable, mean,  rhat, contains(\"ess\"), mcse_mean) |&gt;\n  mutate(across(c(mean, rhat, ess_bulk, mcse_mean), ~round(., 3))) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\nvariable\nmean\nrhat\ness_bulk\nmcse_mean\n\n\n\n\nQ[1]\n0.139\n1.000\n17902.83\n0.002\n\n\nQ[2]\n0.102\n1.001\n21604.99\n0.002\n\n\nQ[3]\n0.270\n1.000\n19573.56\n0.002\n\n\nQ[4]\n0.552\n1.001\n17416.81\n0.002\n\n\nQ[5]\n-0.123\n1.000\n16630.99\n0.002\n\n\nQ[6]\n-0.365\n1.001\n19249.44\n0.002\n\n\nQ[7]\n0.291\n1.002\n17612.31\n0.002\n\n\nQ[8]\n0.272\n1.001\n19262.19\n0.002\n\n\nQ[9]\n0.079\n1.002\n17524.38\n0.002\n\n\nQ[10]\n0.120\n1.000\n18782.27\n0.002\n\n\nQ[11]\n-0.008\n1.000\n18564.38\n0.002\n\n\nQ[12]\n-0.029\n1.000\n17498.02\n0.002\n\n\nQ[13]\n-0.102\n1.001\n16981.20\n0.002\n\n\nQ[14]\n0.005\n1.000\n18420.52\n0.002\n\n\nQ[15]\n-0.220\n1.000\n17599.63\n0.002\n\n\nQ[16]\n-0.196\n1.001\n19785.29\n0.002\n\n\nQ[17]\n-0.143\n1.001\n17013.66\n0.002\n\n\nQ[18]\n-0.854\n1.001\n17794.77\n0.002\n\n\nQ[19]\n-0.161\n1.000\n19621.52\n0.002\n\n\nQ[20]\n0.382\n1.001\n17177.78\n0.002\n\n\nsigma\n0.997\n1.000\n12573.39\n0.000",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#extendiendo-el-modelo-de-variable-latente",
    "href": "08-mcmc.html#extendiendo-el-modelo-de-variable-latente",
    "title": "8  Markov Chain Monte Carlo",
    "section": "8.4 Extendiendo el modelo de variable latente",
    "text": "8.4 Extendiendo el modelo de variable latente\nAhora continuamos con nuestro modelo de calidad de vinos. Incluímos el origen del vino (que tiene dos niveles). La idea es que el origen, si vemos en el diagrama original, puede ser una variable de confusión entre calidad y score (pues afecta a calidad y también potencialmente al score). Adicionalmente, el origen no tiene puerta trasera, así que podemos examinar su efecto total sobre el score de los vinos. Estratificamos de la manera más simple, incluyendo origen en nuestra regresión:\n\nwines_2012 &lt;- wines_2012 |&gt; mutate(origen_num = ifelse(wine.amer == 1, 1, 2))\nwines_2012 |&gt; select(wine.amer, origen_num) |&gt; unique()\n\n# A tibble: 2 × 2\n  wine.amer origen_num\n      &lt;dbl&gt;      &lt;dbl&gt;\n1         1          1\n2         0          2\n\nn_jueces &lt;- length(unique(wines_2012$juez_num))\nn_vinos &lt;- length(unique(wines_2012$vino_num))\nn_origen &lt;- length(unique(wines_2012$origen_num))\nc(\"num_vinos\" = n_vinos, \"num_jueces\" = n_jueces, \"num_datos\" = nrow(wines_2012))\n\n num_vinos num_jueces  num_datos \n        20          9        180 \n\n\n\nmod_vinos_2 &lt;-cmdstan_model(\"./src/vinos-2.stan\")\nprint(mod_vinos_2)\n\ndata {\n  int&lt;lower=0&gt; N; //número de calificaciones\n  int&lt;lower=0&gt; n_vinos; //número de vinos\n  int&lt;lower=0&gt; n_jueces; //número de jueces\n  int&lt;lower=0&gt; n_origen; //número de jueces\n  vector[N]  S;\n  array[N]  int juez;\n  array[N]  int vino;\n  array[N]  int origen;\n}\n\nparameters {\n  vector[n_vinos] Q;\n  vector[n_origen] O;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] media_score;\n  // determinístico dado parámetros\n  for (i in 1:N){\n    media_score[i] = Q[vino[i]] + O[origen[i]];\n  }\n}\n\nmodel {\n  // partes no determinísticas\n  S ~ normal(media_score, sigma);\n  Q ~ std_normal();\n  O ~ std_normal();\n  sigma ~ exponential(1);\n}\n\ngenerated quantities {\n  real dif_origen;\n  dif_origen = O[1] - O[2];\n}\n\n\n\ndatos_lst &lt;- list(\n  N = nrow(wines_2012),\n  n_vinos = n_vinos,\n  n_jueces = n_jueces,\n  n_origen = n_origen,\n  S = wines_2012$score_est,\n  vino = wines_2012$vino_num,\n  juez = wines_2012$juez_num,\n  origen = wines_2012$origen_num\n)\najuste_vinos_2 &lt;- mod_vinos_2$sample(\n  data = datos_lst,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000,\n  refresh = 1000,\n  step_size = 0.1,\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 1 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 2 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 3 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 4 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 0.6 seconds.\nChain 2 finished in 0.6 seconds.\nChain 3 finished in 0.6 seconds.\nChain 4 finished in 0.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.6 seconds.\nTotal execution time: 0.7 seconds.\n\n\n\najuste_vinos_2$summary(c(\"O\", \"Q\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, contains(\"ess\")) |&gt;\n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nO[1]\n-0.049\n0.295\n-0.538\n0.437\n1.002\n1647.493\n3056.525\n\n\nO[2]\n0.104\n0.351\n-0.467\n0.684\n1.001\n1798.603\n3152.938\n\n\nQ[1]\n0.186\n0.412\n-0.491\n0.870\n1.001\n3005.104\n4635.313\n\n\nQ[2]\n0.013\n0.443\n-0.714\n0.746\n1.000\n2830.536\n4331.506\n\n\nQ[3]\n0.310\n0.412\n-0.373\n0.994\n1.001\n3130.052\n4545.333\n\n\nQ[4]\n0.463\n0.443\n-0.269\n1.190\n1.001\n2854.288\n4524.978\n\n\nQ[5]\n-0.215\n0.441\n-0.938\n0.509\n1.000\n2965.509\n4711.620\n\n\nQ[6]\n-0.324\n0.414\n-1.001\n0.356\n1.001\n2985.900\n4759.978\n\n\nQ[7]\n0.199\n0.448\n-0.539\n0.923\n1.001\n2831.058\n4382.386\n\n\nQ[8]\n0.313\n0.417\n-0.377\n0.996\n1.001\n3134.601\n4235.354\n\n\nQ[9]\n0.131\n0.411\n-0.542\n0.805\n1.001\n3100.295\n4753.044\n\n\nQ[10]\n0.164\n0.413\n-0.519\n0.833\n1.001\n3065.848\n4520.487\n\n\nQ[11]\n0.029\n0.412\n-0.647\n0.706\n1.001\n3237.767\n4811.668\n\n\nQ[12]\n0.010\n0.417\n-0.672\n0.699\n1.001\n2969.857\n4858.759\n\n\nQ[13]\n-0.060\n0.410\n-0.748\n0.612\n1.001\n3086.981\n4152.617\n\n\nQ[14]\n-0.085\n0.440\n-0.792\n0.644\n1.001\n2721.008\n4027.586\n\n\nQ[15]\n-0.312\n0.442\n-1.050\n0.403\n1.001\n2752.770\n4574.809\n\n\nQ[16]\n-0.156\n0.407\n-0.833\n0.509\n1.001\n2953.055\n5064.659\n\n\nQ[17]\n-0.100\n0.410\n-0.778\n0.566\n1.001\n3030.830\n4673.187\n\n\nQ[18]\n-0.814\n0.415\n-1.500\n-0.122\n1.001\n2980.442\n4694.786\n\n\nQ[19]\n-0.255\n0.447\n-0.980\n0.476\n1.001\n2841.318\n4327.589\n\n\nQ[20]\n0.291\n0.447\n-0.448\n1.024\n1.001\n2844.382\n4209.955\n\n\nsigma\n0.998\n0.055\n0.910\n1.093\n1.000\n10580.140\n5665.150\n\n\n\n\n\nTodo parece bien con los diagnósticos. Podemos graficar las estimaciones (nota: aquí estan intervalos de 50% y 90%):\n\nlibrary(bayesplot)\ncolor_scheme_set(\"red\")\nmcmc_intervals(ajuste_vinos_2$draws(c(\"Q\", \"O\", \"sigma\")))\n\n\n\n\n\n\n\n\n\nParece no haber mucha diferencia en calidad debida origen del vinos (tienen relativamente poca variabilidad y están traslapadas: aunque podríamos mejor calcular el contraste si queremos examinar esto con más cuidado).\n\nTodo parece ir bien, así que podemos expandir el modelo para incluir la forma de calificar de los jueces. Esto no es necesario (los jueces son una causa adicional que afecta el score), pero puede mejorar nuestras estimaciones.\nPara estratificar por estas variables, tenemos que separarnos un poco de efectos adivitivos. Una razón importante por la que varían las calificaciones es que hay jueces que son más duros que otros, o que discriminan más qué otros. Esto es usual también cuando pensamos que los jueces son reactivos que las personas contestan: existen reactivos más difíciles que otros, y también discriminan de diferente manera.\nEn primer lugar, definimos un nivel general \\(H\\) que indica qué tan alto o bajo califica un juez en general. Adicionalmente, incluímos un parámetro de discriminación \\(D\\) de los jueces, que indica qué tanto del rango de la escala usa cada juez El modelo para el valor esperado del Score de un vino \\(i\\) calificado por el juez \\(j\\) es:\n\\[\\mu_{i} = Q_{vino(i)} + O_{origen(i)} - H_{juez(i)}\\] Podemos pensar que el valor \\(H\\) de cada juez es qué tan duro es en sus calificaciones. Para cada vino, un juez con valor alto de \\(H\\) tendrá a calificar más bajo un vino de misma calidad y origen que otro juez con un valor más bajo de \\(H\\). Podemos incluír un parámetro de discriminación \\(D\\) para cada juez, que indica qué tanto del rango de la escala usa cada juez de la siguiente forma:\n\\[\\mu_{i} = (Q_{vino(i)} + O_{origen(i)} - H_{juez(i)})D_{juez(i)}\\] Un juez con valor alto de \\(D\\) es más extremo en sus calificaciones: un vino por arriba de su promedio lo califica más alto en la escala, y un vino por debajo de su promedio lo califica más bajo. El extremo es que \\(D=0\\), que quiere decir que el juez tiende a calificar a todos los vinos con un score.\n\nmod_vinos_3 &lt;-cmdstan_model(\"./src/vinos-3.stan\")\nprint(mod_vinos_3)\n\ndata {\n  int&lt;lower=0&gt; N; //número de calificaciones\n  int&lt;lower=0&gt; n_vinos; //número de vinos\n  int&lt;lower=0&gt; n_jueces; //número de jueces\n  int&lt;lower=0&gt; n_origen; //número de jueces\n  vector[N]  S;\n  array[N]  int juez;\n  array[N]  int vino;\n  array[N]  int origen;\n}\n\nparameters {\n  vector[n_vinos] Q;\n  vector[n_origen] O;\n  vector[n_jueces] H;\n  vector&lt;lower=0&gt;[n_jueces] D;\n\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n  vector[N] media_score;\n  // determinístico dado parámetros\n  for (i in 1:N){\n    media_score[i] = (Q[vino[i]] + O[origen[i]] - H[juez[i]]) * D[juez[i]];\n  }\n}\n\nmodel {\n  // partes no determinísticas\n  S ~ normal(media_score, sigma);\n  Q ~ std_normal();\n  O ~ std_normal();\n  H ~ std_normal();\n  D ~ std_normal();\n  sigma ~ exponential(1);\n}\n\ngenerated quantities {\n  real dif_origen;\n  dif_origen = O[1] - O[2];\n}\n\n\n\ndatos_lst &lt;- list(\n  N = nrow(wines_2012),\n  n_vinos = n_vinos,\n  n_jueces = n_jueces,\n  n_origen = n_origen,\n  S = wines_2012$score_est,\n  vino = wines_2012$vino_num,\n  juez = wines_2012$juez_num,\n  origen = wines_2012$origen_num\n)\najuste_vinos_3 &lt;- mod_vinos_3$sample(\n  data = datos_lst,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000,\n  refresh = 1000,\n  step_size = 0.1,\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 3000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 1 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 2 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 2 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 3 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 3 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 4 Iteration: 1000 / 3000 [ 33%]  (Warmup) \nChain 4 Iteration: 1001 / 3000 [ 33%]  (Sampling) \nChain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 3 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 4 Iteration: 2000 / 3000 [ 66%]  (Sampling) \nChain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 1 finished in 1.5 seconds.\nChain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 3 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 2 finished in 1.5 seconds.\nChain 3 finished in 1.5 seconds.\nChain 4 Iteration: 3000 / 3000 [100%]  (Sampling) \nChain 4 finished in 1.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.5 seconds.\nTotal execution time: 1.7 seconds.\n\n\nChecamos diagnósticos:\n\najuste_vinos_3$summary(c(\"O\", \"Q\", \"H\", \"D\", \"sigma\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, contains(\"ess\")) |&gt;\n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) |&gt; \n  filter(variable != \"lp__\") |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nO[1]\n-0.113\n0.441\n-0.833\n0.608\n1.003\n3679.991\n4652.978\n\n\nO[2]\n0.186\n0.477\n-0.593\n0.964\n1.002\n3547.545\n4483.151\n\n\nQ[1]\n0.360\n0.548\n-0.540\n1.276\n1.001\n5322.571\n6002.472\n\n\nQ[2]\n0.178\n0.579\n-0.782\n1.124\n1.001\n5465.570\n6026.028\n\n\nQ[3]\n0.503\n0.539\n-0.388\n1.399\n1.001\n5668.139\n5300.923\n\n\nQ[4]\n0.828\n0.571\n-0.083\n1.791\n1.000\n6802.908\n5985.020\n\n\nQ[5]\n-0.479\n0.557\n-1.391\n0.423\n1.000\n5839.277\n5403.464\n\n\nQ[6]\n-0.810\n0.600\n-1.764\n0.214\n1.001\n4026.734\n4201.062\n\n\nQ[7]\n0.217\n0.597\n-0.764\n1.201\n1.001\n4744.676\n4913.375\n\n\nQ[8]\n0.607\n0.544\n-0.281\n1.503\n1.001\n6310.887\n5454.771\n\n\nQ[9]\n0.273\n0.553\n-0.639\n1.171\n1.000\n5113.046\n6091.356\n\n\nQ[10]\n0.318\n0.530\n-0.547\n1.191\n1.001\n5967.785\n5681.323\n\n\nQ[11]\n0.177\n0.549\n-0.736\n1.069\n1.001\n5352.487\n5580.738\n\n\nQ[12]\n-0.079\n0.563\n-0.980\n0.867\n1.002\n6207.134\n5855.868\n\n\nQ[13]\n0.054\n0.553\n-0.856\n0.950\n1.001\n5568.384\n5382.425\n\n\nQ[14]\n-0.149\n0.556\n-1.064\n0.751\n1.000\n6430.790\n6066.628\n\n\nQ[15]\n-0.515\n0.553\n-1.438\n0.374\n1.001\n5495.661\n6275.992\n\n\nQ[16]\n-0.131\n0.550\n-1.052\n0.768\n1.000\n5415.706\n5541.138\n\n\nQ[17]\n0.089\n0.562\n-0.869\n0.981\n1.001\n4307.663\n4879.125\n\n\nQ[18]\n-1.498\n0.562\n-2.433\n-0.582\n1.001\n6379.214\n5979.677\n\n\nQ[19]\n-0.365\n0.548\n-1.269\n0.512\n1.000\n6283.849\n5708.185\n\n\nQ[20]\n0.481\n0.564\n-0.440\n1.395\n1.001\n5358.471\n5733.736\n\n\nH[1]\n0.592\n0.575\n-0.286\n1.564\n1.001\n4874.425\n5211.588\n\n\nH[2]\n-0.278\n0.452\n-1.011\n0.427\n1.001\n3719.978\n4427.012\n\n\nH[3]\n-0.480\n0.736\n-1.686\n0.727\n1.001\n6326.880\n5398.394\n\n\nH[4]\n1.223\n0.604\n0.301\n2.259\n1.001\n5677.034\n5363.526\n\n\nH[5]\n-1.771\n0.606\n-2.843\n-0.831\n1.001\n5858.210\n5256.673\n\n\nH[6]\n-1.178\n0.655\n-2.295\n-0.172\n1.001\n5301.648\n4724.878\n\n\nH[7]\n-0.252\n0.590\n-1.226\n0.668\n1.001\n5007.531\n3545.318\n\n\nH[8]\n1.193\n0.561\n0.338\n2.166\n1.001\n4624.172\n4535.633\n\n\nH[9]\n0.829\n0.813\n-0.568\n2.120\n1.001\n6615.592\n4544.897\n\n\nD[1]\n0.471\n0.259\n0.091\n0.945\n1.000\n2523.447\n1892.213\n\n\nD[2]\n0.930\n0.359\n0.337\n1.535\n1.004\n2141.388\n1953.117\n\n\nD[3]\n0.252\n0.186\n0.025\n0.611\n1.000\n3784.918\n3508.124\n\n\nD[4]\n0.447\n0.197\n0.176\n0.812\n1.000\n4438.035\n3505.474\n\n\nD[5]\n0.455\n0.150\n0.246\n0.722\n1.000\n5506.215\n5275.142\n\n\nD[6]\n0.346\n0.171\n0.100\n0.653\n1.000\n3715.060\n2460.752\n\n\nD[7]\n0.579\n0.412\n0.045\n1.328\n1.004\n1600.389\n2689.548\n\n\nD[8]\n0.627\n0.247\n0.286\n1.082\n1.000\n4200.483\n4775.449\n\n\nD[9]\n0.198\n0.145\n0.017\n0.469\n1.001\n3227.969\n2801.364\n\n\nsigma\n0.822\n0.050\n0.744\n0.908\n1.003\n4332.677\n5367.818\n\n\n\n\n\nY vemos efectivamente que el uso de la escala de los jueces es considerablemente diferente, y que hemos absorbido parte de la variación con los parámetros \\(H\\) y \\(D\\) (\\(sigma\\) es más baja que en los modelos anteriores):\n\nmcmc_intervals(ajuste_vinos_3$draws(c(\"H\", \"D\", \"sigma\")))\n\n\n\n\n\n\n\n\n\nmcmc_intervals(ajuste_vinos_3$draws(c(\"Q\")))\n\n\n\n\n\n\n\nmcmc_intervals(ajuste_vinos_1$draws(c(\"Q\")))\n\n\n\n\n\n\n\n\nCon el modelo completo, examinamos ahora el contraste de interés: ¿hay diferencias en las calificaciones de vinos de diferentes orígenes? La respuesta es que no hay mucha evidencia de que haya una diferencia, aunque hay variación considerable en este contraste:\n\najuste_vinos_3$summary(c(\"dif_origen\")) |&gt; \n  select(variable, mean, sd, q5, q95, rhat, contains(\"ess\")) |&gt; \n  mutate(across(c(mean, sd, q5, q95, rhat, ess_bulk, ess_tail), ~round(., 3))) \n\n# A tibble: 1 × 8\n  variable     mean    sd    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 dif_origen -0.299 0.495 -1.11  0.51     1    4181.    5324.\n\n\n\nmcmc_hist(ajuste_vinos_3$draws(\"dif_origen\"), binwidth = 0.07)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "08-mcmc.html#transiciones-divergentes",
    "href": "08-mcmc.html#transiciones-divergentes",
    "title": "8  Markov Chain Monte Carlo",
    "section": "8.5 Transiciones divergentes",
    "text": "8.5 Transiciones divergentes\nFinalmente, discutiremos otro tipo de diagnósticos de Stan. Cuando una trayectoria tuvo un cambio grande en energía \\(H\\) desde su valor actual a la propuesta final, usualmente del orden de 10^3 por ejemplo, esto implica un rechazo “fuerte” en el nuevo punto de la trayectoria, e implica que la el integrador numérico falló de manera grave.\n\n\n\n\n\n\nTransiciones divergentes\n\n\n\nCuando en Stan obtenemos un número considerable de transiciones divergentes, generalmente esto indica que el integrador numérico de Stan no está funcionando bien, y por lo tanto la exploración puede ser deficiente y/o puede estar sesgada al espacio de parámetros donde no ocurren estos rechazos.\n\n\nEsto puede pasar cuando encontramos zonas de alta curvatura en el espacio de parámetros. Que una posterior esté altamente concentrada o más dispersa generalmente no es un problema, pero si la concentración varía fuertemente (curvatura) entonces puede ser difícil encontrar la escala correcta para que el integrador funcione apropiadamente.\n\n8.5.1 El embudo de Neal\nPara ver un ejemplo, consideremos un ejemplo de una distribución cuya forma aparecerá más tarde en modelos jerárquicos. Primero, la marginal de \\(y\\) es normal con media 0 y desviación estándar 3. La distribución condicional \\(p(x|y)\\) de \\(x = c(x_1,\\ldots, x_9)\\) dado \\(y\\) es normal multivariada, todas con media cero y desviación estándar \\(e^{y/2}\\). Veamos qué pasa si intentamos simular de esta distribución en Stan:\n\nmod_embudo &lt;- cmdstan_model(\"./src/embudo-neal.stan\")\najuste_embudo &lt;- mod_embudo$sample(\n  chains = 1,\n  iter_warmup = 1000,\n  iter_sampling = 3000,\n  refresh = 1000)\n\nRunning MCMC with 1 chain...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\n\n\nWarning: 73 of 3000 (2.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 1 of 1 chains had an E-BFMI less than 0.3.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nY vemos que aparecen algunos problemas.\n\nsimulaciones &lt;- ajuste_embudo$draws(format = \"df\")\ndiagnosticos &lt;- ajuste_embudo$sampler_diagnostics(format = \"df\")\nsims_diag &lt;- simulaciones |&gt; inner_join(diagnosticos, by = c(\".draw\", \".iteration\", \".chain\"))\najuste_embudo$summary() |&gt; \n  select(variable, mean, rhat, contains(\"ess\")) \n\n# A tibble: 11 × 5\n   variable     mean  rhat ess_bulk ess_tail\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 lp__     -2.51     1.33     2.65    NA   \n 2 y        -0.421    1.28     3.06     8.51\n 3 x[1]     -0.0772   1.05   419.     273.  \n 4 x[2]      0.0673   1.15  3032.     297.  \n 5 x[3]     -0.102    1.27  1039.     369.  \n 6 x[4]     -0.0111   1.18  2310.     366.  \n 7 x[5]     -0.00279  1.29  2352.     377.  \n 8 x[6]      0.00918  1.28  3135.     387.  \n 9 x[7]     -0.0513   1.25  2591.     325.  \n10 x[8]      0.0689   1.04   320.     368.  \n11 x[9]      0.0129   1.24  2402.     389.  \n\nggplot(sims_diag, aes(y = y, x = `x[1]`)) +\n  geom_point(alpha = 0.1) +\n  geom_point(data = sims_diag |&gt; filter(divergent__ == 1), color = \"red\", size = 2) +\n  geom_hline(yintercept = -2.5, linetype = 2) \n\n\n\n\n\n\n\n\nY vemos que hay transiciones divergentes. Cuando el muestreador entra en el cuello del embudo, es muy fácil que se “despeñe” en probabilidad y que no pueda explorar correctamente la forma del cuello. Esto lo podemos ver, por ejemplo, si hacemos más simulaciones:\n\nmod_embudo &lt;- cmdstan_model(\"./src/embudo-neal.stan\")\nprint(mod_embudo)\n\nparameters {\n  real y;\n  vector[9] x;\n}\nmodel {\n  y ~ normal(0, 3);\n  x ~ normal(0, exp(y/2));\n}\n\najuste_embudo &lt;- mod_embudo$sample(\n  chains = 1,\n  iter_warmup = 1000,\n  iter_sampling = 30000,\n  refresh = 10000)\n\nRunning MCMC with 1 chain...\n\nChain 1 Iteration:     1 / 31000 [  0%]  (Warmup) \nChain 1 Iteration:  1001 / 31000 [  3%]  (Sampling) \nChain 1 Iteration: 11000 / 31000 [ 35%]  (Sampling) \nChain 1 Iteration: 21000 / 31000 [ 67%]  (Sampling) \nChain 1 Iteration: 31000 / 31000 [100%]  (Sampling) \nChain 1 finished in 1.2 seconds.\n\n\nWarning: 68 of 30000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 74 of 30000 (0.0%) transitions hit the maximum treedepth limit of 10.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 1 of 1 chains had an E-BFMI less than 0.3.\nSee https://mc-stan.org/misc/warnings for details.\n\najuste_embudo$summary() |&gt; \n  select(variable, mean, rhat, contains(\"ess\")) \n\n# A tibble: 11 × 5\n   variable     mean  rhat ess_bulk ess_tail\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 lp__     -9.75     1.00     200.     67.7\n 2 y         1.08     1.00     195.     68.6\n 3 x[1]     -0.00284  1.00   34995.   2063. \n 4 x[2]     -0.0900   1.00   39167.   2154. \n 5 x[3]     -0.0474   1.00   37347.   1992. \n 6 x[4]     -0.0988   1.00   34905.   1911. \n 7 x[5]      0.0120   1.00   21594.   2016. \n 8 x[6]     -0.0236   1.00   40213.   1970. \n 9 x[7]      0.144    1.00   25185.   2161. \n10 x[8]     -0.0638   1.00   33798.   2117. \n11 x[9]     -0.0243   1.00   34420.   2033. \n\nsimulaciones &lt;- ajuste_embudo$draws(format = \"df\")\ndiagnosticos &lt;- ajuste_embudo$sampler_diagnostics(format = \"df\")\nsims_diag &lt;- simulaciones |&gt; inner_join(diagnosticos, by = c(\".draw\", \".iteration\", \".chain\"))\nggplot(sims_diag, aes(y = y, x = `x[1]`)) +\n  geom_point(alpha = 0.1) +\n  geom_point(data = sims_diag |&gt; filter(divergent__ == 1), color = \"red\", size = 2) +\n  geom_hline(yintercept = -2.5, linetype = 2) \n\n\n\n\n\n\n\n\nY vemos que ahora que en el primer ejemplo estábamos probablemente sobreestimando la media de \\(y\\). Las divergencias indican que esto puede estar ocurriendo. En este ejemplo particular, también vemos que las R-hat y los tamaños efectivos de muestra son bajos.\nEste es un ejemplo extremo. Sin embargo, podemos reparametrizar para hacer las cosas más fáciles para el muestreador. Podemos simular \\(y\\), y después, simular \\(x\\) como \\(x \\sim e^{y/2} z\\) donde \\(z\\) es normal estándar.\n\nmod_embudo_reparam &lt;- cmdstan_model(\"./src/embudo-neal-reparam.stan\")\nprint(mod_embudo_reparam)\n\nparameters {\n  real y;\n  vector[9] z;\n}\n\ntransformed parameters {\n  vector[9] x;\n\n  x = exp(y/2) * z;\n\n}\n\nmodel {\n  y ~ normal(0, 3);\n  z ~ std_normal();\n}\n\najuste_embudo &lt;- mod_embudo_reparam$sample(\n  chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 10000,\n  refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:     1 / 11000 [  0%]  (Warmup) \nChain 1 Iteration:  1000 / 11000 [  9%]  (Warmup) \nChain 1 Iteration:  1001 / 11000 [  9%]  (Sampling) \nChain 1 Iteration:  2000 / 11000 [ 18%]  (Sampling) \nChain 1 Iteration:  3000 / 11000 [ 27%]  (Sampling) \nChain 1 Iteration:  4000 / 11000 [ 36%]  (Sampling) \nChain 1 Iteration:  5000 / 11000 [ 45%]  (Sampling) \nChain 1 Iteration:  6000 / 11000 [ 54%]  (Sampling) \nChain 1 Iteration:  7000 / 11000 [ 63%]  (Sampling) \nChain 1 Iteration:  8000 / 11000 [ 72%]  (Sampling) \nChain 1 Iteration:  9000 / 11000 [ 81%]  (Sampling) \nChain 1 Iteration: 10000 / 11000 [ 90%]  (Sampling) \nChain 1 Iteration: 11000 / 11000 [100%]  (Sampling) \nChain 1 finished in 0.2 seconds.\nChain 2 Iteration:     1 / 11000 [  0%]  (Warmup) \nChain 2 Iteration:  1000 / 11000 [  9%]  (Warmup) \nChain 2 Iteration:  1001 / 11000 [  9%]  (Sampling) \nChain 2 Iteration:  2000 / 11000 [ 18%]  (Sampling) \nChain 2 Iteration:  3000 / 11000 [ 27%]  (Sampling) \nChain 2 Iteration:  4000 / 11000 [ 36%]  (Sampling) \nChain 2 Iteration:  5000 / 11000 [ 45%]  (Sampling) \nChain 2 Iteration:  6000 / 11000 [ 54%]  (Sampling) \nChain 2 Iteration:  7000 / 11000 [ 63%]  (Sampling) \nChain 2 Iteration:  8000 / 11000 [ 72%]  (Sampling) \nChain 2 Iteration:  9000 / 11000 [ 81%]  (Sampling) \nChain 2 Iteration: 10000 / 11000 [ 90%]  (Sampling) \nChain 2 Iteration: 11000 / 11000 [100%]  (Sampling) \nChain 2 finished in 0.2 seconds.\nChain 3 Iteration:     1 / 11000 [  0%]  (Warmup) \nChain 3 Iteration:  1000 / 11000 [  9%]  (Warmup) \nChain 3 Iteration:  1001 / 11000 [  9%]  (Sampling) \nChain 3 Iteration:  2000 / 11000 [ 18%]  (Sampling) \nChain 3 Iteration:  3000 / 11000 [ 27%]  (Sampling) \nChain 3 Iteration:  4000 / 11000 [ 36%]  (Sampling) \nChain 3 Iteration:  5000 / 11000 [ 45%]  (Sampling) \nChain 3 Iteration:  6000 / 11000 [ 54%]  (Sampling) \nChain 3 Iteration:  7000 / 11000 [ 63%]  (Sampling) \nChain 3 Iteration:  8000 / 11000 [ 72%]  (Sampling) \nChain 3 Iteration:  9000 / 11000 [ 81%]  (Sampling) \nChain 3 Iteration: 10000 / 11000 [ 90%]  (Sampling) \nChain 3 Iteration: 11000 / 11000 [100%]  (Sampling) \nChain 3 finished in 0.2 seconds.\nChain 4 Iteration:     1 / 11000 [  0%]  (Warmup) \nChain 4 Iteration:  1000 / 11000 [  9%]  (Warmup) \nChain 4 Iteration:  1001 / 11000 [  9%]  (Sampling) \nChain 4 Iteration:  2000 / 11000 [ 18%]  (Sampling) \nChain 4 Iteration:  3000 / 11000 [ 27%]  (Sampling) \nChain 4 Iteration:  4000 / 11000 [ 36%]  (Sampling) \nChain 4 Iteration:  5000 / 11000 [ 45%]  (Sampling) \nChain 4 Iteration:  6000 / 11000 [ 54%]  (Sampling) \nChain 4 Iteration:  7000 / 11000 [ 63%]  (Sampling) \nChain 4 Iteration:  8000 / 11000 [ 72%]  (Sampling) \nChain 4 Iteration:  9000 / 11000 [ 81%]  (Sampling) \nChain 4 Iteration: 10000 / 11000 [ 90%]  (Sampling) \nChain 4 Iteration: 11000 / 11000 [100%]  (Sampling) \nChain 4 finished in 0.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.9 seconds.\n\n\nY con este truco de reparametrización el muestreador funciona correctamente (observa que la media de \\(y\\) está estimada correctamente, y no hay divergencias).\n\najuste_embudo$summary() |&gt; \n  select(variable, mean, rhat, contains(\"ess\")) |&gt; \n  mutate(across(c(mean, rhat, ess_bulk, ess_tail), ~round(., 3))) \n\n# A tibble: 20 × 5\n   variable   mean  rhat ess_bulk ess_tail\n   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 lp__     -5.03      1   17948.   26229.\n 2 y         0.004     1   77361.   28544.\n 3 z[1]      0.003     1   71376.   30814.\n 4 z[2]      0.001     1   77225.   31280.\n 5 z[3]      0.002     1   74820.   29077.\n 6 z[4]     -0.006     1   76076.   29779.\n 7 z[5]     -0.001     1   73795.   30578.\n 8 z[6]      0.003     1   75544.   31666.\n 9 z[7]      0.005     1   76972.   31473.\n10 z[8]     -0.004     1   75267.   30573.\n11 z[9]      0.004     1   72570.   30613.\n12 x[1]      0.036     1   40572.   31754.\n13 x[2]     -0.046     1   41491.   30843.\n14 x[3]     -0.111     1   40644.   31276.\n15 x[4]     -0.023     1   40500.   31264.\n16 x[5]     -0.048     1   39970.   30863.\n17 x[6]     -0.032     1   39477.   30354.\n18 x[7]      0.028     1   40369.   29356.\n19 x[8]      0.051     1   40578.   31554.\n20 x[9]     -0.04      1   40080.   30505.\n\n\n\n\n\n\nBrooks, Steve, Andrew Gelman, Galin Jones, y Xiao-Li Meng. 2011. Handbook of Markov Chain Monte Carlo. CRC press.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html",
    "href": "09-modelos-jerarquicos.html",
    "title": "9  Modelos jerárquicos",
    "section": "",
    "text": "9.1 Primer ejemplo: construyendo un modelo jerárquico.\nMuchas veces, cuando las observaciones están agrupadas por variables categóricas, puede ser que obtengamos mejores estimaciones cuando consideramos modelos no solo para los observaciones, sino también para la variación que esperamos en parámetros relacionadas con los grupos. Esta es una técnica de modelación con la que en muchos casos podemos mejorar estimaciones, aprovechando de manera más eficiente la información que tenemos.\nEn nuestros ejemplos anteriores, por ejemplo, hemos visto casos donde al estratificar construimos modelos individuales, por ejemplo, en regresión lineal, si \\(g(i)\\) es el grupo de la observación \\(i\\), utilizamos modelos de la forma:\n\\[\\alpha_{g(i)} + \\beta_{g(i)} x_i + \\epsilon_i\\] Este modelo, donde ordenada al origen y coeficientes varían por grupo, tienen a veces el problema de resultar en estimaciones con alta variabilidad y poco informativas, especialmente cuando tenemos pocos datos por grupo. Cuando es el caso de que estos coeficientes no varían por grupo, podemos adoptar un modelo más simple, como \\[\\alpha + \\beta x_i + \\epsilon_i,\\] que da estimaciones con menos error, pero perdemos el objetivo de la estratificación a menos que en efecto los coeficientes no varían mucho por grupo.\nUna alternativa intermedia es construir un modelo donde aprendamos la estructura de variabilidad de \\(\\alpha_g\\) y \\(\\beta_g\\) a lo largo de los grupos: aprendemos de cada grupo, pero los coeficientes de cada grupo tienen una distribución a priori con parámetros que podemos aprender de los datos. Esto resulta en varias mejorías:\nEl objetivo de todo esto es obtener mejores estimaciones de las cantidades de interés. Veremos más adelante cómo se relaciona esto con inferencia causal.\nConsideramos un ejemplo simple, donde queremos estimar el efecto del hospital en la tasa de mortalidad de pacientes de cirugía de corazón. Este ejemplo se puede encontrar en Albert (2009). Plantearemos 3 alternativas de modelación para resolver el problema: modelo de unidades iguales, modelo de unidades independientes y finalmente modelo jerárquico.\nTenemos datos todas las cirugías de transplante de corazón llevadas a cabo en Estados Unidos en un periodo de 24 meses, entre octubre de 1987 y diciembre de 1989. Para cada uno de los 131 hospitales, se registró el número de cirugías de transplante de corazón, y el número de muertes durante los 30 días posteriores a la cirugía \\(y\\). Además, se cuenta con una predicción de la probabilidad de muerte de cada paciente individual. Esta predicción esta basada en un modelo logístico que incluye información a nivel paciente como condición médica antes de la cirugía, género, sexo y raza. En cada hospital se suman las probabilidades de muerte de sus pacientes para calcular el número esperado de muertes \\(e\\), que llamamos como la exposición del hospital. \\(e\\) refleja el riesgo de muerte debido a la mezcla de pacientes que componen un hospital particular.\nEl diagrama simple que consideraremos es uno donde hospital es causa tanto de su exposición \\(e\\) (por su tamaño, tipo de casos que atrae, etc), como de el número de personas fallecidas. A su vez, la exposición \\(e\\) es causa del número de muertes \\(y\\). Nos interesa estimar el efecto directo de hospital en el número de muertes.\nCódigo\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(DiagrammeR)\nggplot2::theme_set(ggplot2::theme_light())\ndatos_hosp &lt;- read_csv(\"../datos/hearttransplants.csv\") |&gt; \n  mutate(hospital = row_number())\nhead(datos_hosp)\n\n# A tibble: 6 × 3\n      e     y hospital\n  &lt;dbl&gt; &lt;dbl&gt;    &lt;int&gt;\n1   532     0        1\n2   584     0        2\n3   672     2        3\n4   722     1        4\n5   904     1        5\n6  1236     0        6\nConsideramos la cantidad \\(y/e\\) como una estimación cruda de la tasa de mortalidad. En la siguiente gráfica, observamos que parece ser la variabilidad es alta cuando el número de expuestos es relativamente baja. Nótese que la tasa de mortalidad no es muy alta en general, y que el número de muertes es relativamente bajo en muchos hospitales (puede tomar valores 0, 1, 2, etc.) Esto produce variabilidad alta para exposiciones bajas.\nggplot(datos_hosp, aes(x = e, y = 1000 * y / e, color = log(1 + y))) +\n  geom_point() + scale_x_log10() + xlab(\"Número de expuestos e\")\nConsideramos primero un modelo donde consideramos que todos los hospitales tienen una misma tasa de mortalidad. Si \\(e_j\\) es la exposición del hospital \\(j\\) y \\(y_j\\) el número de muertes, entonces podemos considerar un modelo de la forma\n\\[y_j \\sim \\text{Poisson}(e_j \\lambda),\\] Es decir, el número de muertes es Poisson con valor esperado igual al número de expuestos multiplicado por la tasa común de mortalidad.\nlibrary(cmdstanr)\nmod_agregado &lt;- cmdstan_model(\"./src/heart-agregado.stan\")\ndatos_agregado &lt;- list(N = nrow(datos_hosp), y = datos_hosp$y, e = datos_hosp$e)\najuste_agregado &lt;- mod_agregado$sample(data = datos_agregado, chains = 4, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\najuste_agregado$summary(\"lambda\")\n\n# A tibble: 1 × 10\n  variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 lambda   0.941  0.939 0.0567 0.0559 0.850  1.04  1.00    1553.    1520.\nLos diagnósticos básicos parecen ser apropiados. Procedemos a hacer un chequeo predictivo posterior:\nset.seed(912)\najuste_agregado$draws(\"y_sim\", format = \"df\") |&gt; \n  as_tibble() |&gt; \n  pivot_longer(cols = starts_with(\"y_sim\"), names_to = \"variable\") |&gt; \n  separate(variable, into = c(\"variable\", \"hospital\"), sep = \"[\\\\[\\\\]]\") |&gt;\n  mutate(hospital = as.integer(hospital)) |&gt;\n  left_join(datos_hosp, by = \"hospital\") |&gt;\n  filter(hospital %in% sample(1:94, 20)) |&gt;\n  ggplot(aes(x = value)) + geom_histogram(binwidth = 1) +\n  facet_wrap(~ hospital) + \n  geom_vline(aes(xintercept = y), color = \"red\")\nY vemos fallas en el ajuste del modelo, con varias observaciones en los extremos de las colas.\nPodemos considerar un modelo donde cada hospital tiene su propia tasa de mortalidad.\nlibrary(cmdstanr)\nmod_ind &lt;- cmdstan_model(\"./src/heart-individual.stan\")\nprint(mod_ind)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N]  int e;\n  array[N]  int y;\n}\n\nparameters {\n  vector&lt;lower=0&gt;[N] lambda;\n}\n\ntransformed parameters {\n  vector[N] media_hospital;\n  // lambda es por cada 1000 expuestos:\n  for (i in 1:N){\n    media_hospital[i] = lambda[i] * e[i] / 1000;\n  }\n}\n\nmodel {\n  // partes no determinísticas\n  y ~ poisson(media_hospital);\n  lambda ~ exponential(1);\n}\n\ngenerated quantities {\n  array[N] int y_sim;\n  for (i in 1:N){\n    y_sim[i] = poisson_rng(media_hospital[i]);\n  }\n}\n\ndatos_ind &lt;- list(N = nrow(datos_hosp), y = datos_hosp$y, e = datos_hosp$e)\najuste_ind &lt;- mod_ind$sample(data = datos_ind, chains = 4, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.2 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.2 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 1.3 seconds.\n\nresumen &lt;- ajuste_ind$summary(\"lambda\") |&gt; \n  select(variable, mean, sd, rhat, ess_bulk)\nresumen |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nrhat\ness_bulk\n\n\n\n\nlambda[1]\n0.6646516\n0.6757171\n1.0003238\n5671.985\n\n\nlambda[2]\n0.6357211\n0.6243277\n1.0007545\n5365.979\n\n\nlambda[3]\n1.7999926\n1.0351070\n1.0005339\n9482.293\n\n\nlambda[4]\n1.1482096\n0.7918770\n0.9995697\n7036.449\n\n\nlambda[5]\n1.0421835\n0.7514765\n1.0003178\n5605.784\n\n\nlambda[6]\n0.4417858\n0.4344137\n1.0006058\n5371.272\n\n\nlambda[7]\n0.5203789\n0.5241833\n1.0015693\n5411.649\n\n\nlambda[8]\n0.8296634\n0.5726511\n1.0008965\n7828.121\n\n\nlambda[9]\n2.2666335\n1.1493925\n1.0013272\n8232.203\n\n\nlambda[10]\n0.5072246\n0.5002002\n1.0010102\n6292.188\n\n\nlambda[11]\n0.5842975\n0.5893118\n1.0003922\n5538.639\n\n\nlambda[12]\n0.7183809\n0.4949999\n1.0011131\n7114.498\n\n\nlambda[13]\n0.5524099\n0.5521176\n1.0014960\n5908.933\n\n\nlambda[14]\n1.4423360\n0.8365688\n1.0011673\n8470.162\n\n\nlambda[15]\n1.8490775\n0.9105362\n1.0000532\n8674.118\n\n\nlambda[16]\n0.4611348\n0.4406408\n1.0012097\n5164.538\n\n\nlambda[17]\n0.4349801\n0.4321191\n0.9996835\n5420.275\n\n\nlambda[18]\n1.4407146\n0.7435426\n1.0009989\n8456.997\n\n\nlambda[19]\n0.4396262\n0.3175211\n1.0017783\n6966.243\n\n\nlambda[20]\n0.9109781\n0.6475169\n0.9998220\n6614.160\n\n\nlambda[21]\n0.8978069\n0.6167924\n0.9999182\n7109.753\n\n\nlambda[22]\n0.9028632\n0.6448046\n1.0009252\n7382.902\n\n\nlambda[23]\n1.9745298\n0.8976105\n1.0003225\n8095.937\n\n\nlambda[24]\n1.5804238\n0.7711687\n1.0014703\n6141.015\n\n\nlambda[25]\n1.3818435\n0.6806168\n1.0007346\n7051.705\n\n\nlambda[26]\n0.6932603\n0.5038569\n1.0023579\n6648.642\n\n\nlambda[27]\n0.4469335\n0.4356824\n1.0007638\n6115.890\n\n\nlambda[28]\n1.2633903\n0.7462800\n1.0007725\n5593.849\n\n\nlambda[29]\n1.1352511\n0.6580436\n1.0006688\n9165.333\n\n\nlambda[30]\n1.8729935\n0.7974212\n1.0006927\n8271.421\n\n\nlambda[31]\n1.7692861\n0.8040345\n0.9995193\n11744.072\n\n\nlambda[32]\n1.6066170\n0.7904808\n1.0002268\n7912.120\n\n\nlambda[33]\n1.1474525\n0.6536435\n1.0003800\n7956.025\n\n\nlambda[34]\n1.5338797\n0.7007129\n1.0013261\n8204.327\n\n\nlambda[35]\n0.7963157\n0.5536296\n1.0014888\n6795.075\n\n\nlambda[36]\n1.4473694\n0.7352793\n1.0014054\n7851.361\n\n\nlambda[37]\n0.4306225\n0.4126602\n1.0013360\n6029.474\n\n\nlambda[38]\n1.9580566\n0.8536929\n1.0022118\n8339.837\n\n\nlambda[39]\n0.7472152\n0.5196808\n0.9999801\n6414.750\n\n\nlambda[40]\n1.1376544\n0.6417261\n0.9999031\n8065.694\n\n\nlambda[41]\n1.4142887\n0.7117459\n1.0003620\n8384.156\n\n\nlambda[42]\n1.6689332\n0.7391365\n1.0012945\n7706.919\n\n\nlambda[43]\n1.8033233\n0.8272017\n1.0004404\n7663.238\n\n\nlambda[44]\n0.8705810\n0.5102484\n1.0019508\n8178.667\n\n\nlambda[45]\n1.0822743\n0.6297766\n1.0005782\n7690.453\n\n\nlambda[46]\n1.4372984\n0.6287997\n1.0013700\n7456.655\n\n\nlambda[47]\n0.8893737\n0.5009567\n1.0004449\n8544.832\n\n\nlambda[48]\n1.0818255\n0.5188063\n1.0005963\n9442.606\n\n\nlambda[49]\n0.3091808\n0.3096686\n1.0001326\n6097.580\n\n\nlambda[50]\n0.3277675\n0.3300572\n0.9999642\n5615.651\n\n\nlambda[51]\n0.7725811\n0.4386927\n1.0020165\n8191.875\n\n\nlambda[52]\n1.5551998\n0.6474287\n1.0023779\n8836.515\n\n\nlambda[53]\n1.4383769\n0.5791151\n0.9996883\n9698.097\n\n\nlambda[54]\n0.5995905\n0.4305288\n1.0009603\n6723.152\n\n\nlambda[55]\n0.5669854\n0.4063470\n0.9993287\n7017.442\n\n\nlambda[56]\n0.8300421\n0.4133649\n1.0000750\n8143.347\n\n\nlambda[57]\n0.5485194\n0.3849103\n1.0017931\n7164.359\n\n\nlambda[58]\n0.5410955\n0.3820882\n0.9999466\n7986.787\n\n\nlambda[59]\n0.9937905\n0.4934654\n1.0028859\n8295.671\n\n\nlambda[60]\n0.4438653\n0.3097022\n1.0011108\n7835.829\n\n\nlambda[61]\n0.8071066\n0.4704887\n1.0011209\n7444.813\n\n\nlambda[62]\n1.5989397\n0.5983520\n1.0011620\n8352.634\n\n\nlambda[63]\n0.2077690\n0.2172824\n0.9997085\n5639.357\n\n\nlambda[64]\n0.5996390\n0.3464267\n1.0008251\n7591.032\n\n\nlambda[65]\n0.8370261\n0.4863333\n0.9998047\n6892.452\n\n\nlambda[66]\n0.5269882\n0.3676465\n1.0023697\n8073.247\n\n\nlambda[67]\n0.5674513\n0.3212519\n1.0004892\n7733.556\n\n\nlambda[68]\n2.0249596\n0.6744208\n0.9997955\n9719.515\n\n\nlambda[69]\n1.5094835\n0.5560700\n1.0003988\n8686.640\n\n\nlambda[70]\n0.3864294\n0.2754893\n1.0000236\n7443.437\n\n\nlambda[71]\n1.4204094\n0.5242873\n1.0008915\n8867.273\n\n\nlambda[72]\n0.9903254\n0.4365463\n1.0012883\n8104.361\n\n\nlambda[73]\n0.3824343\n0.2795265\n1.0007376\n6813.359\n\n\nlambda[74]\n0.8019487\n0.4100269\n1.0031084\n7342.273\n\n\nlambda[75]\n1.0645046\n0.4336646\n1.0010833\n8686.283\n\n\nlambda[76]\n0.4525308\n0.2592850\n1.0005376\n7523.667\n\n\nlambda[77]\n0.6778368\n0.3049926\n0.9999210\n8465.038\n\n\nlambda[78]\n0.6293384\n0.3070139\n1.0001164\n8644.516\n\n\nlambda[79]\n0.9269476\n0.4250754\n1.0014458\n8774.663\n\n\nlambda[80]\n1.0503610\n0.4249451\n1.0026103\n8811.505\n\n\nlambda[81]\n0.4934932\n0.2771659\n1.0027407\n7804.651\n\n\nlambda[82]\n0.9937620\n0.3816912\n0.9998603\n10716.499\n\n\nlambda[83]\n1.4735184\n0.5016865\n1.0016558\n8906.016\n\n\nlambda[84]\n0.4873699\n0.1981582\n1.0024305\n8336.336\n\n\nlambda[85]\n0.1460871\n0.1447668\n1.0004358\n5263.132\n\n\nlambda[86]\n0.9833387\n0.3833634\n1.0002544\n9565.933\n\n\nlambda[87]\n1.3752741\n0.4638758\n1.0015700\n8700.481\n\n\nlambda[88]\n1.1217530\n0.4158173\n1.0002994\n8897.308\n\n\nlambda[89]\n0.5521337\n0.2732107\n1.0005935\n9228.407\n\n\nlambda[90]\n0.4980557\n0.2447710\n0.9996416\n6848.289\n\n\nlambda[91]\n1.1354363\n0.3652249\n1.0024730\n9505.697\n\n\nlambda[92]\n0.7592420\n0.2677413\n1.0011984\n8986.915\n\n\nlambda[93]\n1.4582915\n0.3369176\n1.0038043\n9737.140\n\n\nlambda[94]\n1.3725399\n0.3287539\n1.0027061\n9317.579\nset.seed(912)\najuste_ind$draws(\"lambda\", format = \"df\") |&gt; \n  as_tibble() |&gt; \n  pivot_longer(cols = starts_with(\"lambda\"), names_to = \"variable\") |&gt; \n  separate(variable, into = c(\"variable\", \"hospital\"), sep = \"[\\\\[\\\\]]\") |&gt;\n  mutate(hospital = as.integer(hospital)) |&gt;\n  left_join(datos_hosp, by = \"hospital\") |&gt;\n  mutate(hospital = factor(hospital)) |&gt;\n  group_by(hospital, e, y) |&gt; \n  summarise(inf = quantile(value, 0.1), sup = quantile(value, 0.9)) |&gt;\n  ggplot(aes(x = e)) + geom_linerange(aes(ymin = inf, ymax = sup)) +\n  geom_point(aes(y = 1000 * y / e), color = \"red\") +\n  scale_x_log10() + xlab(\"Número de expuestos e\") + ylab(\"Muertes por mil expuestos\")\nEl problema en este caso es que tenemos intervalos que simplemente no son creíbles, en particular con aquellos hospitales que tienen poca exposición. Adicionalmente, la variabilidad es muy alta para hospitales con poca exposición, tanto en los datos observados como en los intervalos. Los intervalos no aportan mucha información. En este punto utilizar iniciales fuertes para las \\(\\lambda_j\\) si tenemos la información disponible. Sin embargo, los resultados serán altamente sensible a esta información inicial.\nUna alternativa intermedia es poner una distribución inicial sobre las tasas que pueda adaptarse a los datos. Esta es una estrategia intermedia, donde permitimos variación en las \\(\\lambda_j\\) que sea consistente con la variación que observamos a lo largo de los hospitales.\nlibrary(cmdstanr)\nmod_jer &lt;- cmdstan_model(\"./src/heart-jerarquico.stan\")\nprint(mod_jer)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N]  int e;\n  array[N]  int y;\n}\n\nparameters {\n  vector&lt;lower=0&gt;[N] lambda;\n  real&lt;lower=0&gt; alpha;\n  real&lt;lower=0&gt; mu;\n}\n\ntransformed parameters {\n  vector[N] media_hospital;\n  // lambda es por cada 1000 expuestos:\n  for (i in 1:N){\n    media_hospital[i] = lambda[i] * e[i] /1000;\n  }\n}\n\nmodel {\n  // partes no determinísticas\n  y ~ poisson(media_hospital);\n  lambda ~ gamma(alpha, alpha / mu);\n  mu ~ exponential(1);\n  alpha ~ exponential(1);\n}\n\ngenerated quantities {\n  array[N] int y_sim;\n  for (i in 1:N){\n    y_sim[i] = poisson_rng(media_hospital[i]);\n  }\n}\n\ndatos_jer &lt;- list(N = nrow(datos_hosp), y = datos_hosp$y, e = datos_hosp$e)\najuste_jer &lt;- mod_jer$sample(data = datos_ind, \n    chains = 4, step_size = 0.5, iter_sampling = 3000, refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.7 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable[82] is 0, but must be positive finite! (in '/tmp/Rtmpzi9xDb/model-2c843fcee90e.stan', line 24, column 2 to column 36)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.7 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Inverse scale parameter is 0, but must be positive finite! (in '/tmp/Rtmpzi9xDb/model-2c843fcee90e.stan', line 24, column 2 to column 36)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.7 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 3.3 seconds.\n\nresumen &lt;- ajuste_jer$summary(c(\"alpha\", \"mu\")) |&gt; \n  select(variable, mean, sd, rhat, ess_bulk)\nresumen |&gt; kable()\n\n\n\n\nvariable\nmean\nsd\nrhat\ness_bulk\n\n\n\n\nalpha\n4.4206616\n1.3154599\n1.000455\n2527.162\n\n\nmu\n0.9637605\n0.0811844\n1.000259\n10197.606\nset.seed(912)\najuste_jer$draws(\"lambda\", format = \"df\") |&gt; \n  as_tibble() |&gt; \n  pivot_longer(cols = starts_with(\"lambda\"), names_to = \"variable\") |&gt; \n  separate(variable, into = c(\"variable\", \"hospital\"), sep = \"[\\\\[\\\\]]\") |&gt;\n  mutate(hospital = as.integer(hospital)) |&gt;\n  left_join(datos_hosp, by = \"hospital\") |&gt;\n  mutate(hospital = factor(hospital)) |&gt;\n  group_by(hospital, e, y) |&gt; \n  summarise(inf = quantile(value, 0.1), sup = quantile(value, 0.9), median = median(value)) |&gt;\n  ggplot(aes(x = e)) + geom_linerange(aes(ymin = inf, ymax = sup)) +\n  geom_point(aes(y = 1000 * y / e), color = \"red\") +\n  geom_point(aes(y = median)) +\n  scale_x_log10() + xlab(\"Número de expuestos e\") + ylab(\"Muertes por mil expuestos\")\nLos resultados del chequo predictivo posterior da mejores resultados (compara con el modelo agregado):\nset.seed(912)\najuste_jer$draws(\"y_sim\", format = \"df\") |&gt; \n  as_tibble() |&gt; \n  pivot_longer(cols = starts_with(\"y_sim\"), names_to = \"variable\") |&gt; \n  separate(variable, into = c(\"variable\", \"hospital\"), sep = \"[\\\\[\\\\]]\") |&gt;\n  mutate(hospital = as.integer(hospital)) |&gt;\n  left_join(datos_hosp, by = \"hospital\") |&gt;\n  filter(hospital %in% sample(1:94, 20)) |&gt;\n  ggplot(aes(x = value)) + geom_histogram(binwidth = 1) +\n  facet_wrap(~ hospital) + \n  geom_vline(aes(xintercept = y), color = \"red\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html#primer-ejemplo-construyendo-un-modelo-jerárquico.",
    "href": "09-modelos-jerarquicos.html#primer-ejemplo-construyendo-un-modelo-jerárquico.",
    "title": "9  Modelos jerárquicos",
    "section": "",
    "text": "Modelos jerárquicos y estimación\n\n\n\nLos modelos jerárquicos nos permiten ajustar modelos con agregación parcial: es decir, estimamos parámetros a nivel de grupo con mejor precisión que si ajustamos modelos individuales (varianza muy alta) o agregamos los datos e ignoramos el grupo (sesgo alto).\nLa regularización que ocurre en estos modelos está relacionada a la inicial que estimamos sobre parámetros individuales: cuando hay muchos datos en un grupo, la inicial es menos importante, y cuando hay más datos en un grupo, la inicial es menos importante. El grado de regularización es estimado de la evidencia de variación entre los grupos.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html#modelos-jerárquicos-para-estructuras-causales",
    "href": "09-modelos-jerarquicos.html#modelos-jerárquicos-para-estructuras-causales",
    "title": "9  Modelos jerárquicos",
    "section": "9.2 Modelos jerárquicos para estructuras causales",
    "text": "9.2 Modelos jerárquicos para estructuras causales\nTomaremos ahora el ejemplo de McElreath (2020) de un estudio de fertilidad en Bangladesh. Nos interesa entender causas del uso de anticonceptivos en mujeres de Bangladesh, en particular:\n\n¿Cómo cambia con la edad y el tamaño de la familia el uso de anticonceptivos?\n¿Cómo afecta el nivel de urbanización al uso de anticonceptivos? Queremos ver si es posible contestar esta pregunta de forma causal con los datos disponibles.\n\nEn nuestros datos tenemos muestras por distritos (zonas geográficas) que nos puede ayudar o controlar efectos relacionados con variables relacionadas con distrito (como acceso a servicios de salud, etc).\nComenzamos con un diagrama que describe causas posibles de uso de anticonceptivos:\n\nLos distritos (zona donde vive cada persona) influye causalmente en uso de anticonceptivos.\nLa edad de la mujer influye en el uso de anticonceptivos.\nEl número de hijos influye en el uso de anticonceptivos.\nEl status de urbano/rural influye en el uso de anticonceptivos.\n\nNuestro primer diagrama es:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir=BT]\n  node [shape=plaintext]\n    AC\n    Distrito\n    Edad\n    Hijos\n    Urbano\n  edge [minlen = 3]\n   Edad -&gt; AC [color=\"red\"]\n   Hijos -&gt; AC [color=\"red\"]\n   Urbano -&gt; AC\n   Distrito -&gt; AC\n   \n{\n  rank = same; Urbano; Hijos\n}\n}\n', width = 350, height = 140)\n\n\n\n\n\n\nDonde las flechas rojas son efectos causales de interés, y queremos considerar si es posible identificarlos y estimarlos posteriormente. Para decidir cómo construir nuestro modelo (qué variables podemos incluir o no y por qué), consideraremos relaciones entre las causas, que mostramos como flechas rojas.\n\nNinguna variable es causa de edad, pero Edad puede ser causa de número de hijos (más tiempo para tener más hijos).\nUrbano/rural puede ser causa número de hijos (costumbres)\nDistritos tienen distintos niveles de regiones urbano/rural\n\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir=BT]\n  node [shape=plaintext]\n    AC\n    Distrito\n    Edad\n    Hijos\n    Urbano\n  edge [minlen = 3]\n   Edad -&gt; AC [color=\"red\"]\n   Hijos -&gt; AC [color=\"red\"]\n   Urbano -&gt; AC\n   Distrito -&gt; AC\n   Edad -&gt; Hijos \n   Urbano -&gt; Hijos\n   Distrito -&gt; Urbano\n{\n  rank = same; Urbano; Hijos\n  rank = min; Urbano; Hijos\n}\n}\n', width = 350, height = 140)\n\n\n\n\n\n\nDe este diagrama, concluimos para empezar:\n\nPara el efecto total de edad, no debemos estratificar por número de hijos (bloqueamos un camino causal).\n\nFinalmente, puedes pensar en otras relaciones entre causas que puedan dificultar la identificación causal, como las que marcamos en naranja en el siguiente diagrama, donde\n\nTipo de familia (no observado) puede afectar tanto a número de niños como a uso de anticonceptivos. Esta sería una variable confusora para estimar el efecto de número de niños sobre uso de anticonceptivos.\n\nVemos que encontrar el efecto causal de número de hijos puede tener dificultades considerables en este caso:\n\n\nCódigo\ngrViz('\ndigraph {\n  graph [ranksep = 0.2, rankdir=BT]\n  node [shape=plaintext]\n    AC\n    Distrito\n    Edad\n    Hijos\n    Urbano\n  node [shape=ellipse]\n    Familia\n  edge [minlen = 3]\n   Edad -&gt; AC [color=\"red\"]\n   Hijos -&gt; AC [color=\"red\"]\n   Urbano -&gt; AC\n   Distrito -&gt; AC\n   Edad -&gt; Hijos \n   Urbano -&gt; Hijos\n   Distrito -&gt; Urbano\n   Familia -&gt; Hijos [color=\"orange\"]\n   Familia -&gt; AC [color=\"orange\"]\n\n{\n  rank = same; Urbano; Hijos\n    rank = min; Urbano; Hijos\n\n}\n}\n', width = 350, height = 140)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html#primera-parte-de-estructura-jerárquica",
    "href": "09-modelos-jerarquicos.html#primera-parte-de-estructura-jerárquica",
    "title": "9  Modelos jerárquicos",
    "section": "9.3 Primera parte de estructura jerárquica",
    "text": "9.3 Primera parte de estructura jerárquica\nEmpecemos primero como en nuestro ejemplo anterior, modelando jerárquicamente el uso de anticonceptivos segun distrito (solo vemos el efecto \\(D\\to AC\\)). Esta variable nos puede ayudar a controlar variables asociadas con distrito que mejore la estimación de otras cantidades de interés, y es importante usar una estructura jerárquica pues los tamaños de muestra por distrito son considerablemente distintos:\n\nbangladesh &lt;- read_csv(\"../datos/bangladesh.csv\") |&gt; \n  mutate(district = factor(district, levels = 1:61)) \n\nRows: 1934 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): woman, district, use.contraception, living.children, age.centered, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nbangladesh  |&gt; count(district, .drop = FALSE) |&gt; \n  mutate(district_fct = fct_reorder(district, n)) |&gt;\n  ggplot(aes(x = as.numeric(district), y = n)) + geom_point() +\n  xlab(\"Distrito num\")\n\n\n\n\n\n\n\n\nNótese que un distrito no contiene ninguna observación, y que hay distritos con muy pocas observaciones. Este es un caso típico donde un modelo jerárquico puede mejorar nuestras estimaciones de la relación de distrito con la variable respuesta de interés.\nLos datos, por persona, los modelamos como sigue (regresión logística): \\[\n\\begin{align}\nC_i &\\sim \\text{Bernoulli}(p_i)\\\\\n\\textrm{logit}(p_i) &= \\alpha_{D[i]}  \\\\\n\\alpha_j &\\sim N(\\bar{\\alpha},\\sigma) \\\\\n\\bar{\\alpha} &\\sim N(0, 1) \\\\\n\\sigma &\\sim N^+(0, 1) \\\\\n\\end{align}\n\\] Que implementado en stan puede quedar como:\n\nmod_1_bangladesh &lt;- cmdstan_model(\"./src/bangladesh-1.stan\")\nprint(mod_1_bangladesh)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; N_d;\n  array[N]  int ac_uso;\n  array[N]  int distrito;\n}\n\nparameters {\n  real alpha_bar;\n  vector[N_d] alpha;\n  real &lt;lower=0&gt; sigma;\n}\n\ntransformed parameters {\n\n}\n\nmodel {\n  // partes no determinísticas\n  ac_uso ~ bernoulli_logit(alpha[distrito]);\n  alpha ~ normal(alpha_bar, sigma);\n  // parámetros poblacionales\n  alpha_bar ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n}\n\ngenerated quantities {\n  vector[N_d] prob_distrito;\n  for (i in 1:N_d) {\n    prob_distrito[i] = inv_logit(alpha[i]);\n  }\n\n}\n\n\n\ndatos_lst &lt;- list(\n  ac_uso = bangladesh$use.contraception,\n  distrito = as.integer(bangladesh$district),\n  N = nrow(bangladesh),\n  N_d = 61\n)\najuste_1_bangladesh &lt;- mod_1_bangladesh$sample(data = datos_lst,\n                                               refresh = 1000)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.2 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.3 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.4 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.3 seconds.\nTotal execution time: 5.7 seconds.\n\n\n\najuste_1_bangladesh$cmdstan_diagnose()\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nRank-normalized split effective sample size satisfactory for all parameters.\n\nRank-normalized split R-hat values satisfactory for all parameters.\n\nProcessing complete, no problems detected.\n\n\n\najuste_1_bangladesh$summary(c(\"alpha_bar\", \"sigma\", \"alpha\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nalpha_bar\n-0.54\n-0.54\n0.09\n0.09\n-0.69\n-0.39\n1\n3249.05\n3022.43\n\n\nsigma\n0.52\n0.51\n0.09\n0.08\n0.39\n0.67\n1\n1274.86\n1379.70\n\n\nalpha[1]\n-0.99\n-0.99\n0.20\n0.19\n-1.32\n-0.67\n1\n5118.48\n3264.48\n\n\nalpha[2]\n-0.58\n-0.58\n0.35\n0.34\n-1.17\n-0.03\n1\n4868.09\n2860.55\n\n\nalpha[3]\n-0.24\n-0.25\n0.51\n0.50\n-1.04\n0.61\n1\n6034.45\n2991.20\n\n\nalpha[4]\n-0.18\n-0.17\n0.30\n0.30\n-0.70\n0.33\n1\n4858.83\n2761.37\n\n\nalpha[5]\n-0.57\n-0.57\n0.28\n0.28\n-1.04\n-0.11\n1\n4895.57\n2801.80\n\n\nalpha[6]\n-0.82\n-0.81\n0.24\n0.24\n-1.22\n-0.43\n1\n5616.59\n2881.90\n\n\nalpha[7]\n-0.75\n-0.73\n0.36\n0.37\n-1.36\n-0.16\n1\n4964.63\n2900.97\n\n\nalpha[8]\n-0.51\n-0.51\n0.29\n0.29\n-1.00\n-0.04\n1\n5792.48\n2687.59\n\n\nalpha[9]\n-0.71\n-0.69\n0.35\n0.34\n-1.29\n-0.15\n1\n5134.54\n2690.43\n\n\nalpha[10]\n-1.14\n-1.11\n0.43\n0.42\n-1.88\n-0.47\n1\n4368.59\n2894.00\n\n\nalpha[11]\n-1.55\n-1.53\n0.44\n0.42\n-2.29\n-0.86\n1\n3018.27\n2928.31\n\n\nalpha[12]\n-0.61\n-0.60\n0.30\n0.29\n-1.11\n-0.12\n1\n4928.00\n3034.51\n\n\nalpha[13]\n-0.41\n-0.42\n0.32\n0.33\n-0.94\n0.11\n1\n5022.83\n3042.18\n\n\nalpha[14]\n0.39\n0.39\n0.19\n0.19\n0.09\n0.70\n1\n4272.84\n2698.76\n\n\nalpha[15]\n-0.55\n-0.55\n0.33\n0.33\n-1.09\n-0.02\n1\n5306.70\n2752.71\n\n\nalpha[16]\n-0.13\n-0.13\n0.34\n0.33\n-0.69\n0.43\n1\n4565.86\n3175.21\n\n\nalpha[17]\n-0.75\n-0.74\n0.33\n0.34\n-1.30\n-0.21\n1\n5588.68\n2901.02\n\n\nalpha[18]\n-0.63\n-0.63\n0.26\n0.26\n-1.06\n-0.21\n1\n4901.21\n3163.20\n\n\nalpha[19]\n-0.51\n-0.50\n0.31\n0.30\n-1.01\n0.00\n1\n5023.43\n2604.77\n\n\nalpha[20]\n-0.48\n-0.47\n0.38\n0.37\n-1.09\n0.13\n1\n4690.89\n2820.28\n\n\nalpha[21]\n-0.51\n-0.50\n0.37\n0.37\n-1.10\n0.10\n1\n5851.03\n3094.53\n\n\nalpha[22]\n-0.97\n-0.95\n0.38\n0.37\n-1.63\n-0.36\n1\n4290.96\n2944.87\n\n\nalpha[23]\n-0.77\n-0.76\n0.39\n0.38\n-1.41\n-0.13\n1\n5175.73\n2697.31\n\n\nalpha[24]\n-1.17\n-1.16\n0.42\n0.41\n-1.91\n-0.51\n1\n3353.30\n2746.00\n\n\nalpha[25]\n-0.28\n-0.27\n0.23\n0.22\n-0.65\n0.10\n1\n4998.68\n2877.26\n\n\nalpha[26]\n-0.51\n-0.51\n0.38\n0.38\n-1.14\n0.10\n1\n5034.36\n2835.15\n\n\nalpha[27]\n-1.18\n-1.16\n0.31\n0.31\n-1.71\n-0.68\n1\n3588.76\n2832.48\n\n\nalpha[28]\n-0.97\n-0.96\n0.28\n0.27\n-1.42\n-0.53\n1\n4554.07\n3015.25\n\n\nalpha[29]\n-0.80\n-0.79\n0.31\n0.30\n-1.35\n-0.29\n1\n5420.33\n3009.07\n\n\nalpha[30]\n-0.14\n-0.14\n0.23\n0.24\n-0.52\n0.25\n1\n4828.89\n2779.67\n\n\nalpha[31]\n-0.30\n-0.30\n0.30\n0.30\n-0.80\n0.19\n1\n4492.81\n2882.42\n\n\nalpha[32]\n-0.99\n-0.98\n0.37\n0.37\n-1.60\n-0.41\n1\n4138.13\n2786.02\n\n\nalpha[33]\n-0.43\n-0.44\n0.37\n0.37\n-1.04\n0.20\n1\n5927.34\n2772.12\n\n\nalpha[34]\n0.27\n0.27\n0.30\n0.30\n-0.20\n0.75\n1\n3855.09\n2710.54\n\n\nalpha[35]\n-0.14\n-0.14\n0.25\n0.26\n-0.55\n0.27\n1\n5081.71\n2674.78\n\n\nalpha[36]\n-0.59\n-0.58\n0.36\n0.35\n-1.19\n0.00\n1\n5303.17\n2926.50\n\n\nalpha[37]\n-0.22\n-0.22\n0.38\n0.39\n-0.83\n0.40\n1\n4751.87\n2897.66\n\n\nalpha[38]\n-0.72\n-0.71\n0.39\n0.38\n-1.36\n-0.09\n1\n4740.14\n2733.12\n\n\nalpha[39]\n-0.21\n-0.21\n0.31\n0.32\n-0.72\n0.31\n1\n5094.55\n2923.13\n\n\nalpha[40]\n-0.26\n-0.27\n0.27\n0.27\n-0.70\n0.17\n1\n4543.77\n2850.07\n\n\nalpha[41]\n-0.20\n-0.20\n0.32\n0.32\n-0.71\n0.32\n1\n5230.39\n2965.57\n\n\nalpha[42]\n-0.24\n-0.25\n0.40\n0.40\n-0.89\n0.41\n1\n4795.85\n3030.71\n\n\nalpha[43]\n-0.05\n-0.05\n0.26\n0.25\n-0.48\n0.39\n1\n4572.40\n2946.05\n\n\nalpha[44]\n-0.96\n-0.95\n0.34\n0.34\n-1.52\n-0.42\n1\n4358.83\n3040.46\n\n\nalpha[45]\n-0.65\n-0.64\n0.29\n0.28\n-1.12\n-0.19\n1\n5336.34\n3025.28\n\n\nalpha[46]\n0.00\n0.00\n0.20\n0.20\n-0.33\n0.32\n1\n4898.06\n3029.75\n\n\nalpha[47]\n-0.34\n-0.35\n0.37\n0.36\n-0.94\n0.28\n1\n5311.82\n2831.54\n\n\nalpha[48]\n-0.07\n-0.08\n0.27\n0.27\n-0.51\n0.37\n1\n4748.32\n3088.37\n\n\nalpha[49]\n-0.86\n-0.84\n0.49\n0.47\n-1.69\n-0.08\n1\n4257.04\n2652.86\n\n\nalpha[50]\n-0.31\n-0.31\n0.34\n0.33\n-0.86\n0.25\n1\n5365.77\n3016.06\n\n\nalpha[51]\n-0.27\n-0.27\n0.27\n0.27\n-0.73\n0.17\n1\n5042.39\n3060.42\n\n\nalpha[52]\n-0.29\n-0.29\n0.23\n0.23\n-0.67\n0.09\n1\n4916.25\n3063.67\n\n\nalpha[53]\n-0.42\n-0.42\n0.35\n0.35\n-0.99\n0.15\n1\n4921.47\n2725.03\n\n\nalpha[54]\n-0.53\n-0.52\n0.52\n0.50\n-1.39\n0.32\n1\n4980.78\n2793.38\n\n\nalpha[55]\n-0.78\n-0.77\n0.46\n0.44\n-1.52\n-0.06\n1\n4503.41\n2852.82\n\n\nalpha[56]\n0.10\n0.10\n0.27\n0.27\n-0.34\n0.54\n1\n4641.96\n2823.71\n\n\nalpha[57]\n-1.08\n-1.07\n0.34\n0.33\n-1.65\n-0.55\n1\n4487.25\n2898.18\n\n\nalpha[58]\n-0.30\n-0.30\n0.29\n0.29\n-0.78\n0.18\n1\n4732.41\n2780.00\n\n\nalpha[59]\n-1.00\n-0.98\n0.43\n0.42\n-1.75\n-0.33\n1\n3924.03\n2582.82\n\n\nalpha[60]\n-0.99\n-0.97\n0.32\n0.32\n-1.54\n-0.48\n1\n4781.81\n2582.86\n\n\nalpha[61]\n-1.06\n-1.06\n0.30\n0.29\n-1.55\n-0.58\n1\n4446.91\n2615.09\n\n\n\n\n\nLos diagnósticos no apuntan a ningún problema, y obtenemos estimaciones tanto para los parámetros poblacionales como para los parámetros por distrito.\nVeamos cómo se ven las estimaciones crudas (proporción de uso de anticonceptivos en cada distrito) contra las estimaciones de nuestro modelo jerárquico.\n\nprobs_1 &lt;- ajuste_1_bangladesh$draws(\"prob_distrito\", format = \"df\") |&gt; \n  as_tibble() |&gt; pivot_longer(cols = starts_with(\"prob\"), names_to = \"variable\") |&gt;\n  separate(variable, sep = \"[\\\\[\\\\]]\", into = c(\"variable\", \"district\"), \n           extra = \"drop\", convert = TRUE)  |&gt; \n  group_by(district) |&gt; summarise(media = mean(value),\n                                  q5 = quantile(value, 0.05),\n                                  q95 = quantile(value, 0.95)) \nresumen_1 &lt;- bangladesh |&gt; group_by(district) |&gt; \n  summarise(prop_cruda = mean(use.contraception), n = n()) |&gt; \n  mutate(district = as.integer(district))\nprobs_1 |&gt; left_join(resumen_1) |&gt; \n  ggplot(aes(x = district)) +\n  geom_point(aes(y = media), color = \"red\") +\n  geom_linerange(aes(ymin = q5, ymax = q95), color = \"red\") +\n    geom_point(aes(y = prop_cruda, size = n), color = \"black\", alpha = 0.2) \n\n\n\n\n\n\n\n\nObservaciones: - Nótese que cuando la muestra de un distrito es chica, la cantidad de encogimiento es grande (el estimador crudo está cercano de nuestro estimador jerárquico si la muestra es grande). El caso extremo es el distrito 53, donde tenemos muestra de 0. En ese caso, usamos la inicial ajustada para producir estimaciones de la posterior - Adicionalmente, cuando la muestra es chica en un distrito, tenemos también más incertidumbre en la estimación de la proporción de uso de anticonceptivos. - Examina por ejemplo el distrito 11: obtuvimos 0 casos de usos de anticonceptivos, y es una mala estimación de esta proporción. El estimador del modelo jerárquico es de los más bajos, pero se encoge hacia la media poblacional.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html#agregando-covariables",
    "href": "09-modelos-jerarquicos.html#agregando-covariables",
    "title": "9  Modelos jerárquicos",
    "section": "9.4 Agregando covariables",
    "text": "9.4 Agregando covariables\nConsideremos ahora la variable de urbano-rural. Incluiremos esta variable también, considerando que su efecto puede variar por distrito:\n\\[\n\\begin{align}\nC_i &\\sim \\text{Bernoulli}(p_i)\\\\\n\\textrm{logit}(p_i) &= \\alpha_{D[i]} + \\beta_{D[i]} U_i \\\\\n\\alpha_j &\\sim N(\\bar{\\alpha},\\sigma_{\\alpha}) \\\\\n\\beta_j &\\sim N(\\bar{\\beta},\\sigma_{ \\beta}) \\\\\n\\bar{\\alpha}, \\bar{\\beta}  &\\sim N(0, 1)\\\\\n\\sigma_{\\alpha}, \\sigma_{\\beta} &\\sim N^+(0, 1) \\\\\n\\end{align}\n\\] Que implementado en stan puede quedar como:\n\nmod_2_bangladesh &lt;- cmdstan_model(\"./src/bangladesh-2.stan\")\nprint(mod_2_bangladesh)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; N_d;\n  array[N]  int ac_uso;\n  array[N]  int distrito;\n  vector[N] urbano;\n}\n\nparameters {\n  real alpha_bar;\n  real beta_bar;\n  vector[N_d] alpha;\n  vector[N_d] beta;\n  real &lt;lower=0&gt; sigma_alpha;\n  real &lt;lower=0&gt; sigma_beta;\n}\n\ntransformed parameters {\n\n}\n\nmodel {\n  // partes no determinísticas\n  ac_uso ~ bernoulli_logit(alpha[distrito] + beta[distrito] .* urbano);\n  alpha ~ normal(alpha_bar, sigma_alpha);\n  beta ~ normal(beta_bar, sigma_beta);\n  // parámetros poblacionales\n  alpha_bar ~ normal(0, 1);\n  beta_bar ~ normal(0, 1);\n  sigma_alpha ~ normal(0, 1);\n  sigma_beta ~ normal(0, 1);\n}\n\n\n\ndatos_lst &lt;- list(\n  ac_uso = bangladesh$use.contraception,\n  distrito = as.integer(bangladesh$district),\n  urbano = bangladesh$urban,\n  N = nrow(bangladesh),\n  N_d = 61\n)\najuste_2_bangladesh &lt;- mod_2_bangladesh$sample(data = datos_lst,\n                                               refresh = 1000, seed = 9394)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/tmp/Rtmpzi9xDb/model-2c8432361f74.stan', line 25, column 2 to column 41)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 3.5 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 4.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 4.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 3.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 3.7 seconds.\nTotal execution time: 15.1 seconds.\n\n\nWarning: 3 of 4 chains had an E-BFMI less than 0.3.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nY encontramos divergencias en el ajuste. Veamos los tamaños efectivos de muestra y los valores rhat:\n\najuste_2_bangladesh$summary(c(\"alpha_bar\", \"beta_bar\", \"sigma_alpha\", \"sigma_beta\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nalpha_bar\n-0.70\n-0.70\n0.09\n0.08\n-0.84\n-0.56\n1.00\n2616.28\n2472.85\n\n\nbeta_bar\n0.61\n0.62\n0.15\n0.15\n0.36\n0.86\n1.00\n1478.92\n2125.29\n\n\nsigma_alpha\n0.49\n0.48\n0.09\n0.09\n0.34\n0.65\n1.01\n772.58\n1218.47\n\n\nsigma_beta\n0.59\n0.58\n0.20\n0.21\n0.28\n0.95\n1.05\n64.80\n84.57\n\n\n\n\n\nAunque los valores de rhat no presentan problema, vemos que los tamaños efectivos de muestra para las desviaciones estándar poblacionales son malos (especialmente para el parámetro asociado a \\(\\beta\\)). Las trazas indican que quizá el problema no es muy grave, pero las cadenas muestran cierta heterogeneidad y autocorrelación alta:\n\nlibrary(bayesplot)\najuste_2_bangladesh$draws(c(\"sigma_beta\")) |&gt; \n  mcmc_trace()\n\n\n\n\n\n\n\n\nAunque quizá en este ejemplo es posible correr más iteraciones y obtener resultados más confiables, en estos casos es mejor diagnosticar el problema y corregirlo: obtendremos mejores estimaciones de manera más rápida.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html#parametrización-no-centrada",
    "href": "09-modelos-jerarquicos.html#parametrización-no-centrada",
    "title": "9  Modelos jerárquicos",
    "section": "9.5 Parametrización no centrada",
    "text": "9.5 Parametrización no centrada\nEl problema que ocurre en este modelo es uno que aparece con cierta frecuencia en modelos jerárquicos, y está relacionado con el embudo de Neal que vimos al final de la sección anterior.\nEn nuestro ejemplo \\(\\beta_j\\) tienen una inicial que depende de parámetros \\(N(\\beta_0,\\sigma_{\\beta})\\). Cuando \\(\\sigma_{\\beta}\\) es chica, esperamos que haya poca variación en las \\(\\beta_j\\), y cuando es grande, por el contrario, esperamos que haya mucha variación. Esto produce una especie de embudo de Neal:\n\nsims_beta &lt;- ajuste_2_bangladesh$draws(c(\"beta\", \"sigma_beta\"), format = \"df\")\ndiagnosticos_tbl &lt;- ajuste_2_bangladesh$sampler_diagnostics(format = \"df\")\nsims_beta &lt;- left_join(sims_beta, diagnosticos_tbl)\n\nJoining with `by = join_by(.chain, .iteration, .draw)`\n\n\nPodemos examinar gráficas de pares para ver donde aparece el problema: efectivamente, ocurre para valores chicos de \\(\\sigma\\).\n\nsims_beta |&gt; \n  ggplot(aes(y = log(sigma_beta), x = `beta[1]`, size = factor(divergent__),\n               colour = factor(divergent__))) + geom_point() +\n  ylab(\"log sigma_beta\") + xlab(\"beta\")\n\n\n\n\n\n\n\n\nPara corregir este problema (en el mejor de los casos ineficiencia), podemos usar el mismo truco que vimos al final de la sección anterior. En lugar de escribir \\[\\alpha_j = N(\\bar{\\alpha}, \\sigma_{\\alpha})\\] Definimos los valores \\(z_j\\) como \\(z_j\\sim N(0,1)\\) y escribimos \\[\\alpha_j = \\bar{\\alpha} + \\sigma_{\\alpha} z_j\\] Y lo mismo para el parámetro \\(\\beta\\). Se trata exactamente del mismo modelo, pero está parametrizado de manera distinta.\nNuestro modelo reparametrizado se vería como sigue:\n\nmod_3_bangladesh &lt;- cmdstan_model(\"./src/bangladesh-3.stan\")\nprint(mod_3_bangladesh)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; N_d;\n  array[N]  int ac_uso;\n  array[N]  int distrito;\n  vector[N] urbano;\n}\n\nparameters {\n  real alpha_bar;\n  real beta_bar;\n  vector[N_d] z_alpha;\n  vector[N_d] z_beta;\n  real &lt;lower=0&gt; sigma_alpha;\n  real &lt;lower=0&gt; sigma_beta;\n}\n\ntransformed parameters {\n  vector[N_d] alpha;\n  vector[N_d] beta;\n\n  alpha = alpha_bar + sigma_alpha * z_alpha;\n  beta = beta_bar + sigma_beta * z_beta;\n}\n\nmodel {\n  // partes no determinísticas\n  ac_uso ~ bernoulli_logit(alpha[distrito] + beta[distrito] .* urbano);\n  z_alpha ~ normal(0, 1);\n  z_beta ~ normal(0, 1);\n  // parámetros poblacionales\n  alpha_bar ~ normal(0, 1);\n  beta_bar ~ normal(0, 1);\n  sigma_alpha ~ normal(0, 1);\n  sigma_beta ~ normal(0, 1);\n}\n\ngenerated quantities {\n  vector[N_d] prob_distrito_urbano;\n  vector[N_d] prob_distrito_rural;\n\n  for (i in 1:N_d) {\n    prob_distrito_urbano[i] = inv_logit(alpha[i] + beta[i]);\n    prob_distrito_rural[i] = inv_logit(alpha[i]);\n  }\n  // Simular de a priori poblacional\n  vector[2] beta_sim;\n  beta_sim[1] = normal_rng(alpha_bar, sigma_alpha);\n  beta_sim[2] = normal_rng(beta_bar, sigma_beta);\n}\n\n\n\najuste_3_bangladesh &lt;- mod_3_bangladesh$sample(data = datos_lst,\n                                               refresh = 1000, seed = 9394)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 3.3 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 3.4 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 3.5 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 3.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 3.4 seconds.\nTotal execution time: 14.2 seconds.\n\n\nEl resultado es mejor y logramos mejorar todos los diagnósticos:\n\najuste_3_bangladesh$summary(c(\"alpha_bar\", \"beta_bar\", \"sigma_alpha\", \"sigma_beta\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nalpha_bar\n-0.70\n-0.70\n0.09\n0.09\n-0.85\n-0.55\n1\n1769.19\n2432.45\n\n\nbeta_bar\n0.62\n0.62\n0.15\n0.15\n0.36\n0.87\n1\n2488.90\n2467.53\n\n\nsigma_alpha\n0.49\n0.48\n0.09\n0.08\n0.36\n0.64\n1\n1287.18\n2311.66\n\n\nsigma_beta\n0.57\n0.57\n0.21\n0.19\n0.23\n0.92\n1\n735.25\n821.83\n\n\n\n\n\n\nmcmc_trace(ajuste_3_bangladesh$draws(c(\"sigma_beta\")))\n\n\n\n\n\n\n\n\nAhora podemos considerar el efecto de la variable urbano rural por distrito, donde vemos otra vez el efecto de agregación parcial, aunque esta vez el encogimiento es hacia la media de urbano y rural respectivamente:\n\nprobs_1 &lt;- ajuste_3_bangladesh$draws(c(\"prob_distrito_urbano\", \"prob_distrito_rural\"), \n                                     format = \"df\") |&gt; \n  as_tibble() |&gt; pivot_longer(cols = starts_with(\"prob\"), names_to = \"variable\") |&gt;\n  mutate(tipo = ifelse(str_detect(variable, \"urbano\"), \"urbano\", \"rural\")) |&gt; \n  separate(variable, sep = \"[\\\\[\\\\]]\", into = c(\"variable\", \"district\"), \n           extra = \"drop\", convert = TRUE)  |&gt; \n  group_by(district, tipo) |&gt; summarise(media = mean(value),\n                                  q5 = quantile(value, 0.05),\n                                  q95 = quantile(value, 0.95)) \nresumen_1 &lt;- bangladesh |&gt;\n  mutate(tipo = ifelse(urban == 1, \"urbano\", \"rural\")) |&gt; \n  mutate(tipo = factor(tipo, levels = c(\"urbano\", \"rural\"))) |&gt; \n  group_by(district, tipo, .drop = FALSE) |&gt; \n  summarise(prop_cruda = mean(use.contraception), n = n()) |&gt; \n  mutate(district = as.integer(district))\ngraf_1 &lt;- probs_1 |&gt; left_join(resumen_1) |&gt;\n  ggplot(aes(x = district)) +\n  geom_hline(yintercept = 0.5, linetype = 2) +\n  geom_point(aes(y = media), color = \"red\") +\n  geom_linerange(aes(ymin = q5, ymax = q95), color = \"red\") +\n    geom_point(aes(y = prop_cruda, size = n), color = \"black\", alpha = 0.2) +\n  facet_wrap(~tipo, nrow = 2)\ngraf_1\n\n\n\n\n\n\n\n\nObservaciones: - Nótese que generalmente tenemos muestras más chicos en zonas urbanas, y por eso vemos que hay más incertidumbre/variabilidad en las estimaciones urbanas. - Sin embargo, vemos que en general la variable urbana influye en el uso de anticonceptivos, aunque tenemos incertidumbre considerable en las estimaciones de las zonas urbanas de los distritos (menos muestra).\nPodemos también comparar más directamente cómo cambia la probabilidad de zonas urbanas a rurales dentro de cada distrito:\n\nprobs_1 |&gt; \n  select(-q5, -q95) |&gt;\n  pivot_wider(names_from = tipo, values_from = media) |&gt; \n  ggplot(aes(x = urbano, y = rural)) +\n  geom_abline(intercept = 0, slope = 1, linetype = 2) +\n  geom_point(colour = \"red\") \n\n\n\n\n\n\n\n\nNótese que vemos aquí también la diferencia dentro de distritos entre zonas urbanas y rurales. Las medias posteriores en general están por debajo de la identidad. Adicionalmente, hay correlación dentro de distritos entre las tasas de uso de anticonceptivos en zonas urbanas y rurales. Esto se debe, desde el punto de vista del modelo, a correlación entre el coeficiente \\(\\beta_{1,i}\\) común al efecto de urbano y rural: urbano es \\(\\beta_{1,i} + \\beta_{2,i}\\) y rural \\(\\beta_{1,i}\\), y esto se debe a que \\(\\beta_{1,i}\\) y \\(\\beta_{2,i}\\) se extraen de iniciales independientes.\nEs natural entonces observar una correlación positiva entre los dos siguientes coeficientes, en donde simulamos de las distribuciones poblacionales “nuevos” distritos:\n\najuste_3_bangladesh$draws(c(\"beta_sim\"), format = \"df\") |&gt; \n  ggplot(aes(y = `beta_sim[1]`, x = `beta_sim[1]` + `beta_sim[2]`)) +\n  geom_point(alpha = 0.2) + xlab(\"coef_urbano\") + ylab(\"coef_rural\") +\n  geom_abline(intercept = 0, slope = 1, linetype = 2) +\n  labs(subtitle = \"Correlación poblacional entre coeficientes\")\n\n\n\n\n\n\n\n\nEsta última observación sugiere que todavía podemos mejorar nuestras estimaciones: el “encogimiento” en las dos dimensiones debe estar correlacionado dentro de los distritos. En este ejemplo, estamos dejando de utilizar información que está en los datos. Si observamos que el uso de anticonceptivos en una zona urbana de el distrito A tiene un valor dado, esto nos da información acerca del uso de anticonceptivos en la zona rural del distrito A. Veremos ahora cómo podemos aprovechar más eficientemente la información para hacer mejor estimaciones.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "09-modelos-jerarquicos.html#variables-correlacionadas",
    "href": "09-modelos-jerarquicos.html#variables-correlacionadas",
    "title": "9  Modelos jerárquicos",
    "section": "9.6 Variables correlacionadas",
    "text": "9.6 Variables correlacionadas\nEn nuestro ejemplo anterior, observamos que existe correlación entre las tasas de uso de anticonceptivos en zonas urbanas y rurales a lo largo de los distritos. En términos de nuestro modelo, los coeficientes \\(\\alpha_j +\\beta_j\\) están correlacionados con los coeficientes \\(\\alpha_j\\). Podemos hacer la estimación más eficiente modelando explícitamente la correlación en la inicial poblacional. Con dos coeficientes podríamos modelar la población con una distribución normal biivariada.\nCambiamos nuestra notación por conveniencia: ahora \\(\\beta\\) es un vector que incluye la ordenada al origen \\(\\beta_1\\) y la pendiente \\(\\beta_2\\).\n\\[\\beta \\sim NMV(\\bar{\\beta}, \\Sigma)\\] adicionalmente a \\(\\bar{\\beta} \\sim N(0,I)\\) y \\(\\sigma_1, \\sigma_2 \\sim N^{+}(0,1)\\).\nPodemos pensar en la matriz de covarianzas \\(\\Sigma\\) como dada en dos partes: \\(\\Omega\\), una matriz de correlaciones, y dos deviaciones estándar \\(\\sigma\\), de modo que\n\\[\\Sigma = \\textrm{diag}(\\sigma)\\,\\Omega\\, \\textrm{diag}(\\sigma)\\]\nEn nuestro ejemplo anterior teníamos \\(\\Omega = I\\).\nLa pregunta ahora es qué distribución inicial le podemos dar a la matriz \\(\\Omega\\) de correlaciones. Aún cuando en este caso bivariado sólo tenemos que dar una inicial a la correlación y es posible definir alguna distribución inicial para \\(\\rho\\in(-1,1)\\), en general el problema de poner una distribución sobre matrices de correlación no es simple. Usamos la llamada distribución LKJ, \\[\\Omega \\sim \\textrm{LKJ}(\\eta)\\] con \\(\\eta&gt;0\\). \\(\\eta\\) indica qué tan concentrada está la distribución en correlaciones cercanas a 0, o cuánta dispersión esperamos:\n\nmodelo_str &lt;- \"\ndata{}\nparameters {}\nmodel {}\ngenerated quantities {\n  matrix[2,2] Omega_02;\n  matrix[2,2] Omega_2;\n  matrix[2,2] Omega_20;\n  Omega_02 = lkj_corr_rng(2, 0.2);\n  Omega_2 = lkj_corr_rng(2, 2);\n  Omega_20 = lkj_corr_rng(2, 20);\n}\n\"\narchivo &lt;-file(\"./src/ejemplo_lkj.stan\")\nwriteLines(modelo_str, archivo)\nclose(archivo)\nsim_lkj &lt;- cmdstanr::cmdstan_model(\"./src/ejemplo_lkj.stan\")\nsalida &lt;- sim_lkj$sample(fixed_param = TRUE, iter_sampling = 1000,\n                         show_messages = FALSE)\nsims &lt;- salida$draws(format = \"df\") |&gt; \n  select(contains(\"[1,2]\")) |&gt; \n  pivot_longer(cols = everything(), names_to = \"variable\", values_to = \"valor\") \nsims |&gt; \nggplot(aes(x = valor)) +\n  geom_histogram() +\n  facet_wrap(~variable)\n\n\n\n\n\n\n\n\nAhora intentamos ajustar un modelo con esta nueva distribución poblacional inicial:\n\nmod_4_bangladesh &lt;- cmdstan_model(\"./src/bangladesh-4.stan\")\nprint(mod_4_bangladesh)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; N_d;\n  array[N]  int ac_uso;\n  array[N]  int distrito;\n  vector[N] urbano;\n}\n\ntransformed data {\n  matrix[N, 2] x;\n  for (n in 1:N) {\n    x[n,1] = 1;\n    x[n,2] = urbano[n];\n  }\n}\n\nparameters {\n  vector[2] beta_bar;\n  array[N_d] vector[2] beta;\n  vector&lt;lower=0&gt;[2] sigma;\n  corr_matrix[2] Omega;\n}\n\ntransformed parameters {\n  cov_matrix[2] Sigma;\n\n  Sigma = quad_form_diag(Omega, sigma);\n}\n\nmodel {\n  for(n in 1:N){\n      ac_uso[n] ~ bernoulli_logit(x[n] * beta[distrito[n]]);\n  }\n  beta ~ multi_normal(beta_bar, Sigma);\n  // parámetros poblacionales\n  beta_bar ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  Omega ~ lkj_corr(4);\n}\n\ngenerated quantities {\n  vector[N_d] prob_distrito_urbano;\n  vector[N_d] prob_distrito_rural;\n\n  for (i in 1:N_d) {\n    prob_distrito_urbano[i] = inv_logit(beta[i][1] + beta[i][2]);\n    prob_distrito_rural[i] = inv_logit(beta[i][1]);\n  }\n    // Simular de a priori poblacional\n  vector[2] beta_sim;\n  beta_sim = multi_normal_rng(beta_bar, Sigma);\n}\n\n\n\najuste_4_bangladesh &lt;- mod_4_bangladesh$sample(data = datos_lst,\n  refresh = 1000, init = 0.1, step_size = 0.1, parallel_chains = 4, seed = 9394)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 23.8 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 25.8 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 26.8 seconds.\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 27.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 26.0 seconds.\nTotal execution time: 28.0 seconds.\n\n\nWarning: 3 of 4000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nWarning: 1 of 4 chains had an E-BFMI less than 0.3.\nSee https://mc-stan.org/misc/warnings for details.\n\n\n\najuste_4_bangladesh$summary(c(\"beta_bar\", \"sigma\", \"Omega\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nbeta_bar[1]\n-0.70\n-0.70\n0.10\n0.10\n-0.86\n-0.55\n1.00\n3069.54\n3170.06\n\n\nbeta_bar[2]\n0.68\n0.68\n0.17\n0.17\n0.41\n0.95\n1.00\n2091.64\n3110.73\n\n\nsigma[1]\n0.55\n0.55\n0.09\n0.09\n0.40\n0.71\n1.01\n954.40\n1016.20\n\n\nsigma[2]\n0.73\n0.73\n0.20\n0.19\n0.42\n1.06\n1.02\n322.06\n216.78\n\n\nOmega[1,1]\n1.00\n1.00\n0.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\nOmega[2,1]\n-0.55\n-0.57\n0.18\n0.17\n-0.80\n-0.22\n1.01\n870.18\n1931.22\n\n\nOmega[1,2]\n-0.55\n-0.57\n0.18\n0.17\n-0.80\n-0.22\n1.01\n870.18\n1931.22\n\n\nOmega[2,2]\n1.00\n1.00\n0.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\n\n\n\nAunque no tiene problemas graves de divergencia, el ajuste es lento como vemos en el tamaño efectivo bajo de las correlaciones entre la constante \\(\\beta_1\\) y el coeficiente de la variable urbana \\(\\beta_2\\). Nota: observa que los coeficientes \\(\\beta_1\\) y \\(\\beta_2\\) son negativamente correlacionados. Sin embargo, la correlación entre \\(\\beta_1 + \\beta_2\\) y \\(\\beta_1\\) es positiva como veremos más adelante.\nPodemos usar también una parametrización no centrada para este modelo. Observamos primero que si \\(\\Omega\\) es una matriz de correlaciones, entonces siempre podemos escribir su factorización de Cholesky, dada por \\(\\Omega = LL^T\\), donde \\(L\\) es una matriz triangular inferior. De esta forma, podemos escribir\n\\[\\Sigma = \\textrm{diag}(\\sigma)\\,LL^T\\, \\textrm{diag}(\\sigma)\\] De forma que el factor de Cholesky para \\(\\Sigma\\) es \\(\\textrm{diag}(\\sigma)\\,L\\).\nAhora tomemos \\(Z\\sim NMV(0,I)\\) y definamos \\(X = \\textrm{diag}(\\sigma)\\,L\\,Z\\). Entonces se puede demostrar que \\(X\\sim NMV(0,\\Sigma)\\). De esta forma, si \\(\\beta \\sim NMV(\\bar{\\beta}, \\Sigma)\\), podemos escribir \\[\\beta = \\bar{\\beta} + \\textrm{diag}(\\sigma)\\,L\\,Z.\\] Nótese que el caso de una dimensión, para centrar multiplicábamos por la desviación estándar. El análogo en el caso multivariado es el factor de Cholesky de la covarianza, que es una especie de “raíz” de la covarianza.\n\nmod_5_bangladesh &lt;- cmdstan_model(\"./src/bangladesh-5.stan\")\nprint(mod_5_bangladesh)\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0&gt; N_d;\n  array[N]  int ac_uso;\n  array[N]  int distrito;\n  vector[N] urbano;\n}\n\ntransformed data {\n  matrix[N, 2] x;\n  for (n in 1:N) {\n    x[n,1] = 1;\n    x[n,2] = urbano[n];\n  }\n}\n\nparameters {\n  vector[2] beta_bar;\n  vector&lt;lower=0&gt;[2] sigma;\n  cholesky_factor_corr[2] L_Omega;\n  matrix[2, N_d] z;\n}\n\ntransformed parameters {\n  cov_matrix[2] Sigma;\n  corr_matrix[2] Omega;\n  matrix[2, N_d] beta;\n\n  // parametrización no centrada:\n  beta = rep_matrix(beta_bar, N_d) + diag_pre_multiply(sigma, L_Omega) * z;\n\n  // Esto solo para recordar dónde están covarianzas y correlaciones:\n  // no son necesarias\n  Omega = L_Omega * L_Omega';\n  Sigma = quad_form_diag(Omega, sigma);\n\n}\n\nmodel {\n  for(n in 1:N){\n      ac_uso[n] ~ bernoulli_logit( x[n] * beta[,distrito[n]]);\n  }\n  to_vector(z) ~ std_normal();\n  // parámetros poblacionales\n  beta_bar ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  // La siguente línea es para tener Omega ~ lkj_corr(4)\n  L_Omega ~ lkj_corr_cholesky(4);\n}\n\ngenerated quantities {\n  vector[N_d] prob_distrito_urbano;\n  vector[N_d] prob_distrito_rural;\n\n  for (i in 1:N_d) {\n    prob_distrito_urbano[i] = inv_logit(beta[1,i] + beta[2,i]);\n    prob_distrito_rural[i] = inv_logit(beta[1,i]);\n  }\n\n  // Simular de a priori poblacional\n  vector[2] beta_sim;\n  beta_sim = multi_normal_rng(beta_bar, Sigma);\n\n}\n\n\n\najuste_5_bangladesh &lt;- mod_5_bangladesh$sample(data = datos_lst,\n  refresh = 1000, init = 0.1, step_size = 0.1, parallel_chains = 4, seed = 9394)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 17.9 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 18.2 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 18.3 seconds.\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 18.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 18.2 seconds.\nTotal execution time: 18.9 seconds.\n\n\n\najuste_5_bangladesh$summary(c(\"beta_bar\", \"sigma\", \"Omega\")) |&gt; \n  knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\n\nbeta_bar[1]\n-0.70\n-0.70\n0.10\n0.10\n-0.88\n-0.54\n1\n1642.73\n1803.54\n\n\nbeta_bar[2]\n0.68\n0.68\n0.17\n0.16\n0.42\n0.97\n1\n1827.79\n2232.97\n\n\nsigma[1]\n0.56\n0.56\n0.10\n0.09\n0.42\n0.73\n1\n1445.85\n2290.00\n\n\nsigma[2]\n0.76\n0.76\n0.20\n0.20\n0.45\n1.10\n1\n1132.28\n1425.00\n\n\nOmega[1,1]\n1.00\n1.00\n0.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\nOmega[2,1]\n-0.55\n-0.58\n0.18\n0.17\n-0.80\n-0.21\n1\n1500.51\n2393.10\n\n\nOmega[1,2]\n-0.55\n-0.58\n0.18\n0.17\n-0.80\n-0.21\n1\n1500.51\n2393.10\n\n\nOmega[2,2]\n1.00\n1.00\n0.00\n0.00\n1.00\n1.00\nNA\nNA\nNA\n\n\n\n\n\nEste resultado es superior en convergencia al anterior.\nAhora podemos comparar nuestra estimaciones del efecto de la variable urbana/rural en cada distrito, considerando el modelo con correlación y sin correlación:\n\nprobs_corr &lt;- ajuste_5_bangladesh$draws(c(\"prob_distrito_urbano\", \"prob_distrito_rural\"), \n                                     format = \"df\") |&gt; \n  as_tibble() |&gt; pivot_longer(cols = starts_with(\"prob\"), names_to = \"variable\") |&gt;\n  mutate(tipo = ifelse(str_detect(variable, \"urbano\"), \"urbano\", \"rural\")) |&gt; \n  separate(variable, sep = \"[\\\\[\\\\]]\", into = c(\"variable\", \"district\"), \n           extra = \"drop\", convert = TRUE)  |&gt; \n  group_by(district, tipo) |&gt; summarise(media = mean(value),\n                                  q5 = quantile(value, 0.05),\n                                  q95 = quantile(value, 0.95)) \nresumen_corr &lt;- bangladesh |&gt;\n  mutate(tipo = ifelse(urban == 1, \"urbano\", \"rural\")) |&gt; \n  mutate(tipo = factor(tipo, levels = c(\"urbano\", \"rural\"))) |&gt; \n  group_by(district, tipo, .drop = FALSE) |&gt; \n  summarise(prop_cruda = mean(use.contraception), n = n()) |&gt; \n  mutate(district = as.integer(district))\ngraf_corr &lt;- probs_corr |&gt; left_join(resumen_corr) |&gt;\n  ggplot(aes(x = district)) +\n  geom_hline(yintercept = 0.5, linetype = 2) +\n  geom_point(aes(y = media), color = \"red\") +\n  geom_linerange(aes(ymin = q5, ymax = q95), color = \"red\") +\n    geom_point(aes(y = prop_cruda, size = n), color = \"black\", alpha = 0.2) +\n  facet_wrap(~tipo, nrow = 2)\ngraf_corr\n\n\n\n\n\n\n\n\nLas estimaciones son distintas comparando con el modelo sin correlación:\n\nprobs &lt;- bind_rows(probs_1 |&gt; mutate(modelo = \"Sin correlación\"),\n                   probs_corr |&gt; mutate(modelo = \"Con correlación\")) \nprobs |&gt; \n  select(-q5, -q95) |&gt;\n  pivot_wider(names_from = tipo, values_from = media) |&gt;\n  ggplot(aes(x = urbano, y = rural, label = district)) +\n  geom_abline(intercept = 0, slope = 1, linetype = 2) +\n  geom_text() +\n  facet_wrap(~modelo)\n\n\n\n\n\n\n\n\nEn el caso sin correlación, vimos que la asociación entre los coeficientes de urbano y rural se daban en parte por la forma del modelo, y el hecho de que utilizamos distribuciones poblacionales independientes a priori para cada coeficiente. Una vez que modelamos la correlación, vemos que este efecto estaba exagerado.\nY veamos ahora cómo están correlacionados los coeficientes de urbano y rural:\n\najuste_5_bangladesh$draws(c(\"beta_sim\"), format = \"df\") |&gt; \n  ggplot(aes(y = `beta_sim[1]`, x = `beta_sim[1]` + `beta_sim[2]`)) +\n  geom_point(alpha = 0.2) + xlab(\"coef_urbano\") + ylab(\"coef_rural\") +\n  geom_abline(intercept = 0, slope = 1, linetype = 2)\n\n\n\n\n\n\n\n\nY vemos que en realidad los datos no sugieren que existe una correlación alta entre los coeficientes, a pesar de la parametrización que usamos. Por eso observamos un patrón de encogimiento diferente en el modelo con correlaciones. Veamos un ejemplo:\n\nNotemos por ejemplo el distrito 11, que sólo tiene observaciones de regiones rurales, con un tamaño de muestra relativamente chico:\n\n\nresumen_corr |&gt; filter(district == 11)\n\n# A tibble: 2 × 4\n# Groups:   district [61]\n  district tipo   prop_cruda     n\n     &lt;int&gt; &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;\n1       11 urbano        NaN     0\n2       11 rural           0    21\n\n\n\nSu valor observado de uso de anticonceptivos es 0, muy baja, y naturalmente esperamos una estimación por arriba de cero, pero baja en la población de zonas rurales. Sin correlación, la estimación de zonas urbanas es considerablemente baja también.\nCon correlación, sin embargo, la estimación de urbano es considerablemente más alta, cercana a la media poblacional.\n\n\nprobs |&gt; filter(district == 11) |&gt; \n  arrange(tipo) |&gt; kable(digits = 3)\n\n\n\n\ndistrict\ntipo\nmedia\nq5\nq95\nmodelo\n\n\n\n\n11\nrural\n0.179\n0.086\n0.286\nSin correlación\n\n\n11\nrural\n0.159\n0.071\n0.264\nCon correlación\n\n\n11\nurbano\n0.299\n0.095\n0.570\nSin correlación\n\n\n11\nurbano\n0.440\n0.184\n0.724\nCon correlación\n\n\n\n\n\n\n\n\n\nAlbert, Jim. 2009. Bayesian computation with R. Dordrecht: Springer. http://www.springerlink.com/content/978-0-387-92298-0#section=15956&page=1.\n\n\nMcElreath, R. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. A Chapman & Hall libro. CRC Press. https://books.google.com.mx/books?id=Ie2vxQEACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Modelos jerárquicos</span>"
    ]
  },
  {
    "objectID": "13-exp-naturales.html",
    "href": "13-exp-naturales.html",
    "title": "10  Otros métodos para inferencia causal",
    "section": "",
    "text": "10.1 Intro: Variables instrumentales\nEn esta última parte veremos dos métodos que se basan en características particulares del supuesto proceso generador de datos o diagrama causal, que los hacen en algunos aspectos similares a conducir un experimento aleatorizado.\nEstos métodos requieren supuestos fuertes, no son de aplicabilidad general, pero es menos crítico construir un diagrama causal apropiado.\nEn el siglo XIX John Snow tenía la teoría de que algo en la calidad del suministro de agua estaba relacionado con la aparición de casos de cólera en Londres (que entonces era una epidemia).\nReconoció que tenía el problema de variables no observadas que abren puertas traseras: la calidad de agua que toman las personas (o por ejemplo en zonas de la ciudad) es diferente: en zonas más pobres en general la calidad del agua es mala, y también hay más muertes de cólera en lugares pobres.\nOtra variable de confusión podía ser el entonces llamado “miasma”: cosas malas en el aire que contaminan el agua y a las personas.\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n \n  node [shape = circle]\n    MiasmaPobreza\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n    PurezaAgua -&gt; Colera\n    MiasmaPobreza -&gt; Colera\n    MiasmaPobreza -&gt; PurezaAgua\n  {rank = same; PurezaAgua; Colera}\n}\n\", width = 200, height = 100)\nDado este diagrama, como hemos discutido, no podemos identificar el efecto causal de la calidad de suministro de agua en las muertes o infecciones de cólera: podría ser la “miasma” que contamina el agua y enferma a las personas (correlación no causal), por ejemplo, y no hay relación causal entre tomar agua contaminada y cólera.\nJohn Snow, sin embargo, que no creía en la teoría del miasma, investigó con detalle de dónde provenía el agua que tomaban en varias casas a lo largo de toda la ciudad. Lo que descubrió, en sus palabras es que:\nSi las distintas compañías de agua tiene distintos niveles de calidad de agua, podriamos expandir nuestro DAG a:\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n \n  node [shape = circle]\n    Miasma\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n    Comp -&gt; PurezaAgua -&gt; Colera\n    Miasma -&gt; PurezaAgua\n    Miasma -&gt; Colera\n  {rank = same; Comp; PurezaAgua; Colera}\n}\n\")\nTenemos entonces:\nLa conclusión de Snow es que desde el punto de vista de cólera y el sistema que nos interesa, la compañía de agua se comporta como si fuera asignada al azar: no hay ninguna variable relevente al problema que incida en qué compañía abastece a cada casa o zona. Como observó asociación entre compañía de agua y Cólera, concluyó correctamente que esto implicaba que la pureza del agua tenía un efecto causal en la propagación del cólera.\nLa idea de Snow se resumen así:\nLa tabla de Snow, tomada de Freedman (1991):\ntibble(comp = c(\"Southwark+Vauxhall\", \"Lambeth\", \"Resto\"),\n       casas = c(40046, 26107, 256423),\n       muertes_colera = c(1263, 98, 1422),\n       tasa_muertes_10milcasas = c(315, 37, 59)) |&gt; \nknitr::kable() |&gt; kable_paper()\n\n\n\n\ncomp\ncasas\nmuertes_colera\ntasa_muertes_10milcasas\n\n\n\n\nSouthwark+Vauxhall\n40046\n1263\n315\n\n\nLambeth\n26107\n98\n37\n\n\nResto\n256423\n1422\n59\nEsta diferencia grande muestra que la razón de la aparición de cólera tenía que ver con el agua que consumían las personas, considerando los supuestos de arriba. Para llegar a la conclusión de Snow, es necesario que se cumpla la estructura causal del diagrama de arriba.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Otros métodos para inferencia causal</span>"
    ]
  },
  {
    "objectID": "13-exp-naturales.html#intro-variables-instrumentales",
    "href": "13-exp-naturales.html#intro-variables-instrumentales",
    "title": "10  Otros métodos para inferencia causal",
    "section": "",
    "text": "En grandes partes de Londres, los suministros de agua de distintas compañías están organizados de forma compleja. Los tubos de cada compañía van por todas las calles de todas las zonas.\nLa decisión de qué compañía suministraba a cada casa generalmente se había tomado hace mucho, y los habitantes generalmente no lo decidían ni sabían que compañía de agua les correspondía.\nHabía casas muy cercanas, unas con una compañía y otras con otra.\n\n\n\n\n\nLa compañía que suministra a cada casa o zona es causa de la pureza de agua en cada casa.\nNo puede haber aristas directas entre compañía y cólera: el único efecto de compañía en cólera puede ser a través del agua que suministra.\nNo puede haber una arista de Miasma/Pobreza a Compañía, por la observación de Snow: la decisión de qué compañía suministraba a qué casa se había tomado mucho antes, y no tenía relación con pobreza, miasma actual ni cólera (que no existía cuando se tomaron esas decisiones)\n\n\n\n\nPor la gráfica, la asociación entre Compañía y Cólera es causal (no hay confusoras para Compañía y Cólera).\nSi esta relación existe, entonces por los supuestos, la Pureza de Agua tiene un efecto causal sobre Cólera.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Otros métodos para inferencia causal</span>"
    ]
  },
  {
    "objectID": "13-exp-naturales.html#variables-instrumentales",
    "href": "13-exp-naturales.html#variables-instrumentales",
    "title": "10  Otros métodos para inferencia causal",
    "section": "10.2 Variables instrumentales",
    "text": "10.2 Variables instrumentales\nEl diagrama básico que define una variable instrumental con el propósito de identificar el efecto causal de \\(T\\) sobre \\(Y\\) es el siguiente:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2]\n \n  node [shape = circle]\n    U\n  node [shape=plaintext]\n\n  edge [minlen = 3]\n    Z -&gt; T -&gt; Y\n    U-&gt; T\n    U-&gt; Y\n  {rank = same; Z;T; Y}\n}\n\", width= 200, height = 70)\n\n\n\n\n\n\n\n\n\n\n\n\nVariables instrumentales\n\n\n\nDecimos que \\(Z\\) es una variable instrumental para estimar el efecto causal de \\(T\\) sobre \\(Y\\) cuando:\n\n\\(Z\\) es una variable que influye en la asignación del tratamiento.\n\\(Z\\) está \\(d\\)-separada de \\(U\\).\n\\(Z\\) sólo influye en \\(Y\\) a través de \\(T\\) (restricción de exclusión)\n\n\n\n\nGeneralmente las últimas dos de estas hipótesis tienen que postularse basadas en conocimiento experto, ya que no es posible checarlas con datos.\nCon estrategias de condicionamiento es posible encontrar instrumentos potenciales en gráficas más complejas.\nEsta estrategia, como la veremos implementada, funciona suponiendo que los efectos del tratamiento y del instrumento son homogéneos sobre los individuos (no hay heterogeneidad en los efectos). Por ejemplo, si modelos lineales simples son apropiados. Más generalmente, y bajo ciertos supuestos, los estimadores de variables instrumentales son estimadores de un cierto tipo de efecto causal (por ejemplo, para tratamientos binarios, el efecto causal sobre los compliers, ver Morgan y Winship (2015)).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Otros métodos para inferencia causal</span>"
    ]
  },
  {
    "objectID": "13-exp-naturales.html#estimación-con-variables-instrumentales",
    "href": "13-exp-naturales.html#estimación-con-variables-instrumentales",
    "title": "10  Otros métodos para inferencia causal",
    "section": "10.3 Estimación con variables instrumentales",
    "text": "10.3 Estimación con variables instrumentales\nLa estimación de efectos causales con variables instrumentales depende de supuestos adicionales a los del cálculo-do, y su utilidad depende de qué tan fuerte es el instrumento (qué tan correlacionado está con el tratamiento).\nPrimero, hacemos una discusión para ver cómo esto puede funcionar. Lo más importante es notar que el efecto de \\(Z\\) sobre \\(Y\\) y el de \\(Z\\) sobre \\(T\\) son identificables y podemos calcularlos. El que nos interesa el efecto promedio de \\(T\\) sobre \\(Y\\). Supongamos que todos los modelos son lineales:\n\nSupongamos que cuando \\(Z\\) aumenta una unidad, \\(T\\) aumenta en \\(a\\) unidades,\nSupongamos que cuando \\(T\\) aumenta 1 unidad \\(Y\\) aumenta \\(b\\) unidades (este es el efecto causal que queremos calcular).\nEsto quiere decir que cuando \\(Z\\) aumenta una unidad, \\(Y\\) aumenta \\(c = ab\\) unidades.\nEl efecto causal de \\(T\\) sobre \\(Y\\) se puede calcular dividiendo \\(c/a\\) (que es igual a \\(b\\)), y estas dos cantidades están identificadas\n\nNótese que si \\(a=0\\), o es muy chico, este argumento no funciona (\\(Z\\) es un instrumento débil).\nVeremos un ejemplo simulado, y cómo construir un estimador estadístico en el caso lineal para estimar el efecto causal.\n\nsim_colera &lt;- function(n){\n  # se selecciona al azar la compañía\n  comp &lt;- sample(1:5, n, replace = TRUE)\n  contaminacion_comp &lt;- c(5, 5, 0.3, 0.2, 0)\n  # confusor\n  u &lt;- rnorm(n, 0, 1)\n  # confusor afecta a pureza y muertes\n  pureza &lt;- rnorm(n, contaminacion_comp[comp] +  2 * u, 1)\n  colera &lt;- rnorm(n, 3 * pureza +  2 * u, 1)\n  tibble(comp, pureza, colera) \n}\nset.seed(800)\ndatos_tbl &lt;- sim_colera(1000)\n\n\ndatos_tbl |&gt; head()\n\n# A tibble: 6 × 3\n   comp pureza colera\n  &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     3 -0.569  -3.73\n2     3  2.89   10.3 \n3     2  3.59    9.26\n4     2  4.59   12.4 \n5     4 -0.744  -2.88\n6     4 -4.23  -17.9 \n\n\nPodríamos construir un modelo generativo modelando una variable latente \\(U\\). Si embargo, es más simple definir un modelo estadístico como sigue:\n\nLas variables pureza y cólera son normales bivariadas con alguna correlación (producida por el confusor U).\nLa media de Pureza depende la Compañía, y el efecto promeido es el mismo para todas las unidades.\nLa media de Cólera depende de la pureza, y el efecto promedio es el mismo para todas las unidades.\n\nCon un modelo así podemos resolver el problema de estimar el efecto causal la variable instrumental.\nSin embargo, modelos de regresión simples no nos dan la respuesta correcta. Por ejemplo, sabemos que esta regresión es incorrecta (por el confusor):\n\nlm(colera~ pureza, datos_tbl) |&gt; broom::tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -0.739    0.0702     -10.5 1.27e-24\n2 pureza         3.38     0.0184     184.  0       \n\n\n\nlm(colera ~ pureza + factor(comp), datos_tbl) |&gt; broom::tidy()\n\n# A tibble: 6 × 5\n  term          estimate std.error statistic   p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    -4.02      0.137    -29.4   6.92e-137\n2 pureza          3.80      0.0187   203.    0        \n3 factor(comp)2   0.0447    0.139      0.322 7.47e-  1\n4 factor(comp)3   3.77      0.162     23.2   7.99e- 96\n5 factor(comp)4   3.92      0.164     23.9   4.03e-100\n6 factor(comp)5   4.14      0.166     24.9   5.35e-107\n\n\nY agregar la variable compañía empeora la situación. La razón es que al condicionar a pureza, abrimos un nuevo camino no causal entre compañía y la respuesta, y esta es capturada por esos coeficientes.\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1.9000\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /home/runner/.cmdstan/cmdstan-2.36.0\n\n\n- CmdStan version: 2.36.0\n\nmod_colera &lt;- cmdstan_model(\"./src/iv-ejemplo.stan\")\nprint(mod_colera)\n\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int compania;\n  vector[N] colera;\n  vector[N] pureza;\n}\n\ntransformed data {\n    array[N] vector[2] py;\n    for(i in 1:N){\n      py[i][1] = pureza[i];\n      py[i][2] = colera[i];\n    }\n}\n\nparameters {\n  vector[6] alpha;\n  real alpha_0;\n  real beta_0;\n  real beta_1;\n  corr_matrix[2] Omega;\n  vector&lt;lower=0&gt;[2] sigma;\n}\n\ntransformed parameters{\n  array[N] vector[2] media;\n  cov_matrix[2] S;\n\n  for(i in 1:N){\n    media[i][2] = beta_0 + beta_1 * pureza[i];\n    media[i][1] = alpha_0 + alpha[compania[i]];\n  }\n\n  S = quad_form_diag(Omega, sigma);\n}\n\nmodel {\n  py ~ multi_normal(media, S);\n  Omega ~ lkj_corr(2);\n  sigma ~ normal(0, 10);\n  alpha_0 ~ normal(0, 1);\n  beta_0 ~ normal(0, 1);\n  beta_1 ~ normal(0, 1);\n  alpha ~ normal(0, 300);\n}\n\ngenerated quantities{\n\n}\n\n\n\najuste &lt;- mod_colera$sample(\n  data = list(N = nrow(datos_tbl), \n                compania = datos_tbl$comp,\n                colera = datos_tbl$colera,\n                pureza = datos_tbl$pureza),\n  init = 0.01, step_size = 0.01,\n  parallel_chains = 4, iter_warmup = 500, iter_sampling = 1000\n)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 1500 [  0%]  (Warmup) \n\n\nChain 2 Iteration:    1 / 1500 [  0%]  (Warmup) \n\n\nChain 3 Iteration:    1 / 1500 [  0%]  (Warmup) \n\n\nChain 4 Iteration:    1 / 1500 [  0%]  (Warmup) \n\n\nChain 2 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 4 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 1 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 3 Iteration:  100 / 1500 [  6%]  (Warmup) \nChain 2 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 4 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 1 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 2 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 3 Iteration:  200 / 1500 [ 13%]  (Warmup) \nChain 4 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 2 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 1 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 3 Iteration:  300 / 1500 [ 20%]  (Warmup) \nChain 4 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 2 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 2 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 1 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 3 Iteration:  400 / 1500 [ 26%]  (Warmup) \nChain 4 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 4 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 2 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 1 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 1 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 3 Iteration:  500 / 1500 [ 33%]  (Warmup) \nChain 3 Iteration:  501 / 1500 [ 33%]  (Sampling) \nChain 4 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 2 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 1 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 3 Iteration:  600 / 1500 [ 40%]  (Sampling) \nChain 2 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 4 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 1 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 3 Iteration:  700 / 1500 [ 46%]  (Sampling) \nChain 2 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 3 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 4 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 1 Iteration:  800 / 1500 [ 53%]  (Sampling) \nChain 2 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 3 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 1 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 4 Iteration:  900 / 1500 [ 60%]  (Sampling) \nChain 2 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 3 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 1 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 4 Iteration: 1000 / 1500 [ 66%]  (Sampling) \nChain 2 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 3 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 1 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 4 Iteration: 1100 / 1500 [ 73%]  (Sampling) \nChain 2 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 3 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 1 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 4 Iteration: 1200 / 1500 [ 80%]  (Sampling) \nChain 2 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 3 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 1 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 2 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 3 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 2 finished in 73.1 seconds.\nChain 4 Iteration: 1300 / 1500 [ 86%]  (Sampling) \nChain 1 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 4 Iteration: 1400 / 1500 [ 93%]  (Sampling) \nChain 3 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 3 finished in 77.1 seconds.\nChain 1 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 1 finished in 78.8 seconds.\nChain 4 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 4 finished in 79.5 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 77.1 seconds.\nTotal execution time: 79.7 seconds.\n\n\n\najuste$summary(c(\"alpha\", \"beta_0\", \"beta_1\", \"sigma\", \"Omega\")) |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 14 × 4\n   variable       mean        q5     q95\n   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 alpha[1]    5.01       3.33     6.58 \n 2 alpha[2]    4.94       3.26     6.52 \n 3 alpha[3]    0.300     -1.37     1.88 \n 4 alpha[4]    0.260     -1.42     1.85 \n 5 alpha[5]   -0.00940   -1.69     1.59 \n 6 alpha[6]    8.04    -473.     496.   \n 7 beta_0      0.0604    -0.0944   0.223\n 8 beta_1      2.98       2.92     3.03 \n 9 sigma[1]    2.29       2.20     2.37 \n10 sigma[2]    2.31       2.18     2.44 \n11 Omega[1,1]  1          1        1    \n12 Omega[2,1]  0.810      0.785    0.835\n13 Omega[1,2]  0.810      0.785    0.835\n14 Omega[2,2]  1          1        1    \n\n\nNótese que recuperamos el coeficiente correcto (\\(\\beta_1\\)).\nNotas:\n\nEn estos modelos, muchas veces es crucial la información a priori. Iniciales no informativas pueden dar resultados malos (dificultades numéricas, poca precisión y sesgo).\nFuera del ámbito bayesiano se utilizan métodos como mínimos cuadrados en 2 etapas.\nSin supuestos lineales, hay más supuestos que se tienen que cumplir para que este enfoque funcione (ver Morgan y Winship (2015)), por ejemplo, ¿qué se identifica en el caso de efecto heterogéneo sobre los individuos?\n\nEjemplos clásicos (que a veces funcionan pero no siempre) de potenciales instrumentos son:\n\nTemporada en la que nace una persona (construye por ejemplo un diagrama para educación, salario en el futuro y mes en el que nació una persona), y por qué variables instrumentales podrían ayudar a identificar el efecto causal de educación en salario futuro.\nDistancia a algún servicio: el uso de un servicio varía con la distancia para accederlo (por ejemplo, ¿cómo saber si un centro comunitario en una población mejora el bienestar del que lo usan?)\nLoterías reales para determinar cuál es el efecto de recibir una cantidad grande de dinero sobre bienestar o ahorros futuros, etc.\n\nPuedes encontrar más ejemplos en Morgan y Winship (2015) y aquí.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Otros métodos para inferencia causal</span>"
    ]
  },
  {
    "objectID": "13-exp-naturales.html#regresión-discontinua",
    "href": "13-exp-naturales.html#regresión-discontinua",
    "title": "10  Otros métodos para inferencia causal",
    "section": "10.4 Regresión discontinua",
    "text": "10.4 Regresión discontinua\nMuchas veces, la decisión de aplicar un tratamiento o no depende de un límite administrativo en una variable dada, y en algunos casos esto nos da la posibilidad de explotar un experimento natural.\nPor ejemplo, supongamos que quisiéramos estimar el efecto de clases extras obligatorias para estudiantes que tienen calificaciones bajas. Para esto, se aplica un examen de evaluación a todos los estudiantes. Aquellos que tienen una calificación menor a 100 entren obligatoriamente a la clase, y aquellos que tienen una calificación mayor a 100 no. Al final de un semestre, se mide el desempeño de todos los estudiantes con otro examen .\nLa pregunta entonces es cuál es el efecto de las clases extra sobre el desempeño de los alumnos. Comenzamos haciendo un diagrama, donde \\(X\\) es la calificación del primer examen, \\(T\\) es el tratamiento (asistir a clases extras) y \\(Y\\) es el desempeño en el segundo examen. También es necesario agregar variables desconocidas \\(U\\) (como habilidad) que afectan a las dos calificaciones.\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n  node [shape = circle]\n    U\n  node [shape=plaintext]\n    X\n  edge [minlen = 3]\n     U -&gt; Y\n\n    X -&gt; T\n    T -&gt; Y\n    X -&gt; Y\n    U -&gt; X\n{rank = same; U; T}\n{rank = same;  Y}\n{rank = min;  X}\n\n}\n\", width = 200, height = 200)\n\n\n\n\n\n\nVemos que no podemos comparar simplemente las calificaciones \\(Y\\) de los que asistieron contra los que no asistieron (corriendo una regresión por ejemplo), pues hay una puerta trasera abierta entre \\(T\\) y \\(Y\\) (el tratamiento no se asignó al azar). Es necesario entonces condicionar a \\(X\\) para hacer nuestras estimaciones. Podríamos hacer supuestos acerca de modelos e intentar hacer nuestra estimación de esta manera.\nSin embargo, podemos hacer algo más simple para comenzar. Si consideramos aquellos estudiantes que tienen calificación \\(X\\) cercana a 100, podríamos considerar que esos alumnos fueron prácticamente asignados al azar a uno u otro grupo.\nSi restringimos, el diagrama se convierte en:\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.2, rankdir=LR]\n \n  node [shape = circle]\n    U\n  node [shape=plaintext]\n    \n  edge [minlen = 3]\n     U -&gt; Y\n  \n    X_100 -&gt; T\n    T -&gt; Y\n{rank = same; U; Y}\n{rank = min; T; X_100}\n}\n\",width = 200, height = 200)\n\n\n\n\n\n\nEn este caso, el grupo X_100 son aquellos que obtuvieron, por ejemplo, calificaciones entre 95 y 105.La idea es comparar en el grupo X_100 aquellos que recibieron el tratamiento con los que no lo recibieron:\n\nDiferencias mínimas en estatura determinan el tratamiento.\nCaminos no causales a través de \\(X\\) están prácticamente bloqueados, pues prácticamente estamos condicionando a un valor de examen fijo (\\(X\\) no puede influir en nada más que en asignación del tratamiento).\n\nPodemos entonces comparar directamente tratados y no tratados para obtener una estimación del efecto promedio del tratamiento, siempre y cuando el efecto del tratamiento sea homogéneo, o especifiquemos que el efecto sólo es condicional a \\(X=100\\).\nEn la práctica, usualmente un grupo suficientemente angosto produciría un tamaño de muestra chico y sería difícil estimar el efecto del tratamiento (no tendríamos precisión). Así que recurrimos a modelos simples de la forma\n\\[p(y|x)\\] que tienen la particularidad de que permiten un cambio discontinuo en la distribución en el punto de corte \\(x = x_0\\). Se puede tratar de dos modelos: uno del lado izquierdo y otro del lado derecho, aunque es posible que compartir parámetros. Con esto podemos ganar precisión al aplicar el método en un intervalo más grande.\n\nEjemplo simulado\nSupongamos existe un programa de becas para permanecer en la escuela que se les da a niños de 9 o más años cumplidos. Nos interesa ver cuál es la asistencia escolar en el año siguiente al programa. Veamos un ejemplo simulado:\n\ninv_logit &lt;- function(x) 1/(1+exp(-x))\nsimular_des &lt;- function(n = 100){\n  edad &lt;- runif(n, 5, 12)\n  t &lt;- ifelse(edad &gt;= 9, 1, 0)\n  u &lt;- rnorm(n, 0, 0.6)\n  asistencia_dias &lt;- 200 * inv_logit(3 - 0.6* (edad - 5) + 1 * t + u)\n  tibble(edad, t, asistencia_dias)\n}\nset.seed(8)\ndatos_tbl &lt;- simular_des(500)\nggplot(datos_tbl, aes(x = edad, y = asistencia_dias)) +\n  geom_point() +\n  geom_vline(xintercept = 9, colour = \"red\")\n\n\n\n\n\n\n\n\nPodríamos ajustar dos modelos:\n\nggplot(datos_tbl, aes(x = edad, y = asistencia_dias)) +\n  geom_point() +\n  geom_vline(xintercept = 9, colour = \"red\") +\n  geom_smooth(aes(group = t))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nSi nuestros modelos son apropiados, podemos estimar el efecto causal a los 9 años: el programa incrementa la asistencia en un promedio de alrededor de 25 días de 200 posibles. Para hacer inferencia apropiadamente, podemos ajustar modelos como veremos más adelante.\n\n\n\n\n\n\nRegresión discontinua\n\n\n\nEl supuesto básico de identificación para regresión discontinua se puede expresar con contrafactuales:\n\nTanto \\(p(Y_i^1|X=x)\\) como \\(p(Y_i^0|X=x)\\) varían continuamente en el punto de corte \\(x=x_0\\)\nEl único criterio de aplicación del tratamiento es estar en \\(X\\) por arriba o abajo de \\(x_0\\).\n\n\n\nEsto quiere decir que si vemos un salto en el punto de corte del tratamiento, este se debe al tratamiento, y no a cómo son \\(p(Y_i^0|X=x)\\) y \\(p(Y_i^1|X=x)\\).\nEn particular, para el efecto promedio:\n\\[E[Y^1 - Y^0|X=x_0] = E[Y^1|X=x_0] - E[Y^0|X=x_0]\\] es igual a\n\\[\\lim_{x\\to x_0^+} E[Y^1|X=x_0] - \\lim_{x\\to x_0^-} E[Y^0|X=x_0]\\] Después de \\(x_0\\) todas las unidades tienen el tratamiento, y antes ninguna, de modo que esto equivale a\n\\[\\lim_{x\\to x_0^+} E[Y|X=x, T = 1] - \\lim_{x\\to x_0^-} E[Y|X=x, T = 0]\\] y estas dos cantidades están identificadas. Solamente usamos el supuesto de continuidad y del punto de corte para el tratamiento. Nótese que este supuesto se puede violar cuando unidades de un lado del corte son diferentes a las del otro lado, lo cual sucede por ejemplo cuando es un corte genérico que afecta muchas cosas o cuando de alguna manera la variable del corte es manipulable por los individuos:\n\nHay otras cosas que suceden el punto de corte, por ejemplo: es difícil usar mayoria de edad como punto de corte, porque varias cosas suceden cuando alguien cumple 18 años (puede votar, puede ser que tome decisiones alrededor de esos momentos, puede comprar alcohol, etc).\nHay maneras de manipular la variable con la que se hace el punto de corte (por ejemplo, si mi hijo nace en septiembre reporto en el acta que nació en agosto por fines escolares).\n\nUna manera usual de checar estos supuestos es considerar otras variables (que varían continuamente con la variable que usa para el corte), y que no deberían ser afectadas por el tratamiento, y verificar que no hay discontinuidades en el punto de corte de interés.\nPuedes ver más aquí\n\n\nEjemplo: parte 2\nArriba hicimos un ajuste con curvas loess. Lo más apropiado es construir modelos y así facilitar la inferencia del tamaño del efecto.\n\nlibrary(cmdstanr)\nlibrary(splines)\n\nmodelo_disc &lt;- cmdstan_model(\"./src/reg-discontinua.stan\")\nprint(modelo_disc)\n\ndata {\n  int N;\n  int n_base;\n  vector[N] y;\n  vector[N] x;\n  vector[N] trata;\n  matrix[n_base, N] B;\n}\n\nparameters {\n  row_vector[n_base] a_raw;\n  real a0;\n  real delta;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; tau;\n}\n\ntransformed parameters {\n  row_vector[n_base] a;\n  vector[N] y_media;\n  a = a_raw * tau;\n  y_media = a0 * x + to_vector(a * B) + trata * delta;\n}\n\nmodel {\n  a_raw ~ normal(0, 1);\n  tau ~ normal(0, 1);\n  sigma ~ normal(0, 10);\n  delta ~ normal(0, 10);\n  y ~ normal(y_media, sigma);\n}\n\ngenerated quantities {\n\n}\n\n\n\nx &lt;- datos_tbl$edad \nB &lt;- t(ns(x, knots = 6, intercept = TRUE)) \ny &lt;- datos_tbl$asistencia_dias\ntrata &lt;- datos_tbl$t\ndatos_lista &lt;- list(N = length(x), n_base = nrow(B), B = B,\n                    y = y, x = x, trata = trata)\najuste &lt;- modelo_disc$sample(data = datos_lista, parallel_chains = 4, \n                             refresh = 1000)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 2.6 seconds.\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 2.8 seconds.\nChain 2 finished in 2.7 seconds.\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 2.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.8 seconds.\nTotal execution time: 3.0 seconds.\n\n\nNuestro resumen del efecto local en 9 años es el siguiente:\n\najuste$summary(\"delta\") |&gt; select(variable, mean, q5, q95)\n\n# A tibble: 1 × 4\n  variable  mean    q5   q95\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 delta     19.4  12.8  26.1\n\n\nFinalmente, vemos cómo ajusta el modelo:\n\ny_media_tbl &lt;- ajuste$draws(\"y_media\", format = \"df\") |&gt; \n  pivot_longer(cols = contains(\"y_media\"), names_to = \"variable\") |&gt; \n  separate(variable, into = c(\"a\", \"indice\"), sep = \"[\\\\[\\\\]]\", \n           extra = \"drop\", convert = TRUE) \n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\ny_media_tbl &lt;- y_media_tbl |&gt; \n  left_join(tibble(indice = 1:length(x), edad= x))\n\nJoining with `by = join_by(indice)`\n\n\n\nres_y_media_tbl &lt;- y_media_tbl |&gt; group_by(indice, edad) |&gt; \n  summarise(media = mean(value), q5 = quantile(value, 0.05),\n            q95 = quantile(value, 0.95))\n\n`summarise()` has grouped output by 'indice'. You can override using the\n`.groups` argument.\n\nggplot(res_y_media_tbl, aes(x = edad)) + \n  geom_line(aes(y = media), colour = \"red\", size = 2) +\n  geom_line(aes(y = q5), colour = \"red\") +\n  geom_line(aes(y = q95), colour = \"red\") + \n  geom_point(data = datos_tbl, aes(y = asistencia_dias), alpha = 0.2)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nNotas:\n\nIgual que en experimentos, puede tener sentido controlar por otras variables(“buenos controles”) para mejorar la precisión del análisis.\nEsto es especialmente cierto cuando la variable \\(x\\) en la regresión discontinua no determina de manera muy fuerte la respuesta \\(y\\) (datos ruidosos)\nEs necesario tener cuidado con la forma funcional que se utiliza en los modelos (ver esta liga, donde muestran por ejemplo este análisis que es incorrecto:\n\n\nEn general, usar polinomios de orden alto es mala idea, pues la forma general de los datos lejos de la discontinuidad puede influir fuertemente la diferencia que observamos cerca de la discontinuidad.\n\n\nEjemplo: edad mínima de consumo de alcohol\nConsideramos datos de The Effect of Alcohol Consumption on Mortality: Regression Discontinuity Evidence from the Minimum Drinking Age\nEn este caso, queremos ver el efecto causal de permitir legalmente tomar alcohol sobre la mortalidad de jóvenes. La regla administrativa en este caso es que a partir de los 21 años es legal que consuman alcohol.\nEn este ejemplo particular, los datos se agruparon en cubetas por rangos de edad de 2 meses de edad. Esto no es necesario (podríamos utilizar los datos desagregados y un modelo logístico, por ejemplo).\nVeamos dos ejemplos particulares, muertes en vehículos, suicidios y homicidios:\n\nmlda_tbl &lt;- read_csv(\"../datos/mlda.csv\") |&gt; \n  select(agecell,  over21, all, homicide, suicide, \n         `vehicle accidents` = mva, drugs, external, externalother) |&gt; \n  pivot_longer(cols=c(all:externalother), names_to = \"tipo\", values_to = \"mortalidad\") |&gt; \n  filter(tipo %in% c(\"vehicle accidents\", \"suicide\", \"homicide\"))\nhead(mlda_tbl)\n\n# A tibble: 6 × 4\n  agecell over21 tipo              mortalidad\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1    19.1      0 homicide                16.3\n2    19.1      0 suicide                 11.2\n3    19.1      0 vehicle accidents       35.8\n4    19.2      0 homicide                16.9\n5    19.2      0 suicide                 12.2\n6    19.2      0 vehicle accidents       35.6\n\nggplot(mlda_tbl, aes(x = agecell, y = mortalidad, group = over21)) + geom_point() +\n  geom_smooth(method = \"loess\", span = 1, formula = \"y ~ x\") + facet_wrap(~tipo)\n\n\n\n\n\n\n\n\nEjercicio: construye modelos de stan para estos datos, como en el ejemplo anterior.\n\n\n\n\nFreedman, David A. 1991. «Statistical Models and Shoe Leather». Sociological Methodology 21: 291-313. http://www.jstor.org/stable/270939.\n\n\nMorgan, S. L., y C. Winship. 2015. Counterfactuals and Causal Inference. Analytical Methods for Social Research. Cambridge University Press. https://books.google.com.mx/books?id=Q6YaBQAAQBAJ.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Otros métodos para inferencia causal</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html",
    "href": "14-mas-flujo-bayesiano.html",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "",
    "text": "11.1 Calibración algorítmica\nEn esta parte veremos más detalles del flujo Bayesiano de trabajo, partiendo del plantwamiento de M. Betancourt\nVeamos el diagrama que se propone en este artículo:\nEste flujo está dividido en tres partres: una pre-modelo y pre-datos, una pre-datos, y uno cuando ya tenemos modelo y datos. Este enfoque es robusto desde el punto de vista estadístico y computacional, aunque está escrito de una forma un poco diferente a como lo planteamos en secciones anteriores.\nPara introducir algunos análisis que consideraremos planteamos una situación simple, donde estamos midiendo los resultados de 100 sensores de alguna partícula, todos intentando medir la misma fuente fija, como un experimento de control de calidad. En este caso, todos los detectores están midiendo la misma cantidad, pero hay cierto error en la medición, y podemos escribir el diagrama simple, que supone que dada la fuente las observaciones son observaciones independientes. \\(L\\) representa la fuente seleccionada, y las \\(y_j\\) son las observaciones de los sensores:\nComenzaremos con un modelo simple. Como las observaciones son enteros, supondremos que las observaciones son Poisson con media \\(\\lambda_F\\). Nos interesa entonces estimar \\(\\lambda_F\\) que nos da la intensidad de la fuente.\nPara poner una inicial necesitamos concocimiento de dominio. Supongamos que sabemos que para este tipo de fuentes, detectores, y tiempo de detección es extremo obtener conteos mayores a 25 partículas: los pondremos en el 1% de la cola superior, por ejemplo. Podemos experimentar con valores para \\(\\sigma\\) en una normal truncada en cero.\nY podemos ver que requerimos aproximadamente \\(\\lambda\\leq 99\\) con alta probabilidad. Experimentando, podemos ver que si \\(\\sigma=6\\) es un valor razonable para la normal truncada:\nAhora construimos nuestro modelo generativo y examinamos sus consecuencias. Simularemos 1500 repeticiones de las 100 observaciones que esperamos:\nAhora podemos examinar algunas posibles configuraciones del modelo junto con las observaciones que esperaríamos ver:\nY podemos resumir estas simulaciones como sigue: que muestra la distribución predictiva a priori:\nY vemos que es muy poco probable observar cantidades medidas por arriba de 25:\nBajo los supuestos del modelo, ahora podemos proponer nuestro algoritmo de estimación, y checar en primer lugar que funciona apropiadamente. En este ejemplo, tomaremos solamente 40 simulaciones y ajustaremos en cada caso el siguiente modelo consecuencia de nuestros supuestos. Usualmente podemos usar 100 o más.\nEn este paso podemos ajustar nuestro muestreador, número de cadenas y su longitud, etc. Hacemos un ajuste para cada posible conjunto de observaciones, y extraemos también la \\(\\lambda_F\\) que generó cada conjunto de datos:\nmod_2 &lt;- cmdstan_model(\"src/flujo-mb/2-modelo-poisson.stan\")\nprint(mod_2)\n\ndata {\n  int N;\n  array[N] int y;\n}\n\nparameters {\n  real&lt;lower=0&gt; lambda;\n}\n\nmodel {\n  lambda ~ normal(0, 6);\n  y ~ poisson(lambda);\n}\n\ngenerated quantities {\n  array[N] int y_sim;\n\n  for (n in 1:N) {\n    y_sim[n] = poisson_rng(lambda);\n  }\n}\n\najustes_apriori &lt;- purrr::map(1:40, function(rep){\n  y &lt;- obs_priori_tbl |&gt; filter(.draw == rep) |&gt; pull(valor)\n  datos_sim_lst &lt;- list(y = y, N = length(y))\n  # Ajustar modelo\n  ajuste &lt;- mod_2$sample(data = datos_sim_lst, \n  iter_sampling = 1000, chains = 3, parallel_chains = 3, seed = 4838282, \n    refresh = 0, show_messages = FALSE)\n  list(ajuste = ajuste, lambda_sim = sims_tbl$lambda[rep])\n})\nPodemos checar por ejemplo tamaño efectivo de muestra, rhat o divergencias, para cada caso que extrajimos de la inicial de \\(\\lambda_F\\):\najustes_apriori |&gt; map_df(~ .x$ajuste$summary(\"lambda\")) |&gt; \n  ggplot(aes(x = ess_bulk)) + geom_histogram(bins = 30)\najustes_apriori |&gt; map_dbl(\n  ~ .x$ajuste$diagnostic_summary(\"divergences\")$num_divergent |&gt; sum()) |&gt; \n  sum()\n\n[1] 0\nAdicionalmente, podemos ver si recuperamos o no los parámetros de la simulación. En primer lugar, calculamos el cuantil del valor verdadero para la posterior de la simulación:\nresumen_cuantiles_tbl &lt;- ajustes_apriori |&gt; map_df(function(ajuste_lst){\n  lambda_sim &lt;- ajuste_lst$lambda_sim\n  cuantiles_tbl &lt;- ajuste_lst$ajuste$draws(\"lambda\", format = \"df\") |&gt; \n    mutate(menor = lambda_sim &lt; lambda) |&gt; \n    summarise(q_menor = mean(menor))\n  cuantiles_tbl |&gt; mutate(lambda_sim = lambda_sim)\n})\nAhora podemos hacer una gráfica de cuantiles: si estamos recuperando correctamente los parámetros, la distribución de los cuantiles de los valores verdaderos en la posterior debe ser cercana a uniforme (pues si \\(y\\sim F\\), entonces \\(P(F(y)&lt;t)) = t\\) para cualquier \\(t\\)):\nresumen_cuantiles_tbl\n\n# A tibble: 40 × 2\n   q_menor lambda_sim\n     &lt;dbl&gt;      &lt;dbl&gt;\n 1 0.669         1.92\n 2 0.00433       5.75\n 3 0.660         2.46\n 4 0.885         6.39\n 5 0.365         5.50\n 6 0.464         6.38\n 7 0.295         9.28\n 8 0.587         8.71\n 9 0.279         8.61\n10 0.144         3.77\n# ℹ 30 more rows\n\nggplot(resumen_cuantiles_tbl, aes(sample = q_menor)) +\n  geom_qq(distribution = stats::qunif) +\n  geom_abline(slope = 1, intercept = 0) +\n  labs(subtitle = \"Recuperación de valores en la posterior\")\nEn este caso, vemos que estamos recuperando adecuadamente los valores que pusimos en la simulación. Además de esta gráfica de cuantiles, hay otras alternativas que puedes ver aquí.\nNota: Esto es porque si \\(\\lambda \\sim F_{lambda}\\), donde \\(F_{\\lambda})\\) es la función de distribución acumulada, entonces \\(P(F(\\lambda)&lt;t)) = t\\) para cualquier \\(t\\). Entonces, si encontramos qué cuantil es cada valor \\(\\lambda_i\\) en su posterior \\(p_i\\), y lo denotamos por \\(F_i(\\lambda_i)\\), entonces estos valores están entre cero y uno, y cada uno se distribuye uniforme en \\([0,1]\\). Cada punto es una corrida de un modelo distinto.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#calibración-inferencial",
    "href": "14-mas-flujo-bayesiano.html#calibración-inferencial",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.2 Calibración inferencial",
    "text": "11.2 Calibración inferencial\nFinalmente veremos si las posteriores obtenidas dan inferencias que sean suficientes para nuestros propósitos. Queremos determinar, con el modelo planteado, tamaño de datos e iniciales:\n\n¿Nuestro modelo tiene problemas para aprender más allá de la a priori (“identificación” en el sentido estádistico)??\n¿Nuestro modelo a priori es adecuado para los valores de las cantidades de interés que queremos estimar?\nNuestro ajuste tiende a sobreajustar los datos y darnos malas inferencias?\n\nAbajo presentamos una demostración de M. Betancourt de cómo pueden verse estos problemas:\n Y podemos calcular, para un parámetro particular, dos valores útiles. Primero, el valor z posterior de cada parámetro, que está dado por:\n\\[ z(\\theta^*, y) = \\frac{\\theta^* - \\mu_{post}({\\theta}|y)}{\\sigma_{post}(\\theta|y)}\\]\ndonde \\(\\theta^*\\) es el valor verdadero. Esta es también una medida de qué tanto está el valor verdadero en el centro de la distribución o en una cola de la posterior, y mide, en cada simulación, con qué precisión recuperamos con la posterior el valor verdadero. Valores chicos indican que la posterior está altamente concentrada en el valor verdadero.\nIgualmente necesitamos la contracción posterior, que podemos definir como\n\\[c(y) = 1 - \\frac{Var_{post}(\\theta|y)}{Var_{previa}(\\theta)}\\]\ny esta cantidad mide qué tanto los datos informan sobre el parámetro con respecto a la información previa. Contracciones cercanas a cero indican que no aprendimos mucho por encima de lo que sabíamos con la inicial.\nUsualmente queremos que la contracción sea cercana a 1, y qué los valores \\(z\\) estén cercanos a cero. Sin embargo, podemos encontrar:\n\nSobreajuste: la contracción es cercana a 1, pero observamos valores \\(z\\) grandes en valor absoluto (más allá de 4 y -4 por ejemplo).\nInformación previa incorrecta: la contracción es cercana a 0, y observamos valores de \\(z\\) grandes.\nIndentificación pobre: aunque los valores de \\(z\\) no son muy lejanos a 0, la contracción es cercana a 0 (no aprendemos mucho de los datos).\n\nPodemos hacer esta gráfica para nuestro ejemplo de arriba:\n\ncontraccion_z_tbl &lt;- ajustes_apriori |&gt; map_df(function(ajuste_lst){\n  lambda_sim &lt;- ajuste_lst$lambda_sim\n  sd_previa &lt;- 3.69 # ver inicial de lambda\n  post_media_sd_tbl &lt;- ajuste_lst$ajuste$draws(\"lambda\", format = \"df\") |&gt; \n    summarise(media_post = mean(lambda), sd_post = sd(lambda))\n  tibble(contraccion = 1 - post_media_sd_tbl$sd_post^2/sd_previa^2,\n         z = (lambda_sim - post_media_sd_tbl$media_post)/post_media_sd_tbl$sd_post)\n})\n\n\nggplot(contraccion_z_tbl, aes(x = contraccion, y = z)) +\n  geom_point() +\n  xlab(\"Contracción\") + ylab(\"Valor z\") + \n  xlim(0, 1)\n\n\n\n\n\n\n\n\nY en este caso, obtenemos resultados informativos (alta contracción), que según los valores \\(z\\) capturan adecuadamente los valores verdaderos.\n\n\n\n\n\n\nSobreajuste\n\n\n\nNótese que esta forma de ver el sobreajuste está más relacionada con la inferencia acerca de parámetros de interés que al sobreajuste en modelos predictivos.\nAunque también con modelos bayesianos podemos hacer validación cruzada para predicciones (ya sea tradicional o con métodos computacionalmente más eficientes que aproximan el desempeño predictivo), nuestro objetivo principal no es obtener buenas predicciones, sino tener inferencia correcta e informativa acerca de las cantidades de interés.\n\n\nEl punto de vista predictivo también es importante, y puedes ver el texto de McElreath para más detalles (por ejemplo, el uso de validación cruzada adaptada para modelos bayesianos).\nFinalmente, vamos al ajuste de datos reales y diagnósticos asociados",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#datos-reales-diagnóstico-de-ajuste",
    "href": "14-mas-flujo-bayesiano.html#datos-reales-diagnóstico-de-ajuste",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.3 Datos reales: diagnóstico de ajuste",
    "text": "11.3 Datos reales: diagnóstico de ajuste\nYa hemos visto antes cómo hacer diagnósticos del ajuste (checar MCMC, divergencias, etc.):\n\ndatos_obs &lt;- read_csv(\"../datos/ejemplo-flujo.csv\")\n\nRows: 100 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndatos_lst &lt;- list(y = datos_obs$y, N = nrow(datos_obs))\n  ajuste &lt;- mod_2$sample(data = datos_lst, \n  iter_sampling = 1000, refresh = 1000, chains = 3, parallel_chains = 3, seed = 282)\n\nRunning MCMC with 3 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.1 seconds.\n\nAll 3 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\najuste$summary(\"lambda\") |&gt; \nselect(mean, sd, q5, q95, rhat, ess_bulk, ess_tail)\n\n# A tibble: 1 × 7\n   mean    sd    q5   q95  rhat ess_bulk ess_tail\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  5.95 0.240  5.56  6.35  1.00    1169.    1580.\n\n\nLos diagnósticos no muestran problemas.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#chequeos-predictivos-posteriores",
    "href": "14-mas-flujo-bayesiano.html#chequeos-predictivos-posteriores",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.4 Chequeos predictivos posteriores",
    "text": "11.4 Chequeos predictivos posteriores\nAhora simulamos datos observados de la predictiva posterior ajustada, y comparamos con los datos observados.\n\nsims_post_pred_tbl &lt;- ajuste$draws(\"y_sim\", format = \"df\") |&gt; \n  as_tibble() |&gt;\n  pivot_longer(cols = starts_with(\"y_sim\"), names_to = \"y\", values_to = \"valor\") |&gt; \n  separate(y, into = c(\"y_sim\", \"n\"), sep = \"[\\\\[\\\\]]\", extra = \"drop\") |&gt; select(-y_sim)\n\n\nggplot(sims_post_pred_tbl |&gt; filter(.draw &lt;=10) |&gt; \n  bind_rows(datos_obs |&gt; rename(valor = y) |&gt; mutate(.draw = 11)), \n    aes(x = valor)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~.draw) +\n  labs(subtitle = \"Chequeo predictivo posterior\")\n\n\n\n\n\n\n\n\nY vemos un desajuste claro en el modelo: los datos tienen exceso de ceros, y los datos que nos son cero tienden a ser mayores que los simulados. En este punto, es necesario regresar al análisis conceptual, pues hay algo fundamental en el proceso generador de datos que no estamos considerando.\nPodemos hacer también hacer una gráfica agregada de la posterior predictiva, comparando con la observada, donde vemos el mismo problema:\n\nggplot(sims_post_pred_tbl |&gt; group_by(.draw, valor) |&gt; count() |&gt; \n         group_by(valor) |&gt; \n         summarise(mediana = median(n), q_10 = quantile(n, 0.1), q90 = quantile(n, 0.9)) |&gt; \n         pivot_longer(cols = c(mediana, q_10, q90), names_to = \"tipo\", values_to = \"resumen\"),\n  aes(x = valor)) +\n  geom_line(aes(y = resumen, group = tipo)) +\n  labs(subtitle = \"Distribución predictiva a priori\") +\n  ylab(\"Frecuencia\") +\n  geom_histogram(data = datos_obs, aes(x = y), bins = 30, alpha = 0.5)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#un-segundo-intento",
    "href": "14-mas-flujo-bayesiano.html#un-segundo-intento",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.5 Un segundo intento",
    "text": "11.5 Un segundo intento\nSupongamos que después de investigar, nos enteramos que es común que algunos detectores fallen o estén defectuosos. En ese caso, marcan cero. Nótese que la situación sería diferente, por ejemplo, si los detectores que se desbordan marcan cero, etc. Es necesario regresar entonces al análisis conceptual, y repetir todo el proceso.\nNuestros siguientes pasos dependen de que podamos entender cuál es la razón del exceso de ceros con respecto a nuestro modelo inicial. En este caso, tenemos que considerar que hay cierta probabilidad de que los detectores fallen.\nConsideramos entonces el siguiente diagrama, donde \\(F\\) representa el origen de los sensores (o el lote de sensores):\n\n\nCódigo\ngrViz(\"\ndigraph {\n  graph [ranksep = 0.3, rankdir = LR]\n  node [shape=circle]\n    L\n    F\n  node [shape=plaintext]\n    y_j\n  edge [minlen = 3]\n    L -&gt; y_j\n    F_j -&gt;  y_j\n    F -&gt; F_j\n{rank = same; L;F}\n   \n}\n\")#, width = 200, height = 50)\n\n\n\n\n\n\nProponemos entonces un modelo como sigue: \\(y_n = 0\\) con probabilidad \\(\\pi\\) (si \\(F_n=1\\)), y \\(y_n\\sim \\text{Poisson}(\\lambda)\\) con probabilidad \\(1-\\pi\\) (\\(f_n=0\\)). El modelo de datos se puede escribir como sigue:\n\\[p(y|\\lambda, \\pi) = (1-\\pi) \\textrm{pois}(y|\\lambda) + \\pi I(y=0)\\] que es una Poisson reescalada con una masa \\(\\pi\\) en cero (modelo Poisson con ceros inflados).\nRecorremos los pasos con nuestro nuevo modelo, y consideraremos qué es lo que sucede en la calibración algorítmica:\n\nN &lt;- 100\nR &lt;- 1500\nsim_datos &lt;- list(N = N)\n\nmod_ensemble &lt;- cmdstan_model(\"src/flujo-mb/2-simular-ensemble.stan\")\nprint(mod_ensemble)\n\ndata {\n  int N;\n}\n\ngenerated quantities {\n  real&lt;lower=0&gt; lambda;\n  real&lt;lower=0, upper=1&gt; p;\n  array[N] int y;\n\n  // Simular configuracion del modelo a partir de inicial\n  lambda = abs(normal_rng(0, 6));\n  p = beta_rng(1, 1);\n  // Simular datos del modelo observacional\n  for (n in 1:N){\n    y[n] = 0;\n    if(!bernoulli_rng(p)){\n      y[n] = poisson_rng(lambda);\n    }\n  }\n}\n\nsims_priori &lt;- mod_ensemble$sample(data = sim_datos, \n  iter_sampling = R, chains = 1, refresh = R, seed = 4838282,\n  fixed_param = TRUE)\n\nRunning MCMC with 1 chain...\n\nChain 1 Iteration:    1 / 1500 [  0%]  (Sampling) \nChain 1 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\n\n\nAhora podemos examinar algunas posibles configuraciones del modelo junto con las observaciones que esperaríamos ver:\n\nsims_tbl &lt;-  sims_priori$draws(format = \"df\")\nobs_priori_tbl &lt;-  sims_tbl |&gt; \n  as_tibble() |&gt;\n  pivot_longer(cols = starts_with(\"y\"), names_to = \"y\", values_to = \"valor\") |&gt; \n  separate(y, into = c(\"y\", \"n\"), sep = \"[\\\\[\\\\]]\") |&gt; select(-y)\nggplot(obs_priori_tbl |&gt; filter(.draw &lt; 5), aes(x = valor)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~lambda) +\n  labs(subtitle = \"Simulaciones de observaciones a priori\")\n\n\n\n\n\n\n\n\nY podemos resumir estas simulaciones como\n\nggplot(obs_priori_tbl |&gt; group_by(.draw, valor) |&gt; count() |&gt; \n         group_by(valor) |&gt; \n         summarise(mediana = median(n), q_10 = quantile(n, 0.1), q90 = quantile(n, 0.9)) |&gt; \n         pivot_longer(cols = c(mediana, q_10, q90), names_to = \"tipo\", values_to = \"resumen\"),\n  aes(x = valor)) +\n  geom_line(aes(y = resumen, group = tipo)) +\n  labs(subtitle = \"Simulaciones de observaciones a priori\")\n\n\n\n\n\n\n\n\nY vemos que es muy poco probable observar cantidades medidas por arriba de 25:\n\nobs_priori_tbl |&gt; mutate(mayor_25 = valor &gt; 25) |&gt; \n  summarise(mayor_25 = mean(mayor_25)) \n\n# A tibble: 1 × 1\n  mayor_25\n     &lt;dbl&gt;\n1 0.000253",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#calibración-algorítmica-1",
    "href": "14-mas-flujo-bayesiano.html#calibración-algorítmica-1",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.6 Calibración algorítmica",
    "text": "11.6 Calibración algorítmica\nBajo los supuestos del modelo, ahora podemos proponer nuestro algoritmo de estimación, y checar en primer lugar que funciona apropiadamente. En este ejemplo, tomaremos solamente 100 simulaciones y ajustaremos en cada caso el siguiente consecuencia de nuestros supuestos. Usualmente podemos usar 100 o más.\nEn este paso podemos ajustar nuestro muestreador, número de cadenas y su longitud, etc.\n\nmod_2 &lt;- cmdstan_model(\"src/flujo-mb/2-modelo-poisson-cero-inflado.stan\")\nprint(mod_2)\n\ndata {\n  int N;\n  array[N] int y;\n}\n\nparameters {\n  real&lt;lower=0&gt; lambda;\n  real&lt;lower=0, upper=1&gt; p;\n}\n\nmodel {\n  lambda ~ normal(0, 6);\n  p ~ beta(1, 1);\n  for(n in 1:N){\n    real lpdf = poisson_lpmf(y[n] | lambda);\n    if(y[n] == 0){\n      target += log_mix(p, 0, lpdf);\n    } else {\n      target += log(1-p) + lpdf;\n    }\n  }\n}\n\ngenerated quantities {\n  array[N] int y_sim;\n\n  for (n in 1:N) {\n    real zero = bernoulli_rng(p);\n    if (zero == 1) {\n      y_sim[n] = 0;\n    } else {\n      y_sim[n] = poisson_rng(lambda);\n    }\n  }\n}\n\nset.seed(4852)\nsimulados_rep &lt;- sample(1:1500, 100)\najustes_apriori &lt;- purrr::map(simulados_rep, function(rep){\n  y &lt;- obs_priori_tbl |&gt; filter(.draw == rep) |&gt; pull(valor)\n  datos_sim_lst &lt;- list(y = y, N = length(y))\n  ajuste &lt;- mod_2$sample(data = datos_sim_lst, \n  iter_sampling = 1000, chains = 3, parallel_chains = 3, seed = 483828251, \n    refresh = 0, show_messages = FALSE)\n  list(ajuste = ajuste, lambda_sim = sims_tbl$lambda[rep], p_sim = sims_tbl$p[rep])\n})\n\nY vemos que nos encontramos con problemas. Examinamos los ajustes que producen divergencias:\n\ndivergencias_lst &lt;- ajustes_apriori |&gt; map_dbl(\n  ~ .x$ajuste$diagnostic_summary(\"divergences\")$num_divergent |&gt; sum()) \n\nWarning: 6 of 3000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\nWarning: 6 of 3000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\ndiv_sim &lt;- which(divergencias_lst &gt; 0)\ndiv_sim\n\n[1] 47 68\n\n\nVeamos entonces que valores de \\(p\\) y \\(lambda\\) corresponden:\n\ndiag_tbl &lt;- obs_priori_tbl |&gt; as_tibble() |&gt; select(lambda, p, .draw) |&gt; unique() |&gt; \n  filter(.draw %in% simulados_rep) |&gt; \n  mutate(problemas = .draw %in% simulados_rep[div_sim]) \nggplot(diag_tbl, aes(x = lambda, y = p, color = problemas, size = problemas)) +\n  geom_point() +\n  labs(subtitle = \"Problemas de divergencia\")\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\nY el problema aparece con valores extremos de \\(p\\) y valores chicos de \\(\\lambda\\) (prueba haciendo más ajustes). Cuando estos valores se presentan, tenemos observaciones que son principalmente ceros, y es difícil distinguir entre ceros que se deben a fallas en los detectores y ceros que se deben a una tasa baja de Poisson.\nEste es un ejemplo donde vimos divergencias:\n\nfilter(obs_priori_tbl |&gt; filter(.draw == div_sim[1])) |&gt; \n  select(valor) |&gt; summarise(num_ceros = sum(valor == 0), num_no_ceros = sum(valor &gt; 0))\n\n# A tibble: 1 × 2\n  num_ceros num_no_ceros\n      &lt;int&gt;        &lt;int&gt;\n1        99            1\n\n\nTambién podemos ver que, incluso si no hubiera divergencias fuertes, los ajustes que parecen problemáticos también muestran valores malos de muestra efectiva:\n\najustes_apriori |&gt; map_df(~ .x$ajuste$summary(\"lambda\")) |&gt; \n  ggplot(aes(x = ess_bulk)) + geom_histogram(bins = 30) \n\n\n\n\n\n\n\najustes_apriori |&gt; map_df(~ .x$ajuste$summary(\"p\")) |&gt; \n  ggplot(aes(x = ess_bulk)) + geom_histogram(bins = 30) \n\n\n\n\n\n\n\n\nPuedes ver más de esto en la discusión de M. Betancourt en aquí.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#tercer-intento",
    "href": "14-mas-flujo-bayesiano.html#tercer-intento",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.7 Tercer intento",
    "text": "11.7 Tercer intento\nEn este punto, es necesario otra vez regresar al análisis conceptual: los datos no tienen información acerca de las causas de los ceros. En primer lugar, podríamos informarnos acerca de qué tan común es que los detectores fallen (o si han existido chequeos recientes que nos den confianza que una proporción razonable está funcionando), o adicionalmente cuál es el rango de tasas mínimas razonables que se espera para el tipo de fuente con el que se está experimentando. En este caso, podríamos evitar las zonas degeneradas y mal identificadas:\n\nPoniendo una inicial en la tasa de Poisson que no sea muy cercana a cero (para un detector que está funcionando), si tenemos información en este sentido\nDescartando probabilidades extremas de fallas de detección: puede ser muy factible que algunos detectores fallen, pero no que la mayoría falle, y quizá tampoco esperamos que todos estén en perfectas condiciones.\n\nSupongamos que en este ejemplo, después de hacer investigaciones adicionales, que con la fuente seleccionada, todos los sensores son configurados para detectar al menos un mínimo de partículas (la fuente es suficientemente fuerte si el sensor está funcionando), y adicionalmente, sabemos que por el proceso, es altamente improbable que todos los sensores tengan fallas (que interpetaremos como que es muy poco probable tener más de 90% de los detectores fallando).\nEsta información no proviene de los datos, sino de conocimiento de dominio, y nos permite configurar más apropiadamente nuestro modelo para evitar este comportamiento patológico.\nRevisamos la inicial que estábamos usando anteriormente con un chequeo de la inicial:\n\n# distribución nicial de p\nggplot(obs_priori_tbl |&gt; select(lambda, p, .draw) |&gt; unique() ,\n       aes(x = p)) + \n  geom_histogram(bins = 30) +\n  labs(subtitle = \"Distribución inicial de p\")\n\n\n\n\n\n\n\nggplot(obs_priori_tbl |&gt; select(lambda, p, .draw) |&gt; unique() ,\n       aes(x = lambda)) + \n  geom_histogram(bins = 30) +\n  labs(subtitle = \"Distribución inicial de lambda\")\n\n\n\n\n\n\n\n\nNinguna de estas coincide con nuestro conocimiento de área. Podemos utilizar una gamma para la inicial de \\(\\lambda\\), y una beta para la inicial de \\(p\\).\nComenzamos recordando el límite de unas 15 unidades para para un aparato que esté funcionando. Experimentando con algunos valores de la gamma (por ejemplo, queremos aproximadamente la media en 5 como en nuestro ejemplo anterior, y la media de una gamma(a,b) es \\(a/b\\)):\n\nggplot(tibble(lambda = rgamma(10000, 4, 0.6)), aes(x = lambda)) +\n  geom_histogram(bins = 60) +\n  labs(subtitle = \"Distribución inicial de lambda\")\n\n\n\n\n\n\n\n\nY para la probabilidad de falla, podemos usar una beta(2, 4) que nos da\n\nggplot(tibble(lambda = rbeta(10000, 2, 4)), aes(x = lambda)) +\n  geom_histogram(bins = 60) +\n  labs(subtitle = \"Distribución inicial de lambda\")\n\n\n\n\n\n\n\n\nAhora repetimos los chequeos a priori:\n\nN &lt;- 100\nR &lt;- 1500\nsim_datos &lt;- list(N = N)\n\nmod_ensemble &lt;- cmdstan_model(\"src/flujo-mb/3-simular-ensemble.stan\")\nprint(mod_ensemble)\n\ndata {\n  int N;\n}\n\ngenerated quantities {\n  real&lt;lower=0&gt; lambda;\n  real&lt;lower=0, upper=1&gt; p;\n  array[N] int y;\n\n  // Simular configuracion del modelo a partir de inicial\n  lambda = gamma_rng(4, 0.6);\n  p = beta_rng(2, 4);\n  // Simular datos del modelo observacional\n  for (n in 1:N){\n    y[n] = 0;\n    if(!bernoulli_rng(p)){\n      y[n] = poisson_rng(lambda);\n    }\n  }\n}\n\nsims_priori &lt;- mod_ensemble$sample(data = sim_datos, \n  iter_sampling = R, chains = 1, refresh = R, seed = 4838282,\n  fixed_param = TRUE)\n\nRunning MCMC with 1 chain...\n\nChain 1 Iteration:    1 / 1500 [  0%]  (Sampling) \nChain 1 Iteration: 1500 / 1500 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\n\n\nAhora podemos examinar algunas posibles configuraciones del modelo junto con las observaciones que esperaríamos ver:\n\nsims_tbl &lt;-  sims_priori$draws(format = \"df\")\nobs_priori_tbl &lt;-  sims_tbl |&gt; \n  as_tibble() |&gt;\n  pivot_longer(cols = starts_with(\"y\"), names_to = \"y\", values_to = \"valor\") |&gt; \n  separate(y, into = c(\"y\", \"n\"), sep = \"[\\\\[\\\\]]\") |&gt; select(-y)\nggplot(obs_priori_tbl |&gt; filter(.draw &lt; 5), aes(x = valor)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~lambda) +\n  labs(subtitle = \"Simulaciones de observaciones a priori\")\n\n\n\n\n\n\n\n\nY podemos resumir estas simulaciones como\n\nggplot(obs_priori_tbl |&gt; group_by(.draw, valor) |&gt; count() |&gt; \n         group_by(valor) |&gt; \n         summarise(mediana = median(n), q_10 = quantile(n, 0.1), q90 = quantile(n, 0.9)) |&gt; \n         pivot_longer(cols = c(mediana, q_10, q90), names_to = \"tipo\", values_to = \"resumen\"),\n  aes(x = valor)) +\n  geom_line(aes(y = resumen, group = tipo)) +\n  labs(subtitle = \"Simulaciones de observaciones a priori\")\n\n\n\n\n\n\n\n\nY vemos que es muy poco probable observar cantidades medidas por arriba de 25:\n\nobs_priori_tbl |&gt; mutate(mayor_25 = valor &gt; 25) |&gt; \n  summarise(mayor_25 = mean(mayor_25)) \n\n# A tibble: 1 × 1\n  mayor_25\n     &lt;dbl&gt;\n1 0.000787",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#calibración-algorítmica-intento-3",
    "href": "14-mas-flujo-bayesiano.html#calibración-algorítmica-intento-3",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.8 Calibración algorítmica (intento 3)",
    "text": "11.8 Calibración algorítmica (intento 3)\nBajo los supuestos del modelo, ahora podemos proponer nuestro algoritmo de estimación, y checar en primer lugar que funciona apropiadamente. En este ejemplo, tomaremos solamente 40 simulaciones y ajustaremos en cada caso el siguiente consecuencia de nuestros supuestos. Usualmente podemos usar 100 o más.\nEn este paso podemos ajustar nuestro muestreador, número de cadenas y su longitud, etc.\n\nmod_3 &lt;- cmdstan_model(\"src/flujo-mb/3-modelo-poisson-cero-inflado.stan\")\nprint(mod_3)\n\ndata {\n  int N;\n  array[N] int y;\n}\n\nparameters {\n  real&lt;lower=0&gt; lambda;\n  real&lt;lower=0, upper=1&gt; p;\n}\n\nmodel {\n  lambda ~ gamma(4, 0.6);\n  p ~ beta(2, 4);\n  for(n in 1:N){\n    real lpdf = poisson_lpmf(y[n] | lambda);\n    if(y[n] == 0){\n      target += log_mix(p, 0, lpdf);\n    } else {\n      target += log(1-p) + lpdf;\n    }\n  }\n}\n\ngenerated quantities {\n  array[N] int y_sim;\n\n  for (n in 1:N) {\n    real zero = bernoulli_rng(p);\n    if (zero == 1) {\n      y_sim[n] = 0;\n    } else {\n      y_sim[n] = poisson_rng(lambda);\n    }\n  }\n}\n\najustes_apriori &lt;- purrr::map(1:40, function(rep){\n  y &lt;- obs_priori_tbl |&gt; filter(.draw == rep) |&gt; pull(valor)\n  datos_sim_lst &lt;- list(y = y, N = length(y))\n  ajuste &lt;- mod_3$sample(data = datos_sim_lst, \n  iter_sampling = 1000, chains = 3, parallel_chains = 3, seed = 4838282, \n    refresh = 0, show_messages = FALSE)\n  list(ajuste = ajuste, lambda_sim = sims_tbl$lambda[rep], p_sim = sims_tbl$p[rep])\n})\n\nUna vez que corregimos valores no factibles con las iniciales, el algoritmo funciona bien:\n\ndivergencias_lst &lt;- ajustes_apriori |&gt; map_dbl(\n  ~ .x$ajuste$diagnostic_summary(\"divergences\")$num_divergent |&gt; sum()) \ndiv_sim &lt;- which(divergencias_lst &gt; 0)\ndiv_sim\n\ninteger(0)\n\n\nAhora vemos si recuperamos o no los parámetros de la simulación. En primer lugar, calculamos el cuantil del valor verdadero para la posterior de la simulación:\n\nresumen_cuantiles_tbl &lt;- ajustes_apriori |&gt; map_df(function(ajuste_lst){\n  lambda_sim &lt;- ajuste_lst$lambda_sim\n  cuantiles_tbl &lt;- ajuste_lst$ajuste$draws(\"lambda\", format = \"df\") |&gt; \n    mutate(menor = lambda_sim &lt; lambda) |&gt; \n    summarise(q_menor = mean(menor))\n  cuantiles_tbl |&gt; mutate(lambda_sim = lambda_sim)\n})\n\nAhora podemos hacer una gráfica de cuantiles: si estamos recuperando correctamente los parámetros, la distribución de los cuantiles de los valores verdaderos en la posterior debe ser cercana a uniforme (pues si \\(y\\sim F\\), entonces \\(P(F(y)&lt;t)) = t\\) para cualquier \\(t\\)):\n\nresumen_cuantiles_tbl\n\n# A tibble: 40 × 2\n   q_menor lambda_sim\n     &lt;dbl&gt;      &lt;dbl&gt;\n 1  0.0683       9.23\n 2  0.300       13.6 \n 3  0.953        2.33\n 4  0.858        8.57\n 5  0.209        4.77\n 6  0.0227       3.45\n 7  0.384        5.00\n 8  0.883        8.40\n 9  0.846        6.94\n10  0.175        6.94\n# ℹ 30 more rows\n\nggplot(resumen_cuantiles_tbl, aes(sample = q_menor)) +\n  geom_qq(distribution = stats::qunif) +\n  geom_abline(slope = 1, intercept = 0) +\n  labs(subtitle = \"Recuperación de valores en la posterior\")\n\n\n\n\n\n\n\n\nEn este caso, vemos que estamos recuperando adecuadamente los valores que pusimos en la simulación.\n\nresumen_cuantiles_tbl &lt;- ajustes_apriori |&gt; map_df(function(ajuste_lst){\n  p_sim &lt;- ajuste_lst$p_sim\n  cuantiles_tbl &lt;- ajuste_lst$ajuste$draws(\"p\", format = \"df\") |&gt; \n    mutate(menor = p_sim &lt; p) |&gt; \n    summarise(q_menor = mean(menor))\n  cuantiles_tbl |&gt; mutate(p_sim = p_sim)\n})\n\nAhora podemos hacer una gráfica de cuantiles: si estamos recuperando correctamente los parámetros, la distribución de los cuantiles de los valores verdaderos en la posterior debe ser cercana a uniforme (pues si \\(y\\sim F\\), entonces \\(P(F(y)&lt;t)) = t\\) para cualquier \\(t\\)):\n\nggplot(resumen_cuantiles_tbl, aes(sample = q_menor)) +\n  geom_qq(distribution = stats::qunif) +\n  geom_abline(slope = 1, intercept = 0) +\n  labs(subtitle = \"Recuperación de valores en la posterior\")\n\n\n\n\n\n\n\n\nY los diagnósticos son razonables, podemos recuperar correctamente los parámetros de interés.\n\n11.8.1 Calibración inferencial 3\nAhora hacemos nuestro diagnóstico de cómo estamos aprendiendo de los datos (ver más arriba en el paso 1 para explicaciones). Los diagnósticos de calibración inferencial son satisfactorios:\n\ncontraccion_z_tbl &lt;- ajustes_apriori |&gt; map_df(function(ajuste_lst){\n  lambda_sim &lt;- ajuste_lst$lambda_sim\n  sd_previa &lt;- 3.33 # ver inicial de lambda\n  post_media_sd_tbl &lt;- ajuste_lst$ajuste$draws(\"lambda\", format = \"df\") |&gt; \n    summarise(media_post = mean(lambda), sd_post = sd(lambda))\n  tibble(contraccion = 1 - post_media_sd_tbl$sd_post^2/sd_previa^2,\n         z = (lambda_sim - post_media_sd_tbl$media_post)/post_media_sd_tbl$sd_post)\n})\n\n\nggplot(contraccion_z_tbl, aes(x = contraccion, y = z)) +\n  geom_point() +\n  xlab(\"Contracción\") + ylab(\"Valor z\") + \n  xlim(0, 1) + labs(subtitle = \"Lambda\")\n\n\n\n\n\n\n\n\n\ncontraccion_z_tbl &lt;- ajustes_apriori |&gt; map_df(function(ajuste_lst){\n  p_sim &lt;- ajuste_lst$p_sim\n  sd_previa &lt;- 0.182 # ver inicial de lambda\n  post_media_sd_tbl &lt;- ajuste_lst$ajuste$draws(\"p\", format = \"df\") |&gt; \n    summarise(media_post = mean(p), sd_post = sd(p))\n  tibble(contraccion = 1 - post_media_sd_tbl$sd_post^2/sd_previa^2,\n         z = (p_sim - post_media_sd_tbl$media_post)/post_media_sd_tbl$sd_post)\n})\n\n\nggplot(contraccion_z_tbl, aes(x = contraccion, y = z)) +\n  geom_point() +\n  xlab(\"Contracción\") + ylab(\"Valor z\") + \n  xlim(0, 1) + labs(subtitle = \"Probabilidad p\")\n\n\n\n\n\n\n\n\nLos diagnósticos no muestran problemas.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#chequeos-predictivos-posteriores-3",
    "href": "14-mas-flujo-bayesiano.html#chequeos-predictivos-posteriores-3",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.9 Chequeos predictivos posteriores 3",
    "text": "11.9 Chequeos predictivos posteriores 3\nAjustamos los datos y checamos diagnósticos de la cadena, que no señalan problemas:\n\ndatos_obs &lt;- read_csv(\"../datos/ejemplo-flujo.csv\")\n\nRows: 100 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndatos_lst &lt;- list(y = datos_obs$y, N = nrow(datos_obs))\n  ajuste &lt;- mod_3$sample(data = datos_lst, \n  iter_sampling = 1000, refresh = 1000, chains = 3, parallel_chains = 3, seed = 282)\n\nRunning MCMC with 3 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33666cd27318.stan', line 12, column 2 to column 25)\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 1 \n\n\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33666cd27318.stan', line 12, column 2 to column 25)\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 2 \nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33666cd27318.stan', line 12, column 2 to column 25)\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 2 \n\n\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 3 Exception: gamma_lpdf: Random variable is 0, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33666cd27318.stan', line 12, column 2 to column 25)\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 3 \n\n\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.2 seconds.\n\nAll 3 chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.3 seconds.\n\n\n\najuste$summary(c(\"lambda\",\"p\")) |&gt; \nselect(mean, sd, q5, q95, rhat, ess_bulk, ess_tail)\n\n# A tibble: 2 × 7\n   mean     sd    q5   q95  rhat ess_bulk ess_tail\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 8.49  0.343  7.94  9.05   1.00    2671.    2102.\n2 0.304 0.0433 0.235 0.377  1.00    3126.    2154.\n\n\nNotemos cómo ahora la interpretación de \\(\\lambda\\) es diferente, y nuestra inferencia es que entre 0.23 y 0.38 de los detectores no están funcionando correctamente.\nAhora simulamos datos observados de la predictiva posterior ajustada, y comparamos con los datos observados.\n\nsims_post_pred_tbl &lt;- ajuste$draws(\"y_sim\", format = \"df\") |&gt; \n  as_tibble() |&gt;\n  pivot_longer(cols = starts_with(\"y_sim\"), names_to = \"y\", values_to = \"valor\") |&gt; \n  separate(y, into = c(\"y_sim\", \"n\"), sep = \"[\\\\[\\\\]]\", extra = \"drop\") |&gt; select(-y_sim)\n\n\nggplot(sims_post_pred_tbl |&gt; filter(.draw &lt;=10) |&gt; \n  bind_rows(datos_obs |&gt; rename(valor = y) |&gt; mutate(.draw = 11)), \n    aes(x = valor)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~.draw) +\n  labs(subtitle = \"Chequeo predictivo posterior\")\n\n\n\n\n\n\n\n\nEste diagnóstico se ve mucho mejor, ahora que hemos incluido la posibilidad de detectores defectuosos.\nPodemos hacer también hacer una gráfica agregada de la posterior predictiva, comparando con la observada. Hasta ahora, este es el mejor resultado que hemos obtenido:\n\nggplot(sims_post_pred_tbl |&gt; group_by(.draw, valor) |&gt; count() |&gt; \n         group_by(valor) |&gt; \n         summarise(mediana = median(n), q_10 = quantile(n, 0.1), q90 = quantile(n, 0.9)) |&gt; \n         pivot_longer(cols = c(mediana, q_10, q90), names_to = \"tipo\", values_to = \"resumen\"),\n  aes(x = valor)) +\n  geom_line(aes(y = resumen, group = tipo)) +\n  labs(subtitle = \"Distribución predictiva a priori\") +\n  ylab(\"Frecuencia\") +\n  geom_histogram(data = datos_obs, aes(x = y), bins = 30, alpha = 0.5)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  },
  {
    "objectID": "14-mas-flujo-bayesiano.html#cuarta-iteración",
    "href": "14-mas-flujo-bayesiano.html#cuarta-iteración",
    "title": "11  Más detalles y diagnósticos del flujo bayesiano",
    "section": "11.10 Cuarta iteración",
    "text": "11.10 Cuarta iteración\nDespués de descubrir todos estos problemas con los datos, tenemos algo de preocupación de que algo más esté pasando y que nuestros resultados no sean correctos. Después de leer el manual de los sensores, nos damos cuenta de que tienen un punto de corte de 14 unidades, de forma que cuando se detectan más de 14 unidades, el sensor devuelve un resultado nan. Sin embargo, para hacernos la vida “fácil”, nos dicen que en esos casos repitieron la medición del sensor hasta obtener algún valor.\nEsto puede cambiar la inferencia, porque los datos están truncados por la derecha en 14. Podemos cambiar entonces el modelo para incluir un truncamiento a la derecha. Nótese que esto no lo hacemos viendo los datos, lo hacemos porque sabemos que el proceso generador contiene características no modeladas que pueden afectar la inferencia.\nEn este punto, puedes consultar la fuente original de este caso de estudio M. Betancourt para todos los chequeos. En este caso, sólo mostraremos cómo queda el modelo final y las inferencias obtenidas.\n\nmod_4 &lt;- cmdstan_model(\"src/flujo-mb/4-modelo-poisson-cero-inflado-truncado.stan\")\nprint(mod_4)\n\ndata {\n  int N;\n  array[N] int y;\n}\n\nparameters {\n  real&lt;lower=0&gt; lambda;\n  real&lt;lower=0, upper=1&gt; p;\n}\n\nmodel {\n  lambda ~ gamma(4, 0.6);\n  p ~ beta(2, 4);\n  for(n in 1:N){\n    // Poisson truncada en 14:\n    real lpdf = poisson_lpmf(y[n] | lambda) - poisson_lcdf(14 | lambda);\n    if(y[n] == 0){\n      target += log_mix(p, 0, lpdf);\n    } else {\n      target += log(1-p) + lpdf;\n    }\n  }\n}\n\ngenerated quantities {\n\n}\n\n\n\ndatos_obs &lt;- read_csv(\"../datos/ejemplo-flujo.csv\")\n\nRows: 100 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndatos_lst &lt;- list(y = datos_obs$y, N = nrow(datos_obs))\n  ajuste &lt;- mod_4$sample(data = datos_lst, \n  iter_sampling = 1000, refresh = 1000, chains = 3, parallel_chains = 3, seed = 282)\n\nRunning MCMC with 3 parallel chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 1 Exception: gamma_lpdf: Random variable is 0, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33665adb8d60.stan', line 12, column 2 to column 25)\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 1 \nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 1 Exception: gamma_lpdf: Random variable is 0, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33665adb8d60.stan', line 12, column 2 to column 25)\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 1 \n\n\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33665adb8d60.stan', line 12, column 2 to column 25)\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 2 \nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33665adb8d60.stan', line 12, column 2 to column 25)\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 2 \n\n\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 3 Exception: gamma_lpdf: Random variable is 0, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33665adb8d60.stan', line 12, column 2 to column 25)\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 3 \nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\nChain 3 Exception: gamma_lpdf: Random variable is 0, but must be positive finite! (in '/tmp/RtmpHba8sI/model-33665adb8d60.stan', line 12, column 2 to column 25)\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\nChain 3 \n\n\nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.0 seconds.\nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.2 seconds.\nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.3 seconds.\n\nAll 3 chains finished successfully.\nMean chain execution time: 1.2 seconds.\nTotal execution time: 1.4 seconds.\n\n\n\najuste$summary(c(\"lambda\",\"p\")) |&gt; \nselect(mean, sd, q5, q95, rhat, ess_bulk, ess_tail)\n\n# A tibble: 2 × 7\n   mean     sd    q5   q95  rhat ess_bulk ess_tail\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 8.76  0.394  8.14  9.42   1.00    3085.    1890.\n2 0.302 0.0433 0.230 0.377  1.00    2970.    1774.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Más detalles y diagnósticos del flujo bayesiano</span>"
    ]
  }
]